{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.segment.mask import applymask\n",
    "from dipy.segment.mask import bounding_box\n",
    "from dipy.segment.mask import crop\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.imwarp import DiffeomorphicMap\n",
    "from dipy.align.metrics import CCMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import (transform_centers_of_mass,\n",
    "                                 AffineMap,\n",
    "                                 MutualInformationMetric,\n",
    "                                 AffineRegistration)\n",
    "from dipy.align.transforms import (TranslationTransform3D,\n",
    "                                   RigidTransform3D,\n",
    "                                   AffineTransform3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_chart(scan1, scan2, scan3, scan4, sagital=0, coronal=0, axial=0):\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(3,4,1).set_axis_off()\n",
    "    plt.imshow(scan1[:, :, axial, 0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Scan 1 PET\")\n",
    "    plt.subplot(3,4,2).set_axis_off()\n",
    "    plt.imshow(scan2[:, :, axial, 0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Scan 2 PET\")\n",
    "    plt.subplot(3,4,3).set_axis_off()\n",
    "    plt.imshow(scan3[:, :, axial, 0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Scan 1 TRIO\")\n",
    "    plt.subplot(3,4,4).set_axis_off()\n",
    "    plt.imshow(scan4[:, :, axial, 0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Scan 2 TRIO\")\n",
    "    plt.subplot(3,4,5).set_axis_off()\n",
    "    plt.imshow(scan1[sagital, :, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,6).set_axis_off()\n",
    "    plt.imshow(scan2[sagital, :, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,7).set_axis_off()\n",
    "    plt.imshow(scan3[sagital, :, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,8).set_axis_off()\n",
    "    plt.imshow(scan4[sagital, :, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,9).set_axis_off()\n",
    "    plt.imshow(scan1[:, coronal, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,10).set_axis_off()\n",
    "    plt.imshow(scan2[:, coronal, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,11).set_axis_off()\n",
    "    plt.imshow(scan3[:, coronal, :, 0].T, cmap='gray', origin='lower')\n",
    "    plt.subplot(3,4,12).set_axis_off()\n",
    "    plt.imshow(scan4[:, coronal, :, 0].T, cmap='gray', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for performing affine transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affine_registration(reference, reference_grid2world, scan, scan_grid2world):\n",
    "    #get first b0 volumes for both scans\n",
    "    reference_b0 = reference[:,:,:,0]\n",
    "    scan_b0 = scan[:,:,:,0]\n",
    "    \n",
    "    #In this function we use multiple stages to register the 2 scans\n",
    "    #providng previous results as initialisation to the next stage, \n",
    "    #the reason we do this is because registration is a non-convex \n",
    "    #problem thus it is important to initialise as close to the \n",
    "    #optiaml value as possible\n",
    "    \n",
    "    #Stage1: we obtain a very rough (and fast) registration by just aligning \n",
    "    #the centers of mass of the two images\n",
    "    center_of_mass = transform_centers_of_mass(reference_b0, reference_grid2world, scan_b0, scan_grid2world)\n",
    "    \n",
    "    #create the similarity metric (Mutual Information) to be used:\n",
    "    nbins = 32\n",
    "    sampling_prop = None #use all voxels to perform registration\n",
    "    metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "    \n",
    "    #We use a multi-resolution stratergy to accelerate convergence and avoid\n",
    "    #getting stuck at local optimas (below are the parameters)\n",
    "    level_iters = [10000, 1000, 100]\n",
    "    sigmas = [3.0, 1.0, 0.0] #parameters for gaussian kernel smoothing at each resolution\n",
    "    factors = [4, 2, 1] #subsampling factor\n",
    "    \n",
    "    #optimisation algorithm used is L-BFGS-B\n",
    "    affreg = AffineRegistration(metric=metric, level_iters=level_iters, sigmas=sigmas, factors=factors)\n",
    "    \n",
    "    #Stage2: Perform a basic translation transform\n",
    "    transform = TranslationTransform3D()\n",
    "    translation = affreg.optimize(reference_b0, scan_b0, transform, None, reference_grid2world, scan_grid2world, starting_affine=center_of_mass.affine)\n",
    "    \n",
    "    #Stage3 : optimize previous result with a rigid transform\n",
    "    #(Includes translation, rotation)\n",
    "    transform = RigidTransform3D()\n",
    "    rigid = affreg.optimize(reference_b0, scan_b0, transform, None, reference_grid2world, scan_grid2world, starting_affine=translation.affine)\n",
    "    \n",
    "    #Stage4 : optimize previous result with a affine transform\n",
    "    #(Includes translation, rotation, scale, shear)\n",
    "    transform = AffineTransform3D()\n",
    "    affine = affreg.optimize(reference_b0, scan_b0, transform, None, reference_grid2world, scan_grid2world, starting_affine=rigid.affine)\n",
    "    \n",
    "    #Stage 5 : Symmetric Diffeomorphic Registration\n",
    "    metric = CCMetric(3)\n",
    "    level_iters = [400, 200, 100]\n",
    "    sdr = SymmetricDiffeomorphicRegistration(metric, level_iters)\n",
    "    mapping = sdr.optimize(reference_b0, scan_b0, reference_grid2world, scan_grid2world, affine.affine)\n",
    "    \n",
    "    #Once this is completed we can perform the affine transformation on each \n",
    "    #volume of scan2\n",
    "   \n",
    "    for volume in range(0, scan.shape[3]):\n",
    "        #note affine is an AffineMap object,\n",
    "        #The transform method transforms the input image from co-domain to domain space\n",
    "        #By default, the transformed image is sampled at a grid defined by the shape of the domain\n",
    "        #The sampling is performed using linear interpolation (refer to comp vision lab on homographies)\n",
    "        scan[:,:,:,volume] = mapping.transform(scan[:,:,:,volume])\n",
    "        \n",
    "    return scan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_masks_crop(reference_scan, other_scan1, other_scan2):\n",
    "    #Median_otsu is a segmnentation technique that is a hybridisation of median filtering and otsu thresholding\n",
    "    #the combination (4,4) is shown to be the most robust\n",
    "    _, reference_scan_mask = median_otsu(reference_scan, median_radius=4, numpass=4, autocrop=False, dilate=2)\n",
    "    _, other_scan1_mask = median_otsu(other_scan1, median_radius=4, numpass=4, autocrop=False, dilate=2)\n",
    "    _, other_scan2_mask = median_otsu(other_scan2, median_radius=4, numpass=4, autocrop=False, dilate=2)\n",
    "    \n",
    "    #Get the intersection of the masks\n",
    "    mask_union = np.logical_and(reference_scan_mask, np.logical_and(other_scan1_mask, other_scan2_mask))\n",
    "    \n",
    "    #Apply the combined mask to the scans\n",
    "    reference_scan_brain = applymask(reference_scan, mask_union)\n",
    "    other_scan1_brain = applymask(other_scan1, mask_union)\n",
    "    other_scan2_brain = applymask(other_scan2, mask_union)\n",
    "    \n",
    "    #Crop the scans using the unioned mask\n",
    "    (mins, maxs) = bounding_box(mask_union)\n",
    "    reference_scan_brain = crop(reference_scan_brain, mins, maxs)\n",
    "    other_scan1_brain = crop(other_scan1_brain, mins, maxs)\n",
    "    other_scan2_brain = crop(other_scan2_brain, mins, maxs)\n",
    "    \n",
    "    return (reference_scan_brain, other_scan1_brain, other_scan2_brain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_masks_crop_bet(reference_scan, other_scan1, other_scan2, ref_data_path, other_data_path, subject, scan):\n",
    "    # Use bet for generating brain masks for each of the scans\n",
    "\n",
    "    # Get the mask of the reference scan \n",
    "    os.chdir(ref_data_path + \"/Subj\" + str(subject) + \"Scan\" +str(scan))\n",
    "    subprocess.call([\"bet\", \"NODDI_3Shells.nii\", \"Brain_temp\", \"-m\", \"-n\", \"-R\", \"-f\", \"0.2\", \"-t\"])\n",
    "    reference_scan_mask = nib.load(\"Brain_temp_mask.nii.gz\")\n",
    "    reference_scan_mask = reference_scan_mask.get_data()\n",
    "    # Delete the created files\n",
    "    os.remove('Brain_temp.nii.gz')\n",
    "    os.remove('Brain_temp_mask.nii.gz')\n",
    "\n",
    "    # Similarly get the masks of the other scans\n",
    "    os.chdir(other_data_path + \"/Subj\" + str(subject) + \"Scan1\")\n",
    "    subprocess.call([\"bet\", \"Full_Registered_Scan\" + str(scan) + \".nii.gz\", \"Brain_temp\", \"-m\", \"-n\", \"-R\", \"-f\", \"0.2\", \"-t\"])\n",
    "    other_scan1_mask = nib.load(\"Brain_temp_mask.nii.gz\")\n",
    "    other_scan1_mask = other_scan1_mask.get_data()\n",
    "    os.remove('Brain_temp.nii.gz')\n",
    "    os.remove('Brain_temp_mask.nii.gz')\n",
    "        \n",
    "    os.chdir(other_data_path + \"/Subj\" + str(subject) + \"Scan2\")\n",
    "    subprocess.call([\"bet\", \"Full_Registered_Scan\" + str(scan) + \".nii.gz\", \"Brain_temp\", \"-m\", \"-n\", \"-R\", \"-f\", \"0.2\", \"-t\"])\n",
    "    other_scan2_mask = nib.load(\"Brain_temp_mask.nii.gz\")\n",
    "    other_scan2_mask = other_scan2_mask.get_data()\n",
    "    os.remove('Brain_temp.nii.gz')\n",
    "    os.remove('Brain_temp_mask.nii.gz')\n",
    "    \n",
    "    #Get the intersection of the masks\n",
    "    mask_union = np.logical_and(reference_scan_mask, np.logical_and(other_scan1_mask, other_scan2_mask))\n",
    "    \n",
    "    #Apply the combined mask to the scans\n",
    "    reference_scan_brain = applymask(reference_scan, mask_union)\n",
    "    other_scan1_brain = applymask(other_scan1, mask_union)\n",
    "    other_scan2_brain = applymask(other_scan2, mask_union)\n",
    "    \n",
    "    #Crop the scans using the unioned mask\n",
    "    (mins, maxs) = bounding_box(mask_union)\n",
    "    reference_scan_brain = crop(reference_scan_brain, mins, maxs)\n",
    "    other_scan1_brain = crop(other_scan1_brain, mins, maxs)\n",
    "    other_scan2_brain = crop(other_scan2_brain, mins, maxs)\n",
    "    \n",
    "    return (reference_scan_brain, other_scan1_brain, other_scan2_brain)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_registration(dataset_path_petmr, dataset_path_trio, reference):\n",
    "    # Iterate through the subjects in the directory\n",
    "    \n",
    "    if reference == \"PETMR\":\n",
    "        ref_data_path = dataset_path_petmr\n",
    "        other_data_path = dataset_path_trio\n",
    "    else:\n",
    "        ref_data_path = dataset_path_trio\n",
    "        other_data_path = dataset_path_petmr\n",
    "    \n",
    "    subjects = [1,2,3,4,5,6,7,8,9,10]\n",
    "    scans = [1,2]\n",
    "    for subject in subjects:\n",
    "        for scan in scans:\n",
    "            \n",
    "            print (\"Processing Subject %s, Using Scan %s (%s) as the reference scan\" % (str(subject), str(scan), reference))\n",
    "            # Load the reference scan and the 2 corresponding scans from the other scanner\n",
    "                \n",
    "            reference_scan = nib.load(ref_data_path + \"/Subj\" + str(subject) + \"Scan\" +str(scan) + \"/NODDI_3Shells.nii.gz\")\n",
    "            other_scan1 = nib.load(other_data_path + \"/Subj\" + str(subject) + \"Scan1\" + \"/NODDI_3Shells.nii.gz\")\n",
    "            other_scan2 = nib.load(other_data_path + \"/Subj\" + str(subject) + \"Scan2\" + \"/NODDI_3Shells.nii.gz\")\n",
    "            \n",
    "            # Convert the images to dipy format\n",
    "            reference_scan_data = reference_scan.get_data()\n",
    "            other_scan1_data = other_scan1.get_data()\n",
    "            other_scan2_data = other_scan2.get_data()\n",
    "            \n",
    "            # Get the grid2world matrices for each scan\n",
    "            reference_scan_grid2world = reference_scan.affine\n",
    "            other_scan1_grid2world = other_scan1.affine\n",
    "            other_scan2_grid2world = other_scan2.affine\n",
    "            \n",
    "            # Perform registration using the 'reference_scan' as the static/reference scan\n",
    "            # i.e we apply spatial transformations to all other scans to achive spatial correspondance with the reference_scan\n",
    "            # by doing so we indirectly achive spatial correspondace between all scans\n",
    "            print (\"Performing Registration for: Scan 1\")\n",
    "            other_scan1_transformed = affine_registration(reference_scan_data, reference_scan_grid2world, other_scan1_data, other_scan1_grid2world)\n",
    "            print (\"Performing Registration for: Scan 2\")\n",
    "            other_scan2_transformed = affine_registration(reference_scan_data, reference_scan_grid2world, other_scan2_data, other_scan2_grid2world)\n",
    "            print (\"---Registration Completed---\")\n",
    "\n",
    "            # Create images from the data\n",
    "            other_scan1_img = nib.Nifti1Image(other_scan1_transformed.astype(np.float32), reference_scan.affine)\n",
    "            other_scan2_img = nib.Nifti1Image(other_scan2_transformed.astype(np.float32), reference_scan.affine)\n",
    "            \n",
    "            nib.save(other_scan1_img, other_data_path + \"/Subj\" + str(subject) + \"Scan1\" + \"/Full_Registered_Scan\" + str(scan) + \".nii.gz\")\n",
    "            nib.save(other_scan2_img, other_data_path + \"/Subj\" + str(subject) + \"Scan2\" + \"/Full_Registered_Scan\" + str(scan) + \".nii.gz\")    \n",
    "\n",
    "            # Compute brain masks for each scan - Use FSL BET for this\n",
    "            print (\"Computing brain masks\")\n",
    "            (reference_brain, other_brain1, other_brain2) = \\\n",
    "                compute_masks_crop_bet(reference_scan_data, other_scan1_transformed, other_scan2_transformed, ref_data_path, other_data_path, subject, scan)\n",
    "\n",
    "            # Save the new masked/cropped scans\n",
    "            print (\"Saving cropped masks\")  \n",
    "            \n",
    "            # Create images from the cropped data\n",
    "            reference_brain_img = nib.Nifti1Image(reference_brain.astype(np.float32), reference_scan.affine)\n",
    "            other_brain1_img = nib.Nifti1Image(other_brain1.astype(np.float32), reference_scan.affine)\n",
    "            other_brain2_img = nib.Nifti1Image(other_brain2.astype(np.float32), reference_scan.affine)\n",
    "            \n",
    "            # Store the images -- These are cropped\n",
    "            nib.save(reference_brain_img, ref_data_path + \"/Subj\" + str(subject) + \"Scan\" + str(scan) + \"/Brain_Extracted\" + \".nii.gz\")\n",
    "            nib.save(other_brain1_img, other_data_path + \"/Subj\" + str(subject) + \"Scan1\" + \"/Brain_Extracted_Scan\" + str(scan) + \".nii.gz\")\n",
    "            nib.save(other_brain2_img, other_data_path + \"/Subj\" + str(subject) + \"Scan2\" + \"/Brain_Extracted_Scan\" + str(scan) + \".nii.gz\")\n",
    "\n",
    "            print (\"---Iteration Complete---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With automated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Subject 1, Using Scan 1 (PETMR) as the reference scan\n",
      "Performing Registration for: Scan 1\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "Optimizing level 2 [max iter: 10000]\n"
     ]
    }
   ],
   "source": [
    "dataset_path_trio = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data' \n",
    "dataset_path_petmr = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data'\n",
    "perform_registration(dataset_path_petmr, dataset_path_trio, reference=\"PETMR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data/Subj1Scan1/')\n",
    "imgScan1 = nib.load(\"Brain_Extracted.nii.gz\")\n",
    "petmr_scan1 = imgScan1.get_data()\n",
    "\n",
    "os.chdir('/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data/Subj1Scan2/')\n",
    "imgScan2 = nib.load(\"Brain_Extracted.nii.gz\")\n",
    "petmr_scan2 = imgScan2.get_data()\n",
    "\n",
    "os.chdir('/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data/Subj1Scan1/')\n",
    "imgScan3 = nib.load(\"Brain_Extracted.nii.gz\")\n",
    "trio_scan1 = imgScan3.get_data()\n",
    "\n",
    "os.chdir('/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data/Subj1Scan2/')\n",
    "imgScan4 = nib.load(\"Brain_Extracted.nii.gz\")\n",
    "trio_scan2 = imgScan4.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_chart(petmr_scan1, petmr_scan2, trio_scan1, trio_scan2, 25, 25, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
