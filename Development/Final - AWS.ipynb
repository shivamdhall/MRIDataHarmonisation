{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fianl - AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use both scans of subjects 1-8 from the PETMR and TRIO dataset for training.\n",
    "\n",
    "We used the scan of subjects 9-10 also from the PETMR and TRIO dataset for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function simply uploads the testing and training scans into lists of numpy arrays\n",
    "#the data is not yet sliced or patched at this stage\n",
    "\n",
    "#specify in a list what scans to use for training and what scans to use for testing\n",
    "\n",
    "\n",
    "def get_data(petmr_path, trio_path, scans_dict, input_scanner):\n",
    "    \n",
    "    train_val_test_inp = []\n",
    "    train_val_test_out1 = []\n",
    "    train_val_test_out2 = []\n",
    "    test_data_inp = []\n",
    "    test_data_out1 = []\n",
    "    test_data_out2 = []\n",
    "    \n",
    "    if input_scanner == \"PETMR\":\n",
    "        input_path = petmr_path\n",
    "        output_path = trio_path\n",
    "    else:\n",
    "        input_path = trio_path\n",
    "        output_path = petmr_path       \n",
    "    \n",
    "    for key, subjs in scans_dict.iteritems():\n",
    "        for subj_scan in subjs:\n",
    "                \n",
    "            input_scan_image = nib.load(str(input_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan\" + str(subj_scan[1]) + \"/Brain_Matched.nii.gz\")\n",
    "            input_scan_data = input_scan_image.get_data()\n",
    "                \n",
    "            # Important : Upload the output scan that is registered to the appropriate input scan\n",
    "            output_scan_image1 = nib.load(str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan1\" + \"/Brain_Matched_Scan\" + str(subj_scan[1]) + \".nii.gz\")\n",
    "            output_scan_data1 = output_scan_image1.get_data()\n",
    "            \n",
    "            output_scan_image2 = nib.load(str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan2\" + \"/Brain_Matched_Scan\" + str(subj_scan[1]) + \".nii.gz\")\n",
    "            output_scan_data2 = output_scan_image2.get_data()\n",
    "                \n",
    "            input_bvals_scan, input_bvecs_scan = read_bvals_bvecs(str(input_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan\" + str(subj_scan[1]) + \"/NODDI.bval\",\\\n",
    "                                                          str(input_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan\" + str(subj_scan[1]) + \"/NODDI.bvec\")\n",
    "                \n",
    "            output_bvals_scan1, output_bvecs_scan1 = read_bvals_bvecs(str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan1/NODDI.bval\",\\\n",
    "                                                          str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan1/NODDI.bvec\")\n",
    "            \n",
    "            output_bvals_scan2, output_bvecs_scan2 = read_bvals_bvecs(str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan2/NODDI.bval\",\\\n",
    "                                                          str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan2/NODDI.bvec\")\n",
    "                \n",
    "            #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "            input_gtab_scan = gradient_table(input_bvals_scan, input_bvecs_scan, b0_threshold=5)\n",
    "            input_s0s_scan = input_scan_data[:, :, :, input_gtab_scan.b0s_mask]\n",
    "                \n",
    "            output_gtab_scan1 = gradient_table(output_bvals_scan1, output_bvecs_scan1, b0_threshold=5)\n",
    "            output_s0s_scan1 = output_scan_data1[:, :, :, output_gtab_scan1.b0s_mask]\n",
    "            \n",
    "            output_gtab_scan2 = gradient_table(output_bvals_scan2, output_bvecs_scan2, b0_threshold=5)\n",
    "            output_s0s_scan2 = output_scan_data2[:, :, :, output_gtab_scan2.b0s_mask]\n",
    "                \n",
    "            # Use only the first volume, ignore other volumes\n",
    "            if(key == \"train_val_test\"):\n",
    "                print (\"Uploading Subject %s Scan %s\" % (str(subj_scan[0]), str(subj_scan[1])))\n",
    "                #append the data to the lists containing the training inputs and outputs\n",
    "                train_val_test_inp.append(input_s0s_scan[:,:,:,[0]])\n",
    "                train_val_test_out1.append(output_s0s_scan1[:,:,:,[0]])\n",
    "                train_val_test_out2.append(output_s0s_scan2[:,:,:,[0]])\n",
    "            else:\n",
    "                print (\"Testing: Subject %s Scan %s\" % (str(subj_scan[0]), str(subj_scan[1])))\n",
    "                test_data_inp.append(input_s0s_scan[:,:,:,[0]])\n",
    "                test_data_out1.append(output_s0s_scan1[:,:,:,[0]])\n",
    "                test_data_out2.append(output_s0s_scan2[:,:,:,[0]])\n",
    "    return (train_val_test_inp, train_val_test_out1, train_val_test_out2, test_data_inp, test_data_out1, test_data_out2, output_scan_image1.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "\n",
    "def patchify(data_scans_inp, data_scans_out1, data_scans_out2, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store1 = []\n",
    "    target_patches_store2 = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan1 = data_scans_out1[scan_no]\n",
    "        target_scan2 = data_scans_out2[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel1 = target_scan1[pos_x,pos_y,pos_z,volume]\n",
    "                        target_voxel2 = target_scan2[pos_x,pos_y,pos_z,volume]\n",
    "                        \n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store1.append(target_voxel1)\n",
    "                        target_patches_store2.append(target_voxel2)\n",
    "                        \n",
    "    return (input_patches_store, target_patches_store1, target_patches_store2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "#This version of the functions only considers voxels wholly contained within the brain\n",
    "\n",
    "def patchify_brain_only(data_scans_inp, data_scans_out1, data_scans_out2, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store1 = []\n",
    "    target_patches_store2 = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan1 = data_scans_out1[scan_no]\n",
    "        target_scan2 = data_scans_out2[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        # Exclude all background voxels\n",
    "                        if(input_scan[pos_x,pos_y,pos_z,volume] == 0):\n",
    "                            continue\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel1 = target_scan1[pos_x,pos_y,pos_z,volume]\n",
    "                        target_voxel2 = target_scan2[pos_x,pos_y,pos_z,volume]\n",
    "                        # Exclude all patches that contain artefacts\n",
    "                        if input_patch.min() < 0:\n",
    "                            continue\n",
    "                            \n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store1.append(target_voxel1)\n",
    "                        target_patches_store2.append(target_voxel2)\n",
    "                        \n",
    "    return (input_patches_store, target_patches_store1, target_patches_store2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(input_list, output_list1, output_list2, train_prop, val_prop, test_prop):\n",
    "    length = len(input_list)\n",
    "    indexes = range(length)\n",
    "    # Randomly shuffle the indexes\n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    train_len = int(round(length * train_prop))\n",
    "    val_len = int(round(length * val_prop))\n",
    "    test_len = int(length - train_len - val_len)\n",
    "\n",
    "    train_indices = indexes[:train_len]\n",
    "    val_indices = indexes[train_len:train_len+val_len]\n",
    "    test_indices = indexes[train_len+val_len:]\n",
    "\n",
    "    training_input = [input_list[i] for i in train_indices]\n",
    "    training_output = [output_list1[i] for i in train_indices]\n",
    "    \n",
    "    validation_input = [input_list[i] for i in val_indices]\n",
    "    validation_output = [output_list1[i] for i in val_indices]\n",
    "    \n",
    "    testing_input = [input_list[i] for i in test_indices]\n",
    "    testing_output1 = [output_list1[i] for i in test_indices]\n",
    "    testing_output2 = [output_list2[i] for i in test_indices]\n",
    "    \n",
    "    return(training_input, training_output, validation_input, validation_output, testing_input, testing_output1, testing_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_pred(inputs, predictions, labels, sliceNo):\n",
    "    maximum = np.max([inputs.max(), predictions.max(), labels.max()])\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1).set_axis_off()\n",
    "    plt.imshow(inputs[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmax = maximum, vmin=0)\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2).set_axis_off()\n",
    "    plt.imshow(predictions[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmax = maximum, vmin=0)\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.subplot(1, 3, 3).set_axis_off()\n",
    "    plt.imshow(labels[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmax = maximum, vmin=0)\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Subject 1 Scan 1\n",
      "Uploading Subject 1 Scan 2\n",
      "Uploading Subject 2 Scan 1\n",
      "Uploading Subject 2 Scan 2\n",
      "Uploading Subject 3 Scan 1\n",
      "Uploading Subject 3 Scan 2\n",
      "Uploading Subject 4 Scan 1\n",
      "Uploading Subject 4 Scan 2\n",
      "Uploading Subject 5 Scan 1\n",
      "Uploading Subject 5 Scan 2\n",
      "Uploading Subject 6 Scan 1\n",
      "Uploading Subject 6 Scan 2\n",
      "Uploading Subject 7 Scan 1\n",
      "Uploading Subject 7 Scan 2\n",
      "Uploading Subject 8 Scan 1\n",
      "Uploading Subject 10 Scan 1\n",
      "Testing: Subject 9 Scan 1\n",
      "Number of scans used for training, validation and testing: 16\n",
      "Number of scans used for final testing: 1\n"
     ]
    }
   ],
   "source": [
    "#upload the data\n",
    "petmr_data_path = '/home/ubuntu/project/Dataset/PETMR_data'\n",
    "trio_data_path = '/home/ubuntu/project/Dataset/TRIO_data'\n",
    "\n",
    "# Enter a list of tuples (subject, scan_number)\n",
    "# Use this to get all scans then split into training, validation and testing\n",
    "train_val_test_scans = [(1,1), (1,2), (2,1), (2,2), (3,1), (3,2), (4,1), (4,2), (5,1), (5,2), \\\n",
    "                        (6,1), (6,2), (7,1), (7,2), (8,1), (10,1)]\n",
    "\n",
    "# This is a final test scan only - used to generate a complete scan from the trained CNN\n",
    "testing_scans = [(9,1)]\n",
    "\n",
    "data_dict = {\"train_val_test\": train_val_test_scans, \"testing\":testing_scans}\n",
    "\n",
    "(train_val_test_inp, train_val_test_out1, train_val_test_out2, final_test_inp, final_test_out1, final_test_out2, affine_mat) = \\\n",
    "        get_data(petmr_data_path, trio_data_path, data_dict, input_scanner=\"PETMR\")\n",
    "print(\"Number of scans used for training, validation and testing: %d\" % len(train_val_test_inp))\n",
    "print (\"Number of scans used for final testing: %d\" % len(final_test_inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patchify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchifying training, validation and testing set\n",
      "Patchifying final testing scan\n"
     ]
    }
   ],
   "source": [
    "print \"Patchifying training, validation and testing set\"\n",
    "(train_val_test_input, train_val_test_target1, train_val_test_target2) = patchify_brain_only(train_val_test_inp, train_val_test_out1, train_val_test_out2, 9)\n",
    "\n",
    "print \"Patchifying final testing scan\"\n",
    "(final_testing_input, final_testing_target1, final_testing_target2) = patchify(final_test_inp, final_test_out1, final_test_out2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nember of training, validation and testing examples : 1389921\n",
      "Nember of final testing examples : 187000\n"
     ]
    }
   ],
   "source": [
    "print (\"Nember of training, validation and testing examples : %d\" % len(train_val_test_input))\n",
    "print (\"Nember of final testing examples : %d\" % len(final_testing_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly split the data into training validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input, training_target, validation_input, validation_target, testing_input, testing_target1, testing_target2 = \\\n",
    "        split_data(train_val_test_input, train_val_test_target1, train_val_test_target2, 0.70, 0.15, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nember of training examples : 972945\n",
      "Nember of Validation examples : 208488\n",
      "Nember of testing examples : 208488\n"
     ]
    }
   ],
   "source": [
    "print (\"Nember of training examples : %d\" % len(training_input))\n",
    "print (\"Nember of Validation examples : %d\" % len(validation_input))\n",
    "print (\"Nember of testing examples : %d\" % len(testing_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset class for our data\n",
    "\n",
    "class MRIdataset(Dataset):\n",
    "    \"\"\"MRI b=0 dataset for patches.\"\"\"\n",
    "\n",
    "    def __init__(self, input_patches, target_patches, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_patches: Input patches\n",
    "            target_patches: Corresponding target patches of the input patches\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        \"\"\"\n",
    "        self.input_patches = input_patches\n",
    "        self.target_patches = target_patches\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_patch = np.array(self.input_patches[idx])\n",
    "        target_patch = np.array(self.target_patches[idx])\n",
    "        sample = {'input': input_patch, 'target': target_patch}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class To_Tensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inp, out = sample['input'], sample['target']\n",
    "        \n",
    "        #first expand dimension because torch expects H x W x D x C\n",
    "        #currently we only have H x W x D\n",
    "        aug_inp = np.expand_dims(inp, 3)\n",
    "        \n",
    "        #The target is a single voxel,\n",
    "        #Conver it to an array\n",
    "        aug_out = np.array([out])\n",
    "\n",
    "        # swap channel axis because\n",
    "        # numpy: H x W x D x C\n",
    "        # torch: C x D x H x W\n",
    "        aug_inp = aug_inp.transpose((3, 2, 0, 1))\n",
    "        \n",
    "        return {'input': torch.Tensor(aug_inp),\n",
    "                'target': torch.Tensor(aug_out)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, valiloader, training_losses, validation_losses, optimizer, criterion, epochs):\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): #done in batches\n",
    "            # get the inputs\n",
    "            inputs = data['input']\n",
    "            labels = data['target']\n",
    "\n",
    "           # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize/update weights\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0] #loss is a variable tensor of size 1, we index to get the value out\n",
    "            if i % 250 == 249:    # print every 250 mini-batches\n",
    "                total_loss = running_loss / (i+1)\n",
    "                print('[%d, %5d] --- Losss = %.5f' % (epoch + 1, i + 1, total_loss))\n",
    "                \n",
    "        total_loss = running_loss / (i+1)\n",
    "        training_losses.append(total_loss)        \n",
    "        print('Training loss iteration %d = %.5f' % (epoch+1, total_loss ))\n",
    "        \n",
    "        # After each epoch evaluat the performance of the CNN on the validation set\n",
    "        net.eval()   \n",
    "        validation_error = 0\n",
    "        total = 0\n",
    "        for validation_data in valiloader: #batch processing\n",
    "            validation_inputs = validation_data['input']\n",
    "            validation_labels = validation_data['target']\n",
    "            total += 1\n",
    "            \n",
    "            validation_inputs, validation_labels = Variable(validation_inputs.cuda()), Variable(validation_labels.cuda())\n",
    "\n",
    "            validation_predictions = net(validation_inputs)\n",
    "            \n",
    "            validation_error += (torch.nn.functional.mse_loss(Variable(validation_predictions.data), validation_labels)).data[0]\n",
    "            \n",
    "        validation_error /= total\n",
    "        print('MSE on validation set: %f' % (validation_error))\n",
    "        validation_losses.append(validation_error)\n",
    " \n",
    "    print('Finished Training')\n",
    "    return (net, training_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_losses(training_losses, validation_losses):\n",
    "    plt.figure\n",
    "    plt.plot(range(1,len(training_losses)+1), training_losses, 'r-', label=\"Training error\")\n",
    "    plt.plot(range(1,len(validation_losses)+1), validation_losses, 'b-', label=\"Validation error\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('iteration')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    plt.ylabel('Loss - (MSE)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(net, testloader):\n",
    "    net.eval()\n",
    "    for index, test_data in enumerate(testloader):\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        if index % 250 == 249:\n",
    "            print index + 1\n",
    "        \n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "\n",
    "        #store the predictions in a numpy array which we can reshape later\n",
    "        test_predictions = net(test_inputs)\n",
    "        if(index == 0):\n",
    "            predictions = test_predictions.data.cpu().numpy() \n",
    "\n",
    "        else:\n",
    "            predictions = np.concatenate((predictions, test_predictions.data.cpu().numpy()), axis=0)\n",
    "            \n",
    "    #convert back to numpy dimensions of (HxWxDxCxNumbExpls)\n",
    "    predictions = predictions.transpose(3,4,2,1,0)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_background(prediction, input_scan):\n",
    "    background_mask = input_scan <= 0\n",
    "    prediction[background_mask] = 0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_brain(predictions, dimensions):\n",
    "    \n",
    "    size_x = dimensions[0]\n",
    "    size_y = dimensions[1]\n",
    "    size_z = dimensions[2]\n",
    "    size_v = dimensions[3]\n",
    "    #assume we have given it a single scan to reconstruct\n",
    "    reconstructed = np.reshape(predictions, [size_v, size_x, size_y, size_z], order='C')\n",
    "    reconstructed = reconstructed.transpose(1,2,3,0)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data using pytorch data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MRIdataset(training_input, training_target, transform=transforms.Compose([To_Tensor()]))\n",
    "validation_dataset = MRIdataset(validation_input, validation_target, transform=transforms.Compose([To_Tensor()]))\n",
    "testing_dataset = MRIdataset(testing_input, testing_target1, transform=transforms.Compose([To_Tensor()]))\n",
    "\n",
    "final_testing_dataset = MRIdataset(final_testing_input, final_testing_target1, transform=transforms.Compose([To_Tensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_dataset, batch_size=160,\n",
    "                        shuffle=True, num_workers=16)\n",
    "\n",
    "valiloader = DataLoader(validation_dataset, batch_size=160,\n",
    "                        shuffle=True, num_workers=16)\n",
    "\n",
    "testloader = DataLoader(testing_dataset, batch_size=160,\n",
    "                        shuffle=False, num_workers=16)\n",
    "\n",
    "final_test_loader = DataLoader(final_testing_dataset, batch_size=160,\n",
    "                        shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Relu\n",
    "\n",
    "--(WxHx2x1)--\n",
    "\n",
    "conv1 = receptive field -> (3x3x3), zero padding -> 2,  number of filters -> 10\n",
    "\n",
    "--(W+2xH+2x4x10)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv2 = receptive field -> (1x1x1), number of filters -> 15\n",
    "\n",
    "--(W+2xH+2x4x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv3 = receptive field -> (3x3x3), number of filters -> 15\n",
    "\n",
    "--(WxHx2x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv4 = receptive field -> (1x1x2), number of filters -> 1\n",
    "\n",
    "--(WxHx1x1)--\n",
    "\n",
    "--RELU--\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv3d (1, 50, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (conv2): Conv3d (50, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop2): Dropout(p=0.2)\n",
      "  (conv3): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop3): Dropout(p=0.2)\n",
      "  (conv4): Conv3d (100, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch4): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop4): Dropout(p=0.2)\n",
      "  (conv5): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch5): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop5): Dropout(p=0.2)\n",
      "  (conv6): Conv3d (100, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch6): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop6): Dropout(p=0.2)\n",
      "  (conv7): Conv3d (50, 50, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch7): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop7): Dropout(p=0.2)\n",
      "  (conv8): Conv3d (50, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 50, 3)\n",
    "        self.batch1 = nn.BatchNorm2d(50)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = nn.Conv3d(50, 100, 1)\n",
    "        self.batch2 = nn.BatchNorm2d(100)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.conv3 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch3 = nn.BatchNorm2d(100)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.conv4 = nn.Conv3d(100, 100, 1)\n",
    "        self.batch4 = nn.BatchNorm2d(100)\n",
    "        self.drop4 = nn.Dropout(p=0.2)\n",
    "        self.conv5 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch5 = nn.BatchNorm2d(100)\n",
    "        self.drop5 = nn.Dropout(p=0.2)\n",
    "        self.conv6 = nn.Conv3d(100, 50, 1)\n",
    "        self.batch6 = nn.BatchNorm2d(50)\n",
    "        self.drop6 = nn.Dropout(p=0.2)\n",
    "        self.conv7 = nn.Conv3d(50, 50, 3)\n",
    "        self.batch7 = nn.BatchNorm2d(50)\n",
    "        self.drop7 = nn.Dropout(p=0.2)\n",
    "        self.conv8 = nn.Conv3d(50, 1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    #note this method isn't called explicitly during train, \n",
    "    #rather the instance object is called as pytorch is then \n",
    "    #able to take care of other stuff in the background\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch1(self.conv1(x)))\n",
    "        x = F.relu(self.batch2(self.conv2(x)))\n",
    "        x = F.relu(self.batch3(self.conv3(x)))\n",
    "        x = F.relu(self.batch4(self.conv4(x)))\n",
    "        x = F.relu(self.batch5(self.conv5(x)))\n",
    "        x = F.relu(self.batch6(self.conv6(x)))\n",
    "        x = F.relu(self.batch7(self.conv7(x)))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use MSE loss\n",
    "criterion = nn.MSELoss() #returns the average over a mini-batch as opposed to the sum\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "validation_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   250] --- Losss = 1952.78291\n",
      "[1,   500] --- Losss = 1941.06679\n",
      "[1,   750] --- Losss = 1929.37950\n",
      "[1,  1000] --- Losss = 1931.62168\n",
      "[1,  1250] --- Losss = 1924.14871\n",
      "[1,  1500] --- Losss = 1931.71043\n",
      "[1,  1750] --- Losss = 1919.30603\n",
      "[1,  2000] --- Losss = 1917.80717\n",
      "[1,  2250] --- Losss = 1920.78886\n",
      "[1,  2500] --- Losss = 1928.36881\n",
      "[1,  2750] --- Losss = 1921.79971\n",
      "[1,  3000] --- Losss = 1920.61732\n",
      "[1,  3250] --- Losss = 1917.91849\n",
      "[1,  3500] --- Losss = 1915.09717\n",
      "[1,  3750] --- Losss = 1913.31565\n",
      "[1,  4000] --- Losss = 1913.63038\n",
      "[1,  4250] --- Losss = 1913.50615\n",
      "[1,  4500] --- Losss = 1911.27405\n",
      "[1,  4750] --- Losss = 1908.33897\n",
      "[1,  5000] --- Losss = 1906.10005\n",
      "[1,  5250] --- Losss = 1907.16088\n",
      "[1,  5500] --- Losss = 1905.98925\n",
      "[1,  5750] --- Losss = 1903.55940\n",
      "[1,  6000] --- Losss = 1902.73269\n",
      "Training loss iteration 1 = 1903.66666\n",
      "MSE on validation set: 1820.568556\n",
      "[2,   250] --- Losss = 1814.62519\n",
      "[2,   500] --- Losss = 1802.02121\n",
      "[2,   750] --- Losss = 1823.85540\n",
      "[2,  1000] --- Losss = 1812.10608\n",
      "[2,  1250] --- Losss = 1818.18962\n",
      "[2,  1500] --- Losss = 1826.50184\n",
      "[2,  1750] --- Losss = 1841.67322\n",
      "[2,  2000] --- Losss = 1838.18279\n",
      "[2,  2250] --- Losss = 1831.65126\n",
      "[2,  2500] --- Losss = 1841.00214\n",
      "[2,  2750] --- Losss = 1836.37575\n",
      "[2,  3000] --- Losss = 1835.72324\n",
      "[2,  3250] --- Losss = 1832.19002\n",
      "[2,  3500] --- Losss = 1830.90798\n",
      "[2,  3750] --- Losss = 1832.34772\n",
      "[2,  4000] --- Losss = 1830.43421\n",
      "[2,  4250] --- Losss = 1829.73099\n",
      "[2,  4500] --- Losss = 1829.34816\n",
      "[2,  4750] --- Losss = 1829.01132\n",
      "[2,  5000] --- Losss = 1828.96838\n",
      "[2,  5250] --- Losss = 1828.92626\n",
      "[2,  5500] --- Losss = 1828.95947\n",
      "[2,  5750] --- Losss = 1830.17091\n",
      "[2,  6000] --- Losss = 1828.98561\n",
      "Training loss iteration 2 = 1829.79268\n",
      "MSE on validation set: 1802.548089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1517:\n",
      "    r = index_queue.get()\n",
      "Process Process-1520:\n",
      "Process Process-1518:\n",
      "Process Process-1506:\n",
      "Process Process-1508:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-1514:\n",
      "Process Process-1509:\n",
      "Process Process-1505:\n",
      "Process Process-1512:\n",
      "Process Process-1507:\n",
      "Process Process-1510:\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process Process-1511:\n",
      "Process Process-1516:\n",
      "Process Process-1515:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-1513:\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "Process Process-1519:\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    r = index_queue.get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    racquire()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "    self.run()\n",
      "    racquire()\n",
      "    self.run()\n",
      "    racquire()\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    racquire()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    racquire()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "    racquire()\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "KeyboardInterrupt\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-00f66f6b35f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaliloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-9d2943ba6b6e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, valiloader, training_losses, validation_losses, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(trained_net, training_losses, validation_losses) = train(net, trainloader, valiloader, training_losses, validation_losses, optimizer, criterion, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac1b19810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_losses(training_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the test error - Random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "-----------------------------\n",
      "\n",
      "MSE on test data: 2108.063965\n",
      "Mean absolute loss on test data: 28.560207\n",
      "R2 loss on test data (Coefficient of determination): 0.943011\n"
     ]
    }
   ],
   "source": [
    "# Calculate the error between the predicted voxel values and target1 -- this is from registered scan 1 of the output\n",
    "\n",
    "# First convert the testing targets to numpy arrays\n",
    "testing_target1_nump = np.asarray(testing_target1)\n",
    "testing_target2_nump = np.asarray(testing_target2)\n",
    "\n",
    "# Get the predicted voxel values of the test set\n",
    "test_predictions = get_predictions(trained_net, testloader)\n",
    "\n",
    "print('-----------------------------')\n",
    "test_error_mse = ((test_predictions - testing_target1_nump) ** 2).mean()\n",
    "print('\\nMSE on test data: %f' % (test_error_mse))\n",
    "\n",
    "test_error_l1 = (np.absolute(test_predictions -  testing_target1_nump)).mean()\n",
    "print('Mean absolute loss on test data: %f' % (test_error_l1))\n",
    "\n",
    "test_error_r1 = 1 - (np.sum((testing_target1_nump - test_predictions) ** 2) / np.sum((testing_target1_nump - testing_target1_nump.mean()) ** 2))\n",
    "print('R2 loss on test data (Coefficient of determination): %f' % (test_error_r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "\n",
      "MSE between both sets of target data: 2645.457031\n",
      "Mean absolute loss between target data: 29.679708\n",
      "R2 loss between target data (Coefficient of determination): 0.928483\n"
     ]
    }
   ],
   "source": [
    "# Similarly calculate the errors between registered scan 1 and registered scan 2\n",
    "\n",
    "print('-----------------------------')\n",
    "target_error_mse = ((testing_target2_nump - testing_target1_nump) ** 2).mean()\n",
    "print('\\nMSE between both sets of target data: %f' % (target_error_mse))\n",
    "\n",
    "target_error_l1 = (np.absolute(testing_target2_nump -  testing_target1_nump)).mean()\n",
    "print('Mean absolute loss between target data: %f' % (target_error_l1))\n",
    "\n",
    "target_error_r1 = 1 - (np.sum((testing_target1_nump - testing_target2_nump) ** 2) / np.sum((testing_target1_nump - testing_target1_nump.mean()) ** 2))\n",
    "print('R2 loss between target data (Coefficient of determination): %f' % (target_error_r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the error on the final testing scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "750\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "final_test_predictions = get_predictions(trained_net, final_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y,z,v) = final_test_inp[0].shape\n",
    "final_predicted_brain = reconstruct_brain(final_test_predictions,[x,y,z,v])\n",
    "final_predicted_brain = replace_background(final_predicted_brain, final_test_inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 68, 50, 1)\n",
      "(55, 68, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print final_predicted_brain.shape\n",
    "print final_test_out1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on final predicted brain: 1698.143188\n",
      "Mean absolute loss on final predicted brain: 18.606682\n",
      "R2 loss on final predicted brain (Coefficient of determination): 0.960131\n"
     ]
    }
   ],
   "source": [
    "final_mse = ((final_predicted_brain - final_test_out1[0]) ** 2).mean()\n",
    "print('MSE on final predicted brain: %f' % (final_mse))\n",
    "\n",
    "final_l1 = (np.absolute(final_predicted_brain - final_test_out1[0])).mean()\n",
    "print('Mean absolute loss on final predicted brain: %f' % (final_l1))\n",
    "\n",
    "final_r1 = 1 - (np.sum((final_test_out1[0] - final_predicted_brain) ** 2) / np.sum((final_test_out1[0] - final_test_out1[0].mean()) ** 2))\n",
    "print('R2 loss on final predicted brain (Coefficient of determination): %f' % (final_r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between targets of brain: 789.372437\n",
      "Mean absolute loss between targets: 12.520751\n",
      "R2 loss between targets (Coefficient of determination): 0.981467\n"
     ]
    }
   ],
   "source": [
    "final_target_mse = ((final_test_out2[0] - final_test_out1[0]) ** 2).mean()\n",
    "print('MSE between targets of brain: %f' % (final_target_mse))\n",
    "\n",
    "final_target_l1 = (np.absolute(final_test_out2[0] - final_test_out1[0])).mean()\n",
    "print('Mean absolute loss between targets: %f' % (final_target_l1))\n",
    "\n",
    "final_target_r1 = 1 - (np.sum((final_test_out1[0] - final_test_out2[0]) ** 2) / np.sum((final_test_out1[0] - final_test_out1[0].mean()) ** 2))\n",
    "print('R2 loss between targets (Coefficient of determination): %f' % (final_target_r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b724eab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_pred(final_test_inp[0], final_predicted_brain, final_test_out1[0], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2150.0\n",
      "1605.78\n"
     ]
    }
   ],
   "source": [
    "print final_test_out1[0].max()\n",
    "print final_predicted_brain.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the target and the predicted scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to = \"/home/ubuntu/project/Dataset/EXP_AWS_1/TrueModel\"\n",
    "\n",
    "predicted_scan = nib.Nifti1Image(predicted_brain, affine_mat)\n",
    "nib.save(predicted_scan, save_to + \"/Predicted_Subj1Scan2_AWS.nii.gz\" )\n",
    "\n",
    "target_scan = nib.Nifti1Image(testing_data_out[0][:,:,:,0], affine_mat)\n",
    "nib.save(target_scan, save_to + \"/Target_Subj1Scan2_AWS.nii.gz\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_net.state_dict(), '/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/True_Model.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_net = Net()\n",
    "trained_net.cuda()\n",
    "trained_net.load_state_dict(torch.load('/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/True_Model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
