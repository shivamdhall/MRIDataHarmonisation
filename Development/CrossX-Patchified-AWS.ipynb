{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - CrossX - Patch - AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use both scans of subjects 1-8 from the PETMR and TRIO dataset for training.\n",
    "\n",
    "We used the scan of subjects 9-10 also from the PETMR and TRIO dataset for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function simply uploads the testing and training scans into lists of numpy arrays\n",
    "# The data is not yet sliced or patched at this stage\n",
    "\n",
    "# Specify in a list what scans to use for training and what scans to use for testing\n",
    "\n",
    "# This function only takes the first and last b=0 volumes\n",
    "\n",
    "def get_data(petmr_path, trio_path, scans_dict):\n",
    "    \n",
    "    train_data_inp = []\n",
    "    test_data_inp = []\n",
    "    train_data_out = []\n",
    "    test_data_out = []\n",
    "    paths = [petmr_path, trio_path]\n",
    "    \n",
    "    for data_path in paths:\n",
    "        if(data_path == petmr_path):\n",
    "            print \"Uploading Inputs:\"\n",
    "            training_data_store = train_data_inp\n",
    "            testing_data_store = test_data_inp\n",
    "        else:\n",
    "            print \"Uploading Outputs\"\n",
    "            training_data_store = train_data_out\n",
    "            testing_data_store = test_data_out\n",
    "        os.chdir(data_path)\n",
    "        for key, subjs in scans_dict.iteritems():\n",
    "            for subj_scan in subjs:\n",
    "                scan_image = nib.load(str(data_path) + \"/Subj\" + subj_scan + \"/Brain_Thresholded.nii.gz\")\n",
    "                scan_data = scan_image.get_data()\n",
    "                #all scans have the same affine mat because registration has already been performed\n",
    "                #we only need it for saving the predictions as a NIfTI file\n",
    "                affine_mat = scan_image.affine\n",
    "                #get b=0 volumes only\n",
    "                bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/Subj\" + subj_scan + \"/NODDI.bval\",\\\n",
    "                                                          str(data_path) + \"/Subj\" + subj_scan + \"/NODDI.bvec\")\n",
    "                #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "                gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "                s0s_scan = scan_data[:, :, :, gtab_scan.b0s_mask]\n",
    "            \n",
    "                if(key == \"training\"):\n",
    "                    print (\"Training: Subj%s\" % subj_scan)\n",
    "                    #append this data to the list containing the training data\n",
    "                    training_data_store.append(s0s_scan[:,:,:,[0,-1]])\n",
    "                else:\n",
    "                    print (\"Testing: Subj%s\" % subj_scan)\n",
    "                    testing_data_store.append(s0s_scan[:,:,:,[0,-1]])\n",
    "    return (train_data_inp, train_data_out, test_data_inp, test_data_out, affine_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "\n",
    "def patchify(data_scans_inp, data_scans_out, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan = data_scans_out[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel = target_scan[pos_x,pos_y,pos_z,volume]\n",
    "\n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store.append(target_voxel)\n",
    "                    \n",
    "    return (input_patches_store, target_patches_store)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "#This version of the functions only considers voxels wholly contained within the brain\n",
    "\n",
    "def patchify_brain_only(data_scans_inp, data_scans_out, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan = data_scans_out[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "        #use unpadded scan (original input scan) to identify non-backround voxels\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        # Exclude all background voxels\n",
    "                        if(input_scan[pos_x,pos_y,pos_z,volume] == 0):\n",
    "                            continue\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel = target_scan[pos_x,pos_y,pos_z,volume]\n",
    "                        # Exclude all patches that contain artefacts\n",
    "                        if input_patch.min() < 0:\n",
    "                            continue\n",
    "                            \n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store.append(target_voxel)\n",
    "                    \n",
    "    return (input_patches_store, target_patches_store)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(dataset, mean=None, std=None):\n",
    "    data_array = np.array(dataset)\n",
    "    if mean==None and std==None:\n",
    "        #This is the training data\n",
    "        mean = np.mean(data_array)\n",
    "        std = np.std(data_array)\n",
    "    #normalise the data\n",
    "    data_array = (data_array - mean)/std\n",
    "    return (data_array, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_pred(inputs, predictions, labels, sliceNo):\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1).set_axis_off()\n",
    "    plt.imshow(inputs[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2).set_axis_off()\n",
    "    plt.imshow(predictions[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.subplot(1, 3, 3).set_axis_off()\n",
    "    plt.imshow(labels[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Inputs:\n",
      "Training: Subj1Scan1\n",
      "Testing: Subj1Scan2\n",
      "Uploading Outputs\n",
      "Training: Subj1Scan1\n",
      "Testing: Subj1Scan2\n",
      "Number of scans used for training input: 1\n",
      "Number of scans used for training output: 1\n",
      "Number of scans used for testing input: 1\n",
      "Number of scans used for testing output: 1\n"
     ]
    }
   ],
   "source": [
    "#upload the data\n",
    "petmr_data_path = '/home/ubuntu/project/Dataset/PETMR_data'\n",
    "trio_data_path = '/home/ubuntu/project/Dataset/TRIO_data'\n",
    "\n",
    "training_scans = [\"1Scan1\"]\n",
    "\n",
    "\n",
    "testing_scans = [\"1Scan2\"]\n",
    "\n",
    "(training_data_inp, training_data_out, testing_data_inp, testing_data_out, affine_mat) = \\\n",
    "        get_data(petmr_data_path, trio_data_path, {\"training\":training_scans, \"testing\":testing_scans})\n",
    "\n",
    "print (\"Number of scans used for training input: %d\" % len(training_data_inp))\n",
    "print (\"Number of scans used for training output: %d\" % len(training_data_out))\n",
    "print (\"Number of scans used for testing input: %d\" % len(testing_data_inp))\n",
    "print (\"Number of scans used for testing output: %d\" % len(testing_data_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patchify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchifying training set\n",
      "Patchifying testing set\n"
     ]
    }
   ],
   "source": [
    "print \"Patchifying training set\"\n",
    "(training_input, training_target) = patchify_brain_only(training_data_inp, training_data_out, 9)\n",
    "\n",
    "print \"Patchifying testing set\"\n",
    "(testing_input, testing_target) = patchify(testing_data_inp, testing_data_out, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nember of training examples : 104054\n",
      "Nember of testing examples : 257600\n"
     ]
    }
   ],
   "source": [
    "print (\"Nember of training examples : %d\" % len(training_input))\n",
    "print (\"Nember of testing examples : %d\" % len(testing_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset class for our data\n",
    "\n",
    "class MRIdataset(Dataset):\n",
    "    \"\"\"MRI b=0 dataset for patches.\"\"\"\n",
    "\n",
    "    def __init__(self, input_patches, target_patches, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_patches: Input patches\n",
    "            target_patches: Corresponding target patches of the input patches\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        \"\"\"\n",
    "        self.input_patches = input_patches\n",
    "        self.target_patches = target_patches\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_patch = np.array(self.input_patches[idx])\n",
    "        target_patch = np.array(self.target_patches[idx])\n",
    "        sample = {'input': input_patch, 'target': target_patch}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class To_Tensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inp, out = sample['input'], sample['target']\n",
    "        \n",
    "        #first expand dimension because torch expects H x W x D x C\n",
    "        #currently we only have H x W x D\n",
    "        aug_inp = np.expand_dims(inp, 3)\n",
    "        \n",
    "        #The target is a single voxel,\n",
    "        #Conver it to an array\n",
    "        aug_out = np.array([out])\n",
    "\n",
    "        # swap channel axis because\n",
    "        # numpy: H x W x D x C\n",
    "        # torch: C x D x H x W\n",
    "        aug_inp = aug_inp.transpose((3, 2, 0, 1))\n",
    "        \n",
    "        return {'input': torch.Tensor(aug_inp),\n",
    "                'target': torch.Tensor(aug_out)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, training_dataset, trainloader, losses_list, optimizer, criterion, epochs):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): #done in batches\n",
    "            # get the inputs\n",
    "            inputs = data['input']\n",
    "            labels = data['target']\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize/update weights\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0] #loss is a variable tensor of size 1, we index to get the value out\n",
    "            if i % 250 == 249:    # print every 250 mini-batches\n",
    "                print('[%d, %d] Loss = %.5f' % (epoch + 1, i + 1, running_loss/i))\n",
    "        total_loss = running_loss / i\n",
    "        losses_list.append(total_loss)\n",
    "        print('Loss iteration %d = %.5f' % (epoch+1, total_loss ))\n",
    "        '''   \n",
    "        test_error = 0\n",
    "        total = 0\n",
    "        for test_data in testloader: #batch processing\n",
    "            test_inputs = test_data['inp']\n",
    "            test_labels = test_data['out']\n",
    "            total += len(test_labels)\n",
    "\n",
    "            test_outputs = net(Variable(test_inputs))\n",
    "\n",
    "            test_error += (torch.nn.functional.mse_loss(test_outputs.data, test_labels, size_average=False)).data[0]\n",
    "\n",
    "        test_error /= total\n",
    "        print('MSE on test data: %f' % (test_error))\n",
    "        Adam_acc.append(test_error)\n",
    "        '''\n",
    "    print('Finished Training')\n",
    "    return (net, losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_losses(losses_list):\n",
    "    plt.figure\n",
    "    plt.plot(range(1,len(losses_list)+1), losses_list, 'r-')\n",
    "    plt.xlabel('iteration')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    " def testing_error(net, testloader, loss_type=\"MSE\"):\n",
    "    net.eval()\n",
    "    test_error = 0\n",
    "    total = 0\n",
    "    for test_data in testloader: #batch processing\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        total += 1\n",
    "\n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "        \n",
    "        test_predictions = net(test_inputs)\n",
    "        \n",
    "        if(loss_type == \"MSE\"):\n",
    "            #Use MSE loss\n",
    "            test_error += (torch.nn.functional.mse_loss( Variable(test_predictions.data), test_labels)).data[0]\n",
    "        else:\n",
    "            test_error += (torch.nn.functional.l1_loss(Variable(test_predictions.data), test_labels)).data[0]\n",
    "        \n",
    "    test_error /= total\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(net, testloader):\n",
    "    net.eval()\n",
    "    for index, test_data in enumerate(testloader):\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        if index % 250 == 249:\n",
    "            print index + 1\n",
    "        \n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "\n",
    "        #store the predictions in a numpy array which we can reshape later\n",
    "        test_predictions = net(test_inputs)\n",
    "        if(index == 0):\n",
    "            predictions = test_predictions.data.cpu().numpy() \n",
    "\n",
    "        else:\n",
    "            predictions = np.concatenate((predictions, test_predictions.data.cpu().numpy()), axis=0)\n",
    "            \n",
    "    #convert back to numpy dimensions of (HxWxDxCxNumbExpls)\n",
    "    predictions = predictions.transpose(3,4,2,1,0)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_brain(predictions, dimensions):\n",
    "    \n",
    "    size_x = dimensions[0]\n",
    "    size_y = dimensions[1]\n",
    "    size_z = dimensions[2]\n",
    "    size_v = dimensions[3]\n",
    "    #assume we have given it a single scan to reconstruct\n",
    "    reconstructed = np.reshape(predictions, [size_v, size_x, size_y, size_z], order='C')\n",
    "    reconstructed = reconstructed.transpose(1,2,3,0)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data using pytorch data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MRIdataset(training_input, training_target, transform=transforms.Compose([To_Tensor()]))\n",
    "testing_dataset = MRIdataset(testing_input, testing_target, transform=transforms.Compose([To_Tensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_dataset, batch_size=160,\n",
    "                        shuffle=True, num_workers=8)\n",
    "testloader = DataLoader(testing_dataset, batch_size=160,\n",
    "                        shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Relu\n",
    "\n",
    "--(WxHx2x1)--\n",
    "\n",
    "conv1 = receptive field -> (3x3x3), zero padding -> 2,  number of filters -> 10\n",
    "\n",
    "--(W+2xH+2x4x10)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv2 = receptive field -> (1x1x1), number of filters -> 15\n",
    "\n",
    "--(W+2xH+2x4x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv3 = receptive field -> (3x3x3), number of filters -> 15\n",
    "\n",
    "--(WxHx2x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv4 = receptive field -> (1x1x2), number of filters -> 1\n",
    "\n",
    "--(WxHx1x1)--\n",
    "\n",
    "--RELU--\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv3d (1, 50, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (conv2): Conv3d (50, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop2): Dropout(p=0.2)\n",
      "  (conv3): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop3): Dropout(p=0.2)\n",
      "  (conv4): Conv3d (100, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch4): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop4): Dropout(p=0.2)\n",
      "  (conv5): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch5): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop5): Dropout(p=0.2)\n",
      "  (conv6): Conv3d (100, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch6): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop6): Dropout(p=0.2)\n",
      "  (conv7): Conv3d (50, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 50, 3)\n",
    "        self.batch1 = nn.BatchNorm2d(50)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = nn.Conv3d(50, 100, 1)\n",
    "        self.batch2 = nn.BatchNorm2d(100)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.conv3 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch3 = nn.BatchNorm2d(100)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.conv4 = nn.Conv3d(100, 100, 1)\n",
    "        self.batch4 = nn.BatchNorm2d(100)\n",
    "        self.drop4 = nn.Dropout(p=0.2)\n",
    "        self.conv5 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch5 = nn.BatchNorm2d(100)\n",
    "        self.drop5 = nn.Dropout(p=0.2)\n",
    "        self.conv6 = nn.Conv3d(100, 50, 1)\n",
    "        self.batch6 = nn.BatchNorm2d(50)\n",
    "        self.drop6 = nn.Dropout(p=0.2)\n",
    "        self.conv7 = nn.Conv3d(50, 1, 3)\n",
    "        \n",
    "        \n",
    "\n",
    "    #note this method isn't called explicitly during train, \n",
    "    #rather the instance object is called as pytorch is then \n",
    "    #able to take care of other stuff in the background\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch1(self.conv1(x)))\n",
    "        x = F.relu(self.batch2(self.conv2(x)))\n",
    "        x = F.relu(self.batch3(self.conv3(x)))\n",
    "        x = F.relu(self.batch4(self.conv4(x)))\n",
    "        x = F.relu(self.batch5(self.conv5(x)))\n",
    "        x = F.relu(self.batch6(self.conv6(x)))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use MSE loss\n",
    "criterion = nn.MSELoss() #returns the average over a mini-batch as opposed to the sum\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 250] Loss = 63626.97413\n",
      "[1, 500] Loss = 36364.67927\n",
      "Loss iteration 1 = 29320.49520\n",
      "[2, 250] Loss = 5243.78701\n",
      "[2, 500] Loss = 4930.42911\n",
      "Loss iteration 2 = 4789.80924\n",
      "[3, 250] Loss = 4038.05435\n",
      "[3, 500] Loss = 3866.42134\n",
      "Loss iteration 3 = 3778.55653\n",
      "[4, 250] Loss = 3289.79532\n",
      "[4, 500] Loss = 3194.71522\n"
     ]
    }
   ],
   "source": [
    "(trained_net, adam_losses) = train(net, training_dataset, trainloader, losses, optimizer, criterion, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83c87b6890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_losses(adam_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test data: 7601.817525\n",
      "Mean error per voxel : 87.188402\n",
      "\n",
      "L1 loss on test data: 38.735781\n"
     ]
    }
   ],
   "source": [
    "test_error_MSE = testing_error(trained_net, testloader, \"MSE\")\n",
    "print('MSE on test data: %f' % (test_error_MSE))\n",
    "print (\"Mean error per voxel : %f\\n\" % \\\n",
    "       (np.sqrt(test_error_MSE)))\n",
    "\n",
    "test_error_L1 = testing_error(trained_net, testloader, \"L1\")\n",
    "print('L1 loss on test data: %f' % (test_error_L1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store predictions in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(net, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y,z,v) = testing_data_inp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_brain = reconstruct_brain(predictions,[x,y,z,v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 56, 46, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_brain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAADnCAYAAAA6hdOiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJztnXuwZlV55p/V3hCRO0jfoKFbGhrobmhuBm2ggJGLBAiTjErIWBRiOTVJzJixJlNxRiUZKilTmilSsWISccygTFTUaACBoBHk2kjTzaWFpulurk0rF1Hjrff8cb5e/tbLWctD73M/z6+K4v3Ot/f+1t57rb1Xv8/7vit1XSdjjDHGGLNjzJroBhhjjDHGTGU8mTLGGGOM6YEnU8YYY4wxPfBkyhhjjDGmB55MGWOMMcb0wJMpY4wxxpgeeDJljJlSpJQWpJS6lNIrB5+vSSn9x3H43Q+llP5hrH/HGDP18GRqgkgpPZpSOnWMf8MPfzNhDPr4j1NKL6aUnk4pfSqltMto/07XdWd0XffpEbZnTMecMTvKYJxs/28bxs6LKaULxrktOw3+wTJvPH93KuPJlDFmLDm767pdJB0l6RhJf8wv0xB+DpkZT9d1u2z/T9ImDcbO4L//+3KOtd1ra8YPP8QmmJTSu1JKN6eUPppSejaltCGldAa+/0ZK6bKU0h0ppedTSl9OKe05+O6klNJj4XiPppROTSmdLum/S/oPg3/ZrB7fMzPml3Rd97ikayQdPujTf5pSukXSjyQdlFLaLaX0dymlJ1NKj6eU/iSl9ApJSim9YjA+tqaUHpF0Fo89ON7F+PzulNIDKaUfpJTuTykdlVL6jKT9Jf3TYDx8YLDt8Smlb6eUnksprU4pnYTjHJhS+ubgONdL2nuML5MxVVJKJ6SUbh+8B55IKX0MUvd2T9J7U0rrJa0d/P2slNJDg/798ZTSbSml38Yx35NSWpdS+n5K6WsppbmDr/518P91g/Fy7rie7BTEk6nJwXGS1mnoYf3nkv4upZTw/e9IukjSHEk/l/S/f9UBu667VtL/knTV4F82y0a91caMkJTSfElnSvrO4E8XSrpE0uslbZT0aQ317UWSjpT07yRtnyC9W9LbBn8/WtK/b/zOb0r6kIbGzK6Sfl3S97quu1Dlv/b/fPDi+JqkP5G0p6Q/lPSFlNI+g8NdKWmVhsblpZLGPC7LmAY/k/SfNdRX3yLpbP1yjGznbZJWSDoypbSfpKsk/YGkfSQ9MfhOkpRSeruk9w2O8wYNjc3tYSErB/9fPBgvXxqLE5pOeDI1OdjYdd0nu677hYZeKrM11Lm385mu69Z2XfdDSR+U9Fvb/9VuzCTnSyml5yTdLOmbGprgS9IVXdfd13XdzzX0cjhD0vu6rvth13VbJH1M0tsH2/6WpI93Xbe567rvS7qs8XsXS/rzruvu7IZ4uOu6jZVtf1vSP3dd989d123ruu56SXdJOjOltL+GZMkPdl33k67r/lXSP+3wVTCmJ13X3THo17/oum69pL+VdGLY7E+7rnuu67ofa+gfEnd2XffVrut+Jumjkp7Ftu+R9Cdd13138P2HJb05pfQGmZeNddXJwVPbja7rfjRwSjFQdzPsjZJeJUsOZmpwbtd1N/APg/7NPn2Ahvr0k3DIzsI2c/TSMVBjvqT1I2zbAZJ+M6V0Nv72Kkk3DX7z2cE/YPi780d4bGNGlZTSEkl/oaH4w9dq6P19S9iM46QYN13XbUspPY7vD5D0iZTSX+FvP5c0T9Lzo9j0GYEnU1MDPsD315C7d6ukH0raefsXA2/VPti2G5fWGfPyYd/cLOknkvYeeKoiT+qlY6DGZkkLR/Cb27f9TNd1744bppQOkLRHSul1mFDtP8wxjBkvPinpG5J+s+u6F1NK/01SzE5l/3xSv5TrNEj0mIvvN0v6r13XfSH+UErpNaPV6JmCZb6pwW+nlJaklHaW9BFJnx9Igt+VtNMgyPBVGsqU4iB4WtICZ0uZyUzXdU9K+rqkv0gp7ZpSmpVSWphS2i5h/D9Jv5dSmpdS2kPSf2sc7m8l/WFKacUgU3DRYGIkDY2Hg7DtP0g6O6X01kGQ+06DpI55A2nwLkkfTim9OqX0Zg3FlhgzUbxe0vODidRhGoolbPEVScellM4cBKr/F0l74PtPSPrjlNJiSUop7ZFSOl+Suq77iYa8UwfJjAi/ZKcGn5F0hYbkwJ0k/Z4kdV33vKT/pKEXyOMa8lQxu+8fB///Xkrp7vFqrDE7wO9IerWk+zUU1/F5DcUOSkP/Ir9O0mpJd0v6Yu0gXdf9o6Q/1VDw+A8kfUlDMVnSUKzVHw8ym/6w67rNks7RUNbrMxr8S12/fC6+U0PJId+X9D8l/Z/ROFFjdpA/kHRxSulFSX+loeDyKoN/pLxDQwlLWzUk363RkBdYXdd9VtLlkr6YUnpB0j2STsMh/oekfxyMl18f5XOZdqSus9d6MpNS+oakf+i67m8nui3GGGOmJgPv1FMaymi9daLbM92wZ8oYY4yZhqSUzhjUcNtJQ97VH2mo3IcZZTyZMsYYY6YnKyVtkLRF0imSzuu67qcT26TpiWU+Y4wxxpge2DNljDHGGNMDT6aMMcYYY3owrkU7U0rWFM2kouu69Ku3Gjs8JsxkY6LHxKxZszwmzKRi27Ztv3JM2DNljDHGGNMDT6aMMcYYY3rgyZQxxhhjTA88mTLGGGOM6YEnU8YYY4wxPfBkyhhjjDGmB55MGWOMMcb0wJMpY4wxxpgeeDJljDHGGNMDT6aMMcYYY3rgyZQxxhhjTA88mTLGGGOM6YEnU8YYY4wxPfBkyhhjjDGmB55MGWOMMcb0wJMpY4wxxpgeeDJljDHGGNMDT6aMMcYYY3rgyZQxxhhjTA88mTLGGGOM6YEnU8YYY4wxPfBkyhhjjDGmB55MGWOMMcb0wJMpY4wxxpgeeDJljDHGGNMDT6aMMcYYY3rgyZQxxhhjTA88mTLGGGOM6YEnU8YYY4wxPfBkyhhjjDGmB55MGWOMMcb0wJMpY4wxxpgeeDJljDHGGNMDT6aMMcYYY3rgyZQxxhhjTA9eOdENMBPDq171qmy/+tWvLr7bdddds73bbrtl++CDD872V77ylTFsnTETyx577FF8fv3rX5/t+fPnZ/vII4/M9uWXXz72DTNmHNl5552z/brXva747jWveU22X/GKV2R79913z/bq1avHsHWTC3umjDHGGGN64MmUMcYYY0wPUtd14/djKY3fj80gXvnKX6q1KaXqdrzXs2b9ch5NyU+SZs+ene1ly5Zle8mSJdk+6aSTin02bNiQ7YsvvngErZ4cdF1Xv2DjgMfE5IFjh/K2JO23337ZPvfcc7PNMUH5T5IeeuihbF9yySWj1s6xZqLHxKxZszwmxgA+81vvCUp2tFvhIHvuuWe2Fy1alO0VK1YU+2zZsiXbH//4x0fS7EnBtm3bfuWYsGfKGGOMMaYHnkwZY4wxxvTAkyljjDHGmB64NMI4sddee2X7xRdfzHaMWdu2bVv1uxrUwmtxUZL0i1/8ItvUzJniKpWaN23CeBBJWrduXbZPOeWUbN94443NtpuZy5w5c7L99NNPZ5v9dDzh2Pn5z39efHfMMcdkm6nfDzzwQLY3btxY7PP9738/2+edd162r7766v6NNdMSxubxPfGTn/yk2K72nojPfDLS9wm341iMsbWMmZo7d262582bV23PE088ke03velN2b711ltH1LbJjD1TxhhjjDE98GTKGGOMMaYHLo0wAk499dRsR/c/XZ+77LJLtp977rliO8pgdP9HSYP3gzZlObp4pXpphJj+yra/9rWvzXas9szUb7qd77333uqxf/zjH2f72WefzTZd1ZK0atUqTSYmOg18qo4Jylb/9m//VnzHz6yazLRoSdq6dWu2OSbi2Bkv2NYFCxYU311wwQXDbnfXXXdl+/nnny/2YVr5T3/602xHyeaGG27YsQaPERM9JqZqaQSWkYnPaJYVoM1+IUmbN2/ONsdRfO/wc+0dHttQg/00whCQWC6EK2KwnM7PfvazbPO9IJXnxPES34OT7T3h0gjGGGOMMWOMJ1PGGGOMMT1wNh847LDDsr3TTjtlm7JVhBkN3IcLo0qlFEdGWrG8Jd9xO7p2o/uWmRX8LmZcsJIzJQ26ZX/0ox8V+/A7Hi+6mpcvX57te+65R2ZyERcz5ZigNEw5IvbtWt9qydOtv0eJYzThWOLvcixLpZy/9957D7vdY489VuxD6aIluSxdujTblNLN5ITyFvsP+2l8pvIzZd7Y1/mZx4vPcn5X61ut9wSJ+7Ovc8zHrG9m8LF9mzZtynaU79hufhdDBfjcue+++4Zt92TDniljjDHGmB54MmWMMcYY0wNPpowxxhhjejDjYqYOOeSQbLeqxVLDpbYbV85mGijLAMRjj7R8AXVt6tCtfWpxUq3zY7ujHs+2Mn2dx4txLEzx5TWKOj0/H3744dleu3Ztta1mbFm5cmW2Y9o+PzNOrna/pbLaP8dOjMeKaeG14/WNmWJ/jvEh7NM//OEPs83xIZWlG2jzmuy8887FPhw7vA5xvDFGxWNicnDsscdmm/1CqlfKb8VMsa9zu/gsZ4wS+1nsW7Wxw74VK5aTVkkk9tXa+yi2qRbfFdvJ2FqOyxgzxeu3cOHCbK9fv77a7onGniljjDHGmB54MmWMMcYY04MZIfOdeOKJ2abrPUoaTP2sLbbakthYQiFWFadLtJYSLpXyAn+rtpixVLpYKaW05BH+Tizj8OSTT2Z7zZo12aa7O7ah5rKNrmF+5rVbsWJFsd1kq4A73WAF8w0bNmQ73tda6jclhJgyzXHFfhv7GccE+0Uce5Q+agu8tkoPsHxBa2Fx/i5/UyqfG88880y2OY5iuRBeh1aaO3+X4+jXfu3Xiu2+/e1vy4wdp59+erb5LI/PUd6/WvXw2B+jbFw7NquM10IspLJPs59RIo/vqto7LY4Jjm0eO8qGlOwoSfLco3xX+641LglLJkiTq2yCPVPGGGOMMT3wZMoYY4wxpgczQuarLagYXax0kdLd3sqQ4Ha1jA2prJQeZRFSc8Vyn3hstoHnENtKty8liVjtmRkTlPy4Xct9S6L7lteoVuHdjD0/+MEPss0+E/tWLRuPMliUraNENtzvSPUFjVvZbuwntb4U28TfjeOrJqvH7Cler1oGbxwTNRkytrWW6dd6TpjRh1IVx0Hst7xf7Ju1Z7dUl6rjPjwex1tcMH6XXXbJNiXA2lhptS9KiGwfFyqO7wnK3U899VS22YfjmGCbWgsss62trPTJxNRopTHGGGPMJMWTKWOMMcaYHkxLmS9G/FNOaLkW6d6suVFjlh6zL55++ulsx2JldPO2XMN07deyoloLGPN4sa0vvPBCtlvuVmaR1IrSRTmIbaA7OGax1DIMo/RxyimnZPvGG28cdh8zcs4444zicy0jLfZHymUcE5TBuPCvVPZ1ymPR5V+Tz2NWHL/jGOVYiTLzSBf/5jjgdYj9tibntcZELUuvVnCxtY8kvfWtb832ddddVz2GGRnHHXdc8TlKaduJz6Zav2W/f8Mb3lDsw0xWhk7wWSvV+3ccE+wbUZKuwWc07djPOGbZhrgd36tsdyuLvBbO0crGrS1GLknLli3L9urVq6vHGA/smTLGGGOM6YEnU8YYY4wxPfBkyhhjjDGmB9MyZipWNmf8Q0srZqwP01K5z4IFC4p9WPKAaaTf+973iu1qFaNj2ifTcJlu2iojwO+on++5557FdrXYsVhCgTEhtRTzGPfB8+C1i4uE8t6w3TFWp+/itqYk3gdeX46PmAbOvsrveI9jCn+tanpsA/vM7rvvPqwtlTFZjGupLbwslf2WYzSOCcavMKYwxslwbDO+g8+MVkmHVrX22gK5/E3JpRJGm9hneB/Yf+J7ovYs53axn7HsAp+B8V1ViymKMVi152NrJYFazFQ8Fp8HjJNslbmpxRjHPszz5fWKMYq1VULi+3IylU2YPC0xxhhjjJmCeDJljDHGGNODFF13Y/pjKY3Zjy1fvjzbdNdLpbuTbvnoUqUrlWmulL3mzp1bPfYTTzyR7ehCri1AOWfOnGI7psree++9Go7oAuXxKIkcffTRxXZctJjyRpQuKaXUpJiYRkz3Ms+VC4ZK5bXkNYpSI93GPPYdd9yh0aTrugktvT6WY+L888/P9ubNm4vvamng8T6wf1Iu472L8h3HH+9dfNbwHjN1PI4xHoPHpswXpQrKL4sXL872XnvtVWzHMXbPPfcM+5sRjvnWigM1ySWGANRKJfB6S6W0yt+69tprq23dESZ6TMyaNWvMxgTLIdTGgNSWoFhyhveY28VnNO85+2qU4mqrDBxyyCHFdhs3bsw2x3ar7EatCj/HoVRKcXxfxv7I8cdjcOzFa8d9eO24SkmE2/H6SOX44zmN9nti27Ztv3JM2DNljDHGGNMDT6aMMcYYY3owbbL5mDUQI/yZ4daq1FqrJEupilkZUummpR1donQNH3HEEdk+5phjiu1uvfXWbLOiOt36MduJbtATTjgh2yeddFKx3TXXXJPtm2++Odsxo4Tu75FmVdC1S3drK8uK1z9mfRAvgrxj8D62FvUm8X7Trc4MpUcffTTbW7ZsKfahlMu+EPstVw9YuHBhtuNCybWMO0oQ++67b7EP+0wtA1Aqz49toIwSf5d9mv0+yiV8BnCMthaWpSwSF4LmeUS5w4wMVvduyc58lkepiv2O44pSVdyndo9jX2d/Ovjgg7N94IEHFttRFue42rBhw7C/KZV9/8QTT8z20qVLi+34bqCEGPstz722EHh8dnMc8FkTZfXaezW+T/hebEnz44E9U8YYY4wxPfBkyhhjjDGmB55MGWOMMcb0YNrETFGnjbFP1MJrK11LpSZM/ZW6b0xr5jH4u1Ffnj9/fra50nVsA+NIDjrooGxTW2cZCKmMfznzzDOzzQrqUhnzcsABB2Q7xofwfKmF11JhpXocQTw/6uStVdH5mdudfPLJ2b7ppptk6jDGhjEWUtlXGesRU7U5DhgLRTuWIiEcB/HY7EPsj5s2bSq2Y3wW+zT73H777Vfsw1gKxh7GWEb2R/bV2G8Zq8Hryli/GIPDccm2tlY94HMslpzgdmz3eeedl+2rr75apg6fTbGUBePQGCcb+y3vc638Rew/rTgiwuc/n/nr168vtmO/mzdvXrYZ9xfbzTbwXRDjKRlDxXhFjvkI4255vBjHxOfOjpRlim3gMVj25Nxzz832l770pZf9OzuCPVPGGGOMMT3wZMoYY4wxpgfTRuZruej5uZU+STdorfJrTFemu5XHjimvrK5OWYRpqFKZZk53MNsQU8zp8r/qqquyvW7dumI7tolu3tbCq5SAeK4xhb62gHGE+1HuiPvUFt+NpSlMHcpEUZblZ0pYsURFbaFiSiRxUVe64imdRPmdnyk133333cV2lP0o+VJuoxQolX2afYYySoRSfDwnHo/nRzma5U+ksn9TLo9jh88NXu9YoZtt4PWPoQdmx6hJVfF+1RZBZl+P9662UH2UfHk8roYRZT62j/2bJRTiwtjf/e53s83neiyzwb7Fd0Zr1Qu2p7WoN+F3UfqsldBpLYjM+/f4449Xf3essGfKGGOMMaYHnkwZY4wxxvRgSst8dMuTmMXAz8xqipIGXZ+U+fg70SX6zDPPZJtyVFw8mFLKDTfckO0HHnig2I5t2meffbJNWea+++4r9qGEcOedd6oGj8Gsv+OPP77Y7l/+5V+yzawW2lEupWuX0keU72oyX3SlU0rh/WtVSjflgqh0icfrxj5Tq4YulfeSi2gzIzXy2GOPZbuWISuVssEjjzyS7ZakwX7CvhUlCG5XW2Q8HpsywWGHHVZsx2cAq0IzuzDKKpRI+GyJY4KSItsdQwr4DKHNBdbNS+FC161MM15T9ttWxXraXBQ8Sq+1LPLW2KtV/pfKfsxsVUrxccyzb3G72FYemytqxP5N+X2kK2XUsh8jtXCcmHlIOH5bmYdjhT1TxhhjjDE98GTKGGOMMaYHU1rmo4u05TJklg0z4WJRS0oFdKvSDc/FJ6VSiiMsQiiVGReU9qIrli7W2qKnUdLgd3RvRrcsJUlKdkuWLCm2qy10zGyQmFVBWhl3dPvy/sUCepSXaq7dRYsWFZ8ffvjh6u/ORFqSKK/p7Nmzs005SiqlD/YfSsZR0mbfqMloUtnP+LutRU/Zv1uZuZTS2OdaC6VyH2bfSuUz4LTTTss25ck4JvhdfNYQZjXynFoyFGUajvP4POI9m6nUsotbRZt5T+J2lMgp5TIEhAUkpbIPcxzEYrN8JnJ8RLmM8F3VyriuFZiNWbZsK98thx56aPV3aXPMx3dQbby14DGifMff4nccKyxkKr00jGC0sGfKGGOMMaYHnkwZY4wxxvTAkyljjDHGmB5M6Zgp6tWMsYmxGdSEW4tMUptlTBG1XS4+LElz587NNvXgGOfD2AVqu63qutyO2nU8di2mKMYhMc7iwQcfzPbtt99ebMd4EcaHsLpujItieja/ay103IqZIrX4rFbMzEylVbmZMC6C/TvGFDHOgjbvcbw/jNthKZJYlZjlR0grlqVVUZnUYihbpRE4xm655ZZiu8MPPzzbPD/GG8b+yOcJx0eMeeT5Me4mHo/nzn34vGvd85kKr0mt38fteH1blejZf/jOiCsOEMbwxoW3+cznsWPMVK3kCPtCHJd83nKf1moWPKd4HRh/zPa0VgXgc56xZ61SBtwnlpLg86p2X2rPmdHGniljjDHGmB54MmWMMcYY04Mp7ROuLagY3eN0O7JabNyOkgRdnXQNR/mAx6CrM8pWrcq7pHZOLTcoXZ8tlybduZRpbrzxxmK7lStXZpsp4Uz3jSnYbAMrYNOVG+G1jNeLn7ndSGWsmQrlBfb7CCU7joko8/F61yo3x0rdlN9r9y62oVUJuibzUcaI8l2tun5L5uexufCyVKZ+87qyBEoce5RF9t9//2yzgrpUyu88p1b/rskYres4U+E9r0ml8Ts+b+Ozl/elVkYmjiPKt7xHHCtSOV5a8nZN7q6tEBA/s/+03mns9wwNie2rLd4crzFDbmpStVReP/bveC+4XU0WHa8xYc+UMcYYY0wPPJkyxhhjjOnBlNJJuIirVMoELfln69at2aZbdt68ecV2dEHutttu2abUFd2yrGxMd2lsK49BOTFmSNDdSXcr3Znx/KJLeTtRVqHrk99FSYOVznm+NVsq5TxW9Y0VcCkptRatbFW93U6rKvBM4aijjio+sw/SRR+zi+g654KqMbuoln1ZW5xXKsclK5vHiuy8/xwTUS7j/aecwPExUvmutfAqjxGlAUok999/f7Z5vWPmEheQpXwXxw5lPkqI8bqyrbUM17gQ+0zkiCOOKD7XJK2WzMd+G+8Dn001uS2GLfDe8X5HmCHHexmf8fxd9k2eX2xbLWM6jjeOUx4jjt9atX4eL0qIcYWF7cR7wfPle7klpXPM8p7FCu9jhd9GxhhjjDE98GTKGGOMMaYHnkwZY4wxxvRgSsVMtVZRb8VMMJ6nVU2Vx2dMCKucxxROxqVQD44xKoxF4XetVE/q1bTjudZipqIOXas4zngVqSxtwNgMxkLF82McALX+GG/Aa8R4sxhbVTtftjvGnqxYsSLbq1at0kwgxgMw7Z73P15fxjLwXjKFXyrvK+MVeLwYx1BLHW+lmDNGMfYt7lcrh9CqoM/rEK8X96Mdt6utSM+4qDgu+WzgPrV4J6m8L3HssH2MX+FzK44JVm5fu3Zt9XenEzFWiNee8UXx+jJerRULx75fi4WL7ypuxxguxpBK0uzZs7PNlShinFWtZEktplCqx4vFWCiOv1bcFo/PNvB6xX34/G+tZsD2teKFCa/J3nvvXd1u8eLF2V63bl11u5eLPVPGGGOMMT3wZMoYY4wxpgdTSuZrpZTSLRhlB7otWcU7yls12aCVpk8XJG2WF5CkBQsWZJuLo27atKnY7qGHHhq2PXRvttJDa1VppfJ86b6NkgZlUbq+W8em/El3K1N9JWnp0qXZppuYckk8Bl3kPHdKQ9JL3fEzAS6gK5X3bs6cOdnmItWStO+++2abVbyjG52yYa38SKuUAYkVmbkd+0Ksrl/r360qxxyL3C72GV4jShDxWcP+zvNl34whAJQxWosRz58/f9jjxXvLc+I1aZVMiKUuZgKtheDZF2J/5LVrvScoi/HZyfdEa/FgEheMZxtqq09I5fOyJvlFmY/n26oKvmjRomyzz8X+yLbyfcJrHEsj1EJX4vViv60tYBz347hslRhpleTpgz1TxhhjjDE98GTKGGOMMaYHU0rmi5kBdIOShQsXFp+PPvrobFNaiC5Wum/pJuR2sQ21DIm4wO8jjzwybHuYWSBJW7ZsGbatzOyI0hndr9wnynfcjzJBrMJO6A6mWzfKCfxMd3KUfCgpUZZbvXp1sR2v17PPPpttXu94L1oy8HQlZgO98Y1vzPab3vSmbC9fvrzYjtX/eR3j8diPabeqQI8k+y5uR6JsGPv7digHxn24+DL7T5QQa6sCRGqLifOcomwUJY7txH7LsX3QQQdlm1m1Uhk6wGNTnoxZm1Gimgm0siVrlcOlctUK3mM+kyO83jxezKSuydOxrc8880y22beiPB0XF98OJa2YFctxwLbGqvn8zD4Y+zNDYWrSXrzGNZk1Pht4vjX5TipXN+H45X1hVq30UvlztLBnyhhjjDGmB55MGWOMMcb0YErJfLEwHzNx6NY755xziu2OP/74bH/rW9/KdnSV0p1I1zm3i+7bWoZTzCCgq/HBBx/MdiySSOmLReBOPfXUbMdMDGZc3XHHHdU20K3K7JLovq0tGEn3aNyn5uKOBeHoamZmX5RyeO4bNmzINiVXuniltlw5XYn3+IQTTsj2m9/85myzeKNUjhdKrNHlz/vCe8x+H+8xXfHRLU94PB4jSgOUqyntMys2jgnKlZSMo5zAPsM+HaWAWrFA/j3KhLUCkfH8+Kyh9Lls2bJiO0qzzHZas2bNsPtLbclruhKfTbXn8nnnnVdsx/CQb37zm9l4wntwAAAXaklEQVSO7x0+m9hvOaZaBaZrbZPKPsRnXWuxZfZpyrqtQrbsJ1EKroWNtMYE+1ktk7ZF7Kf8XRbgjItYczsu2M7jxWvXKvzZB3umjDHGGGN64MmUMcYYY0wPPJkyxhhjjOnBpI+ZYuVwphBLZbwRSwycfvrpxXbUeqkvx6q0jM1g/FQr5Z76PI8dYzP4mdpua1FOVqLluTJ9Vio1Zer5MYaIbaA230oJ53WoLbQa4XYxfoExNEy1j+UsmMJ+1113Zfu2227LdrwOMyU+hHFN8brV0oNjzBRjithPYmxHbZFRxirE8VGr9hzh8fg7cf+Y7j/cPhxTcR/GhMRj83q1FollWxkHUlvsNe5TewbFNjH+MZZ+4TOgVhaCKyhIL70u05WDDz442/GZw9jad77zndm+6KKLiu0+9alPZZvPplppDqleHiD2M97z1qL1PB77ZozvHckC3fF5yOcG+2Pr/cY+HGOwaiti1M417tMqU8Ht+Kw67LDDiu3e9773ZfvSSy/NNuPNYjxlq/p7H+yZMsYYY4zpgSdTxhhjjDE9mPQyX03Kk0rp4uSTT8727Nmzi+3uueeebFPSiK5YujG5sGStUrNUd9lG9y3dpWxDXOCXbeB3t99+e7ZjRV62gS7bKN/VXKwxVZRtr0ka8drFCtS1Y7NNdN/Gar1M62dKeLxe5Kmnnqp+N524+OKLs90q1fH4449nO143VtNmaj7LUEhlP6FMwPsf5YRamYyWy599Lso0/EyZmJJWLMHA/tSq3F+T+Vrp1DWZIEoVHMv8Lq5MUFsQOS4sS+mSKeL8e7wOUfabrvBas5K5JJ1//vnZvvDCC7MdJdDrr78+23zWxXCJmsRGWs+91sLUtVIbrWc596G8FaVq7sN2x2c5+zfHROz37Le1vh7Hcq18RHx/1EIAvvOd7xTbfeADH8j2nXfeme13v/vdw+4vjbxcw8vFniljjDHGmB54MmWMMcYY04NJL/Mde+yx2Y7ZfPPnz882K4dHqYKfKYNFKY4ucmaAUN6IcklNxmjJfHR1tty3zFaj1BjdzrXK5PHYNWkvuj3ZdraV7tIoaXAfuq6jpMFjMGMmSpd0PdNtzwrf0e3M853Okt+KFSuyfeCBBxbfzZ07N9u8x1H+eeCBB7LNexKlOH5mv4vbkdqirnGfmhwQt6vJy62FUtkH2S9iv61JFVGmYV+rLeoaZRVKF9wuSkP8TJkmjnPep7Vr12abz6cjjzyy2IcS7rXXXqvpCkM+3v72txff8R5//etfz3aUjNiHapJ2pBa+0arCzv7YkpzYn1r9lu8G2q1K3zx26znK71pjvrbwedyH15UZ4XzfSuV7lv0+SnZXXHFFto855phsf+ELXxh2G+ml13K0sGfKGGOMMaYHnkwZY4wxxvTAkyljjDHGmB5M+pipj370o9mO2if12PXr12c7xkxR82bsSKyszHiF2qraMRaH8Q61kgJSvTp3q/p4rVp73KdWaTlux8/cJ8abMNaD58FziKmstZiQqNtzO9qxCi9TulkFnxVwo9bPNjGmZLrx/ve/P9uf+9zniu/YT7Zu3ZptVtaWypgExjHE+8o4kFrJg9FYhb2WCh2pVVeO7eZ2rVTtWumPVtXkWmxkvA61mJc4Lvl84QoGsSQLY0wYI8pnUiwLMFNipq666qpsv+c97ym++8u//Mts77rrrsPaUllSh+8J3h+pfA7WyuHEOKtazFTsM7W+FWOPeAz2mRbs6+zPsZ/V+nQcO7USIbw+8R1bi1eKMZ21OOU4dq6++upsf+1rX8v2WWedlW2WvJCkb33rW8Pu0xd7powxxhhjeuDJlDHGGGNMDya9zEfWrVtXfGYaMKtpx8rBdOfSXdqS2Fgdl27euPgo3bmtlFBuV3P5SvXquK3q6qTVhpoc2ErVpmuXLtu4D3+rVk5BKt28rDLPMhdSKfs99thj2d53332zHSvdL1++XDMBlszYtGlT8R2r/bdkVN6jF154IdstabgmT0RXPn+3VYKDUDJopYHTbi0yXCu1ELdjP65VZ45tZ/u4T5RsaiEAcUywrZTvYmgArxFXhuCYiFJMbf+WlDrVueaaa4rPDPvgM2O33XYrtuNznpIqJSeplE4pT7Xk7lZpDML7Qul6pKtw1MpxSGWf5u/EMV9bLLkVVlF7T7TCBsjGjRuLzwznWLRoUbb5rIpQ8vuzP/uzbPM9I0krV66sHqMP9kwZY4wxxvTAkyljjDHGmB5MKZnv7rvvLj4ffPDBw24X3eN07bYWEqX7lcegazK6hvndc889l+3o3qTrlC7kKGnU3PStjI2apBHlwNoCnVHSIHTttiq38ztKItE9ze8omR511FHFdszmY7YSr8Pq1auLfT70oQ8NfxLTGC5YLJX9k9eaUpBUribATD9mtEr1RU9H6v6nnBD7444sOFpbHDW2oVatvVWlnMcY6SKxNZlQKiU7PnfiNea13HvvvbMdVw/gd7yuzODj4taSdNlll2mmccsttxSfOSb4LohjglJ4raq4VF/FoSVv1eTyKCGyr9bk8gjfJ619alJhbEMtG6+WvSeVY5vP6DjGawuG8zpK5XhZvHhxtmNWMscprwOl3S9/+cvFPh/5yEcqZ9EPe6aMMcYYY3rgyZQxxhhjTA+mlMzHLAqpdInSBc5ihZI0b968YW0W+oz71RYPjsXY6IqnGzVmy9DdSRdwzOzg8UcqadTc03E7umzplo1t4H41ySbKILUicK2MwpbL/d577802rx3dvCy+NlO57rrris/veMc7sn388cdne/fddy+24/1iFlMcO7VMOEoBcUzUsj6jzFCTEGPfohQepa/hziG2lRlAUX6pZbXGMVEreEiijMljjzQDl+dxwAEHFNuxeOHDDz+cbUoaUUKciTD7VypDCM4+++xsRxmM7wP24ZhpVlvIm++JKJ2RWnFoqcw8b40xfld777RkdI6p1mLEtezyCCVtynyU3qTyOcRrzBCZ+JnPpDgH4ALJtczaeOyxwp4pY4wxxpgeeDJljDHGGNMDT6aMMcYYY3owpWKmbrvttuLzRRddlG3GOMRyA6wSvXTp0myzirBUarPUv1uVg6llMx4j6vHUemvxU1KpKTOmKFZeJyzxEFNHCdvUqmBdixcbaUwAr3+MPWGa8ty5c7PNqt7xGIwjYMmEGMswE4nlQi644IJss4owVwiQyn68YsWKbD/44IPFdnEB0u3UFvGV6mnSMTaDMRg8XuyP7DMs6dBawYD9My5oS2op5zFui/14pKso1CrLx+tVW/w1xofwWcPxwnHwxS9+sdqemUJcFeC9731vttnXYwkFXl8+h7ds2VJsx/7NGDem98dxw1i/ffbZJ9uMg5PKMcF+G2OruF2tb8bYPsYvcZ/4DiLst3EcjWSx81jqh+OSz4Y43ni+vP4xdqxWqb72DhtL7JkyxhhjjOmBJ1PGGGOMMT2YUjJf5JJLLsn2hz/84WxHtx6lC8pl++23X7FdTc6j6zTKVtyutXgopQq6ieMCtEwxXbJkSbbptozSwi677DLsseOikLVU2dYisTxeqwJubSHP6L7lgsZ02XJhaal0i/PYTCtmergZ4v3vf3+26faOUhLT7mtV6aVSTmI/aVVk5m9Rjoj9j25+9rM4filDsN0cKzH9mTIL5fu4Xa3idGwDz6kmy8V9apJLHEc8D9oxrZzXgWObcmCUy430R3/0R9lmf7zjjjuK7Xhfli1blu0og7Fv1UrRxHcBt6M0yJI+Utk/W6sHcD+O89hnCL9je+K45G/V3ltS+e6qlfRplRLiOGpVSuf1bkmShNL3VVddNaJ9+mLPlDHGGGNMDzyZMsYYY4zpwZSW+QgX+KSUJJUucS4MG6smM4OD7la6KqP7lm5Hujdj9gVd/q2sP0pkdKNS3ooy36JFi7LNxZ/jIrh0l7ayi2rVmrldS4qhK52yhSQdeuih2eZ9icdjBsezzz6bbVZ7Nm3+/u//PttHHHFE8R37E/v0woULi+2YbVRbmDRWRq5VV44ZoLUM3Cg7c7ua1Bwrf1NC5BhrZRSORMqT6pmMcSyzDTyHWI1++fLlw/4OF/iWynAFyuL33HNPta2m5Iorrsh2fOZQOmPGXXyGUari2GFfaEm5XIQ7PmtrK2pEGYzPW2bt8hkfJW0eg++0OH55DLY1vnd4jrxeHIvx2K13KaktIN7KPGd7YlbyeGDPlDHGGGNMDzyZMsYYY4zpgSdTxhhjjDE9mDYxU3/zN3+TbabCSmUsA1cGj6UR5s2bl23qw63Vu6lr83eiZj7SdHHGSVGv5rGjds10aFa6jpr5SGKhItyHbWitSE49P8aD8Du2j3FRkrR69epscxX466+/vvq7poSp361V53kvYzwPYz0Yx8B+wfgpqZ6CHeMdGB/SKo1A+FuMzYiVpBmvxO9iDAdhG+KYYJs4Dtif+ZtSPbaKVdyl8rpyLMdyIatWrco2yz1MRHzIVOWRRx7JNstsSGVfZWp9fG7y+cvnfK2PSGX5Gj7jOQaksj9xzMbjsW+x3zEOib8Zj8Eq8THekNeB7Ysxj6yIzufEo48+qhp8zrfiJHld+dyIzxqOZx6D74/xwp4pY4wxxpgeeDJljDHGGNODaSPzkcsuu6z4HGW/7XCBYKksqbBgwYJsM1U0unxr8l2U4rhda4HHWqVzuv/jIpo8Nt2tsQJ67Tyii5Xf0cXakvbYbl7H6BpmCQuWP4jp3XSzxxRx8/KJbu9aH4z9kaUsKBvUKodLZZ+hVB3LhbA/tqrms60cE/zdKGlwH6a8RzmZ1cPZnjgmSC1tOz4beAzKp3Ec3Xfffdmm9B0XsaY04zHRn7hQOsuHsJ+wCrhUPtN4//n8j5XIKcuyn0X5jtIZw1DiGON+fDfwmRrfQfzckgPZBsqOsc+1FjsfbhupHhYTK5tzJQaOq1aYDa/xRGDPlDHGGGNMDzyZMsYYY4zpQWplco36j6U0fj9W4YMf/GC2o1xGlyQzbihVMBswHqOW+RaPwd+J1XXpNma2Cd23MXOJ23Fx5ChjsiI6pYboQuZnuoYpW8TMLFbAjRXoCdtEeSNeV7ps43mMJl3XDZ/iOE5MhjFx2mmnZXv27NnFd4cccki2586dm232kbhYdy0LNUoftQW1WxlOzLglcdFaygRvectbsh3HPMcEM2GjnFBrN8dElDRqmX5xMWlev7Vr12Z78+bNxXZs31hmK030mJg1a9aEj4mjjjoq25S9JOmNb3xjtikzUeaLWWd83sZnJ2GfofwW+xbHy1577ZVtytYxm5vHo/RN2TruRwkxyvSUP2Pm6Xbie5Bjh2OC7w+pfA7xXcBni1SO009/+tPDtmE02LZt268cE/ZMGWOMMcb0wJMpY4wxxpgezDiZj1Dyk+oLNFJaiG5Luje5f5TO6Kaliza6N5lFwt9lFtyaNWuKfebMmZPtk046KdtxIUkWrGNRtCi/1FzSXBg6SjE8X/ap6Ja9//77s83sJBbmlEp39Vgy0ZLGZBsTK1euLD7XsmrYN2PxW0oVraJ/PB77Y5QT2PcpifF3brjhhmob3va2t2U7Zmax77OvxrHD3+U+raw/fsd9OF7j73JMxGzca6+9tvpbo8lEj4nJIPMRysRSfVF3PjdjX+d27IOxcCjDOdhnoszH4/G32G85bqRS5muFZfCZ/8ADD2Q7Pstr2Xgc13GfWlb74sWLi+34POA7I0qSXLh6LLHMZ4wxxhgzxngyZYwxxhjTA0+mjDHGGGN6MKNjpiK/+7u/m21qvdSnY1ozNdzawq3SS1NltxOvP6vycp+HHnqoeiym7p533nnZZhX3eAzq57EN1MK5HTXuGNPEmKdWijDPj/tMVEXniY4Pmexj4vDDD882+z7jgWIFZaY1s5xCjIsgLFnA2D6pvigr07vXrVtX7MN+xpiQ2AYeg/07jt9aKQj29VgiohZPw2sS9+N4+exnP6uJYKLHxGSLmYocd9xx2a6V/jjwwAOLfRgLy/inY445ptiOfZ/Ha71Pav0sxkwxFnHffffNdozb4jFaccB8BjBui9X+YykStoFxUfF68ZxYquFzn/ucJgLHTBljjDHGjDGeTBljjDHG9MAy3wg455xzsh1d+UwxZcprrGy+cOHCbFMiY9qnJK1atSrbGzZsyDYlxJi2TXcrJYQTTzyx2I5uVbYvpovzeEzPZuV1VsaVSlcs3cR010ql65kV0CeKiZY0puqYoFwWKzrz/tPlH0soUBpg34plMgglO5ZnuOmmm4rtKC+w31PekEqJnOMgpmDzOcm+zrESyyRQzuH4j7IoQwo++clPDvv38WSix8Rkl/lqnHXWWdlmlXSprLTPvhlLKPC5WqugH/fj8djnYgV0HpvlOeI7jZJia1UPMtLFv2urf8QxwffOlVdeWf3d8cIynzHGGGPMGOPJlDHGGGNMDyzzvUyWLVtWfGaGE92ysYozF4xlZgcrzEplFhJdp7RjhhyzLCgHRtcpF2+mKzZWZKY7l+5WLioZz49Q5onV1W+77bbqfhPBREsa02FMsF9J9cyemAFay0KK/ZvS3oUXXphtZvB94xvfKPbh7x566KHZjtm4lD4od0Tpkv2dch5ljCjtU0Jk1mCUPuJKDBPNRI+JqSrzkXhP2ff5HI2LuDN7jovMRzmQWYBcmYJyYnz+87nOSuutTOoYplGDx+a7ihJ7bCvHR/yd8apsPlIs8xljjDHGjDGeTBljjDHG9MCTKWOMMcaYHtRzHc2wrF69uvod46JimjQ1c6ayxiq11I5ZAoExHPHY1KsZm8G4EanU4Knbx1gWxq/Uqj3HNFnGajHmZbLFSJnR5+mnn65+x3iqGD/BfszSCDEejzGBrAr+5JNPZjv2YaaSsyTDkiVLiu0Y08dSHbEsAeOc2G72+1j6gTErLFnyrne9S2Z6c+mll1a/++u//utsxzi7hx9+ONssjcNnslSW6mB/ZMzVscceW+zDeKXPf/7z2WbsklTGybJ/x7gmvl84ZjleWQpBemm84HYmW4zUjmDPlDHGGGNMDzyZMsYYY4zpgUsjjBN0sdItG12ndOdGOW870VVKCZBS48knn1xsR9lwzZo12ab8J5USHtvHlNcoabDa7le/+tVh2z0Zmeg08Jk8JkaTWMpgr732yvaRRx6Z7ZUrVxbbsVTC1q1bsx2rR1P2oyxCKY9VzqUynf3ss89un8AkYqLHxHQojbCj/MZv/Ea2H3zwwWzHZz4lNkppLLtz5plnFvuwf69fv37YY0nlWKJkF0M72L8ZNsK2xnHJ8kGXX365pgoujWCMMcYYM8Z4MmWMMcYY0wPLfJMMZjzVMojiPeN2NXkjfsfFZOOixTw+s6Loor3lllsaZzF1mGhJw2NibGCWFO2lS5cW282ePTvblC04VqRyHDB7kXL37//+7/do8eRhosfETJb5Rso+++wz7N/ZT7lygFRmkTPshBngUrmAOKXBGHbC8BD+LsfRJz7xieFPYIphmc8YY4wxZozxZMoYY4wxpgeW+aYgMbODWXYsskbXq1S6X+najVkaN99886i0cyow0ZKGx8TYwCw7ZjvFMcFso4MOOijby5cvL7b72Mc+NtpNnLRM9JiwzDc6REmbUPqOkjbHC6W9mJl35ZVX9m3ilMEynzHGGGPMGOPJlDHGGGNMDzyZMsYYY4zpgWOmzIxmouNDPCbMZGOix4RjpsxkwzFTxhhjjDFjjCdTxhhjjDE9GFeZzxhjjDFmumHPlDHGGGNMDzyZMsYYY4zpgSdTxhhjjDE98GTKGGOMMaYHnkwZY4wxxvTAkyljjDHGmB54MmWMMcYY0wNPpowxxhhjeuDJlDHGGGNMDzyZMsYYY4zpgSdTxhhjjDE98GTKGGOMMaYHnkwZY4wxxvTAkyljjDHGmB54MmWMMcYY0wNPpowxxhhjeuDJlDHGGGNMDzyZMsYYY4zpgSdTxhhjjDE98GTKGGOMMaYHnkwZY4wxxvTAkyljjDHGmB54MmWMMcYY04P/DwA1BCKTEYDXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83c89cab90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_pred(testing_data_inp[0], predicted_brain, testing_data_out[0], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251.5621"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_brain.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098.3759"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data_out[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the target and the predicted scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to = \"/home/ubuntu/project/Dataset/EXP_AWS_1/Overfit\"\n",
    "\n",
    "predicted_scan = nib.Nifti1Image(predicted_brain, affine_mat)\n",
    "nib.save(predicted_scan, save_to + \"/Predicted_scan_subj2_AWS.nii.gz\" )\n",
    "\n",
    "target_scan = nib.Nifti1Image(testing_data_out[0][:,:,:,0], affine_mat)\n",
    "nib.save(target_scan, save_to + \"/Target_scan_subj2_AWS.nii.gz\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(trained_net.state_dict(), '/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/Overfit_AWS.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_net = Net()\n",
    "trained_net.cuda()\n",
    "trained_net.load_state_dict(torch.load('/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/Overfit_AWS.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
