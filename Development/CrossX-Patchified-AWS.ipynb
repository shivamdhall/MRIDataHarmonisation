{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - CrossX - Patch - AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use both scans of subjects 1-8 from the PETMR and TRIO dataset for training.\n",
    "\n",
    "We used the scan of subjects 9-10 also from the PETMR and TRIO dataset for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function simply uploads the testing and training scans into lists of numpy arrays\n",
    "# The data is not yet sliced or patched at this stage\n",
    "\n",
    "# Specify in a list what scans to use for training and what scans to use for testing\n",
    "\n",
    "# This function only takes the first and last b=0 volumes\n",
    "\n",
    "def get_data(petmr_path, trio_path, scans_dict):\n",
    "    \n",
    "    train_data_inp = []\n",
    "    test_data_inp = []\n",
    "    train_data_out = []\n",
    "    test_data_out = []\n",
    "    paths = [petmr_path, trio_path]\n",
    "    \n",
    "    for data_path in paths:\n",
    "        if(data_path == petmr_path):\n",
    "            print \"Uploading Inputs:\"\n",
    "            training_data_store = train_data_inp\n",
    "            testing_data_store = test_data_inp\n",
    "        else:\n",
    "            print \"Uploading Outputs\"\n",
    "            training_data_store = train_data_out\n",
    "            testing_data_store = test_data_out\n",
    "        os.chdir(data_path)\n",
    "        for key, subjs in scans_dict.iteritems():\n",
    "            for subj_scan in subjs:\n",
    "                scan_image = nib.load(str(data_path) + \"/Subj\" + subj_scan + \"/Brain_Thresholded.nii.gz\")\n",
    "                scan_data = scan_image.get_data()\n",
    "                #all scans have the same affine mat because registration has already been performed\n",
    "                #we only need it for saving the predictions as a NIfTI file\n",
    "                affine_mat = scan_image.affine\n",
    "                #get b=0 volumes only\n",
    "                bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/Subj\" + subj_scan + \"/NODDI.bval\",\\\n",
    "                                                          str(data_path) + \"/Subj\" + subj_scan + \"/NODDI.bvec\")\n",
    "                #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "                gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "                s0s_scan = scan_data[:, :, :, gtab_scan.b0s_mask]\n",
    "            \n",
    "                if(key == \"training\"):\n",
    "                    print (\"Training: Subj%s\" % subj_scan)\n",
    "                    #append this data to the list containing the training data\n",
    "                    training_data_store.append(s0s_scan[:,:,:,[0,-1]])\n",
    "                else:\n",
    "                    print (\"Testing: Subj%s\" % subj_scan)\n",
    "                    testing_data_store.append(s0s_scan[:,:,:,[0,-1]])\n",
    "    return (train_data_inp, train_data_out, test_data_inp, test_data_out, affine_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "\n",
    "def patchify(data_scans_inp, data_scans_out, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan = data_scans_out[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel = target_scan[pos_x,pos_y,pos_z,volume]\n",
    "\n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store.append(target_voxel)\n",
    "                    \n",
    "    return (input_patches_store, target_patches_store)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "#This version of the functions only considers voxels wholly contained within the brain\n",
    "\n",
    "def patchify_brain_only(data_scans_inp, data_scans_out, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan = data_scans_out[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "        #use unpadded scan (original input scan) to identify non-backround voxels\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        # Exclude all background voxels\n",
    "                        if(input_scan[pos_x,pos_y,pos_z,volume] == 0):\n",
    "                            continue\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel = target_scan[pos_x,pos_y,pos_z,volume]\n",
    "                       \n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store.append(target_voxel)\n",
    "                    \n",
    "    return (input_patches_store, target_patches_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise(dataset, mean=None, std=None):\n",
    "    data_array = np.array(dataset)\n",
    "    if mean==None and std==None:\n",
    "        #This is the training data\n",
    "        mean = np.mean(data_array)\n",
    "        std = np.std(data_array)\n",
    "    #normalise the data\n",
    "    data_array = (data_array - mean)/std\n",
    "    return (data_array, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_pred(inputs, predictions, labels, sliceNo):\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1).set_axis_off()\n",
    "    plt.imshow(inputs[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2).set_axis_off()\n",
    "    plt.imshow(predictions[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.subplot(1, 3, 3).set_axis_off()\n",
    "    plt.imshow(labels[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Inputs:\n",
      "Training: Subj2Scan1\n",
      "Training: Subj3Scan2\n",
      "Training: Subj4Scan1\n",
      "Training: Subj5Scan2\n",
      "Testing: Subj1Scan2\n",
      "Uploading Outputs\n",
      "Training: Subj2Scan1\n",
      "Training: Subj3Scan2\n",
      "Training: Subj4Scan1\n",
      "Training: Subj5Scan2\n",
      "Testing: Subj1Scan2\n",
      "Number of scans used for training input: 4\n",
      "Number of scans used for training output: 4\n",
      "Number of scans used for testing input: 1\n",
      "Number of scans used for testing output: 1\n"
     ]
    }
   ],
   "source": [
    "#upload the data\n",
    "petmr_data_path = '/home/ubuntu/project/Dataset/PETMR_data'\n",
    "trio_data_path = '/home/ubuntu/project/Dataset/TRIO_data'\n",
    "\n",
    "training_scans = [\"2Scan1\", \"3Scan2\", \"4Scan1\", \"5Scan2\"]\n",
    "\n",
    "\n",
    "testing_scans = [\"1Scan2\"]\n",
    "\n",
    "(training_data_inp, training_data_out, testing_data_inp, testing_data_out, affine_mat) = \\\n",
    "        get_data(petmr_data_path, trio_data_path, {\"training\":training_scans, \"testing\":testing_scans})\n",
    "\n",
    "print (\"Number of scans used for training input: %d\" % len(training_data_inp))\n",
    "print (\"Number of scans used for training output: %d\" % len(training_data_out))\n",
    "print (\"Number of scans used for testing input: %d\" % len(testing_data_inp))\n",
    "print (\"Number of scans used for testing output: %d\" % len(testing_data_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patchify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchifying training set\n",
      "Patchifying testing set\n"
     ]
    }
   ],
   "source": [
    "print \"Patchifying training set\"\n",
    "(training_input, training_target) = patchify_brain_only(training_data_inp, training_data_out, 9)\n",
    "\n",
    "print \"Patchifying testing set\"\n",
    "(testing_input, testing_target) = patchify(testing_data_inp, testing_data_out, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nember of training examples : 643030\n",
      "Nember of testing examples : 257600\n"
     ]
    }
   ],
   "source": [
    "print (\"Nember of training examples : %d\" % len(training_input))\n",
    "print (\"Nember of testing examples : %d\" % len(testing_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dataset class for our data\n",
    "\n",
    "class MRIdataset(Dataset):\n",
    "    \"\"\"MRI b=0 dataset for patches.\"\"\"\n",
    "\n",
    "    def __init__(self, input_patches, target_patches, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_patches: Input patches\n",
    "            target_patches: Corresponding target patches of the input patches\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        \"\"\"\n",
    "        self.input_patches = input_patches\n",
    "        self.target_patches = target_patches\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_patch = np.array(self.input_patches[idx])\n",
    "        target_patch = np.array(self.target_patches[idx])\n",
    "        sample = {'input': input_patch, 'target': target_patch}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class To_Tensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inp, out = sample['input'], sample['target']\n",
    "        \n",
    "        #first expand dimension because torch expects H x W x D x C\n",
    "        #currently we only have H x W x D\n",
    "        aug_inp = np.expand_dims(inp, 3)\n",
    "        \n",
    "        #The target is a single voxel,\n",
    "        #Conver it to an array\n",
    "        aug_out = np.array([out])\n",
    "\n",
    "        # swap channel axis because\n",
    "        # numpy: H x W x D x C\n",
    "        # torch: C x D x H x W\n",
    "        aug_inp = aug_inp.transpose((3, 2, 0, 1))\n",
    "        \n",
    "        return {'input': torch.Tensor(aug_inp),\n",
    "                'target': torch.Tensor(aug_out)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net, training_dataset, trainloader, losses_list, optimizer, criterion, epochs):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): #done in batches\n",
    "            # get the inputs\n",
    "            inputs = data['input']\n",
    "            labels = data['target']\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize/update weights\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0] #loss is a variable tensor of size 1, we index to get the value out\n",
    "            if i % 250 == 249:    # print every 250 mini-batches\n",
    "                print('[%d, %d] Loss = %.5f' % (epoch + 1, i + 1, running_loss/i))\n",
    "        total_loss = running_loss / i\n",
    "        losses_list.append(total_loss)\n",
    "        print('Loss iteration %d = %.5f' % (epoch+1, total_loss ))\n",
    "        '''   \n",
    "        test_error = 0\n",
    "        total = 0\n",
    "        for test_data in testloader: #batch processing\n",
    "            test_inputs = test_data['inp']\n",
    "            test_labels = test_data['out']\n",
    "            total += len(test_labels)\n",
    "\n",
    "            test_outputs = net(Variable(test_inputs))\n",
    "\n",
    "            test_error += (torch.nn.functional.mse_loss(test_outputs.data, test_labels, size_average=False)).data[0]\n",
    "\n",
    "        test_error /= total\n",
    "        print('MSE on test data: %f' % (test_error))\n",
    "        Adam_acc.append(test_error)\n",
    "        '''\n",
    "    print('Finished Training')\n",
    "    return (net, losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_losses(losses_list):\n",
    "    plt.figure\n",
    "    plt.plot(range(1,len(losses_list)+1), losses_list, 'r-')\n",
    "    plt.xlabel('iteration')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def testing_error(net, testloader, loss_type=\"MSE\"):\n",
    "    net.eval()\n",
    "    test_error = 0\n",
    "    total = 0\n",
    "    for test_data in testloader: #batch processing\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        total += 1\n",
    "\n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "        \n",
    "        test_predictions = net(test_inputs)\n",
    "        \n",
    "        if(loss_type == \"MSE\"):\n",
    "            #Use MSE loss\n",
    "            test_error += (torch.nn.functional.mse_loss( Variable(test_predictions.data), test_labels)).data[0]\n",
    "        else:\n",
    "            test_error += (torch.nn.functional.l1_loss(Variable(test_predictions.data), test_labels)).data[0]\n",
    "        \n",
    "    test_error /= total\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(net, testloader):\n",
    "    net.eval()\n",
    "    for index, test_data in enumerate(testloader):\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        if index % 250 == 249:\n",
    "            print index + 1\n",
    "        \n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "\n",
    "        #store the predictions in a numpy array which we can reshape later\n",
    "        test_predictions = net(test_inputs)\n",
    "        if(index == 0):\n",
    "            predictions = test_predictions.data.cpu().numpy() \n",
    "\n",
    "        else:\n",
    "            predictions = np.concatenate((predictions, test_predictions.data.cpu().numpy()), axis=0)\n",
    "            \n",
    "    #convert back to numpy dimensions of (HxWxDxCxNumbExpls)\n",
    "    predictions = predictions.transpose(3,4,2,1,0)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_background(prediction, input_scan):\n",
    "    background_mask = input_scan <= 0\n",
    "    prediction[background_mask] = 0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_brain(predictions, dimensions):\n",
    "    \n",
    "    size_x = dimensions[0]\n",
    "    size_y = dimensions[1]\n",
    "    size_z = dimensions[2]\n",
    "    size_v = dimensions[3]\n",
    "    #assume we have given it a single scan to reconstruct\n",
    "    reconstructed = np.reshape(predictions, [size_v, size_x, size_y, size_z], order='C')\n",
    "    reconstructed = reconstructed.transpose(1,2,3,0)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data using pytorch data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset = MRIdataset(training_input, training_target, transform=transforms.Compose([To_Tensor()]))\n",
    "testing_dataset = MRIdataset(testing_input, testing_target, transform=transforms.Compose([To_Tensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_dataset, batch_size=160,\n",
    "                        shuffle=True, num_workers=8)\n",
    "testloader = DataLoader(testing_dataset, batch_size=160,\n",
    "                        shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Relu\n",
    "\n",
    "--(WxHx2x1)--\n",
    "\n",
    "conv1 = receptive field -> (3x3x3), zero padding -> 2,  number of filters -> 10\n",
    "\n",
    "--(W+2xH+2x4x10)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv2 = receptive field -> (1x1x1), number of filters -> 15\n",
    "\n",
    "--(W+2xH+2x4x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv3 = receptive field -> (3x3x3), number of filters -> 15\n",
    "\n",
    "--(WxHx2x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv4 = receptive field -> (1x1x2), number of filters -> 1\n",
    "\n",
    "--(WxHx1x1)--\n",
    "\n",
    "--RELU--\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv3d (1, 50, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (conv2): Conv3d (50, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop2): Dropout(p=0.2)\n",
      "  (conv3): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop3): Dropout(p=0.2)\n",
      "  (conv4): Conv3d (100, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch4): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop4): Dropout(p=0.2)\n",
      "  (conv5): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch5): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop5): Dropout(p=0.2)\n",
      "  (conv6): Conv3d (100, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch6): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop6): Dropout(p=0.2)\n",
      "  (conv7): Conv3d (50, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 50, 3)\n",
    "        self.batch1 = nn.BatchNorm2d(50)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = nn.Conv3d(50, 100, 1)\n",
    "        self.batch2 = nn.BatchNorm2d(100)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.conv3 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch3 = nn.BatchNorm2d(100)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.conv4 = nn.Conv3d(100, 100, 1)\n",
    "        self.batch4 = nn.BatchNorm2d(100)\n",
    "        self.drop4 = nn.Dropout(p=0.2)\n",
    "        self.conv5 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch5 = nn.BatchNorm2d(100)\n",
    "        self.drop5 = nn.Dropout(p=0.2)\n",
    "        self.conv6 = nn.Conv3d(100, 50, 1)\n",
    "        self.batch6 = nn.BatchNorm2d(50)\n",
    "        self.drop6 = nn.Dropout(p=0.2)\n",
    "        self.conv7 = nn.Conv3d(50, 1, 3)\n",
    "        \n",
    "        \n",
    "\n",
    "    #note this method isn't called explicitly during train, \n",
    "    #rather the instance object is called as pytorch is then \n",
    "    #able to take care of other stuff in the background\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch1(self.conv1(x)))\n",
    "        x = F.relu(self.batch2(self.conv2(x)))\n",
    "        x = F.relu(self.batch3(self.conv3(x)))\n",
    "        x = F.relu(self.batch4(self.conv4(x)))\n",
    "        x = F.relu(self.batch5(self.conv5(x)))\n",
    "        x = F.relu(self.batch6(self.conv6(x)))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we use MSE loss\n",
    "criterion = nn.MSELoss() #returns the average over a mini-batch as opposed to the sum\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 250] Loss = 62323.92505\n",
      "[1, 500] Loss = 35604.09164\n",
      "[1, 750] Loss = 25725.13548\n",
      "[1, 1000] Loss = 20636.22685\n",
      "[1, 1250] Loss = 17476.46926\n",
      "[1, 1500] Loss = 15349.94603\n",
      "[1, 1750] Loss = 13788.36984\n",
      "[1, 2000] Loss = 12594.17973\n",
      "[1, 2250] Loss = 11649.55889\n",
      "[1, 2500] Loss = 10870.67740\n",
      "[1, 2750] Loss = 10210.21297\n",
      "[1, 3000] Loss = 9658.54407\n",
      "[1, 3250] Loss = 9181.51415\n",
      "[1, 3500] Loss = 8763.31933\n",
      "[1, 3750] Loss = 8395.01554\n",
      "[1, 4000] Loss = 8059.91023\n",
      "Loss iteration 1 = 8036.14244\n",
      "[2, 250] Loss = 2917.27495\n",
      "[2, 500] Loss = 2828.94457\n",
      "[2, 750] Loss = 2780.65938\n",
      "[2, 1000] Loss = 2740.16140\n",
      "[2, 1250] Loss = 2708.46708\n",
      "[2, 1500] Loss = 2682.65638\n",
      "[2, 1750] Loss = 2654.72296\n",
      "[2, 2000] Loss = 2624.76601\n",
      "[2, 2250] Loss = 2600.18006\n",
      "[2, 2500] Loss = 2574.98097\n",
      "[2, 2750] Loss = 2548.41206\n",
      "[2, 3000] Loss = 2523.71047\n",
      "[2, 3250] Loss = 2497.72697\n",
      "[2, 3500] Loss = 2469.97109\n",
      "[2, 3750] Loss = 2443.44012\n",
      "[2, 4000] Loss = 2416.95034\n",
      "Loss iteration 2 = 2414.79014\n",
      "[3, 250] Loss = 1887.36650\n",
      "[3, 500] Loss = 1850.31586\n",
      "[3, 750] Loss = 1848.48898\n",
      "[3, 1000] Loss = 1841.34596\n",
      "[3, 1250] Loss = 1825.84193\n",
      "[3, 1500] Loss = 1815.76526\n",
      "[3, 1750] Loss = 1807.97720\n",
      "[3, 2000] Loss = 1796.65434\n",
      "[3, 2250] Loss = 1784.02144\n",
      "[3, 2500] Loss = 1774.81414\n",
      "[3, 2750] Loss = 1764.62712\n",
      "[3, 3000] Loss = 1752.63500\n",
      "[3, 3250] Loss = 1742.11984\n",
      "[3, 3500] Loss = 1732.79420\n",
      "[3, 3750] Loss = 1722.49736\n",
      "[3, 4000] Loss = 1713.44077\n",
      "Loss iteration 3 = 1713.23510\n",
      "[4, 250] Loss = 1389.67508\n",
      "[4, 500] Loss = 1403.92518\n",
      "[4, 750] Loss = 1402.59059\n",
      "[4, 1000] Loss = 1404.35406\n",
      "[4, 1250] Loss = 1396.15816\n",
      "[4, 1500] Loss = 1393.08256\n",
      "[4, 1750] Loss = 1392.17152\n",
      "[4, 2000] Loss = 1388.79058\n",
      "[4, 2250] Loss = 1386.30794\n",
      "[4, 2500] Loss = 1381.25785\n",
      "[4, 2750] Loss = 1379.15290\n",
      "[4, 3000] Loss = 1372.93084\n",
      "[4, 3250] Loss = 1366.01343\n",
      "[4, 3500] Loss = 1358.61411\n",
      "[4, 3750] Loss = 1353.85831\n",
      "[4, 4000] Loss = 1349.57731\n",
      "Loss iteration 4 = 1349.29476\n",
      "[5, 250] Loss = 1185.63360\n",
      "[5, 500] Loss = 1189.12564\n",
      "[5, 750] Loss = 1181.85794\n",
      "[5, 1000] Loss = 1162.44285\n",
      "[5, 1250] Loss = 1162.37720\n",
      "[5, 1500] Loss = 1155.80410\n",
      "[5, 1750] Loss = 1155.91853\n",
      "[5, 2000] Loss = 1154.87325\n",
      "[5, 2250] Loss = 1155.43032\n",
      "[5, 2500] Loss = 1158.20555\n",
      "[5, 2750] Loss = 1158.49366\n",
      "[5, 3000] Loss = 1152.94345\n",
      "[5, 3250] Loss = 1150.10987\n",
      "[5, 3500] Loss = 1150.16261\n",
      "[5, 3750] Loss = 1145.18291\n",
      "[5, 4000] Loss = 1141.11999\n",
      "Loss iteration 5 = 1141.04715\n",
      "[6, 250] Loss = 987.36997\n",
      "[6, 500] Loss = 1000.78263\n",
      "[6, 750] Loss = 999.71758\n",
      "[6, 1000] Loss = 1008.05765\n",
      "[6, 1250] Loss = 1003.14742\n",
      "[6, 1500] Loss = 1009.33698\n",
      "[6, 1750] Loss = 1009.74734\n",
      "[6, 2000] Loss = 1012.72589\n",
      "[6, 2250] Loss = 1009.88363\n",
      "[6, 2500] Loss = 1009.32062\n",
      "[6, 2750] Loss = 1007.40668\n",
      "[6, 3000] Loss = 1008.28141\n",
      "[6, 3250] Loss = 1006.30619\n",
      "[6, 3500] Loss = 1006.26805\n",
      "[6, 3750] Loss = 1005.70935\n",
      "[6, 4000] Loss = 1005.36477\n",
      "Loss iteration 6 = 1005.37371\n",
      "[7, 250] Loss = 865.19332\n",
      "[7, 500] Loss = 867.69719\n",
      "[7, 750] Loss = 881.12860\n",
      "[7, 1000] Loss = 882.77659\n",
      "[7, 1250] Loss = 887.60494\n",
      "[7, 1500] Loss = 888.10590\n",
      "[7, 1750] Loss = 888.15947\n",
      "[7, 2000] Loss = 894.03689\n",
      "[7, 2250] Loss = 892.92674\n",
      "[7, 2500] Loss = 893.27350\n",
      "[7, 2750] Loss = 891.15221\n",
      "[7, 3000] Loss = 890.60541\n",
      "[7, 3250] Loss = 892.12697\n",
      "[7, 3500] Loss = 890.55403\n",
      "[7, 3750] Loss = 890.29570\n",
      "[7, 4000] Loss = 890.03120\n",
      "Loss iteration 7 = 890.18675\n",
      "[8, 250] Loss = 762.75894\n",
      "[8, 500] Loss = 772.98587\n",
      "[8, 750] Loss = 781.06686\n",
      "[8, 1000] Loss = 789.22245\n",
      "[8, 1250] Loss = 792.35120\n",
      "[8, 1500] Loss = 796.84038\n",
      "[8, 1750] Loss = 800.26656\n",
      "[8, 2000] Loss = 804.61790\n",
      "[8, 2250] Loss = 801.76537\n",
      "[8, 2500] Loss = 805.93875\n",
      "[8, 2750] Loss = 804.93023\n",
      "[8, 3000] Loss = 804.60708\n",
      "[8, 3250] Loss = 806.37209\n",
      "[8, 3500] Loss = 804.47847\n",
      "[8, 3750] Loss = 802.51506\n",
      "[8, 4000] Loss = 801.60168\n",
      "Loss iteration 8 = 801.58467\n",
      "[9, 250] Loss = 731.87250\n",
      "[9, 500] Loss = 725.17136\n",
      "[9, 750] Loss = 725.81006\n",
      "[9, 1000] Loss = 724.55545\n",
      "[9, 1250] Loss = 730.02782\n",
      "[9, 1500] Loss = 735.19925\n",
      "[9, 1750] Loss = 737.93156\n",
      "[9, 2000] Loss = 738.17505\n",
      "[9, 2250] Loss = 737.66272\n",
      "[9, 2500] Loss = 738.97413\n",
      "[9, 2750] Loss = 741.07622\n",
      "[9, 3000] Loss = 740.93352\n",
      "[9, 3250] Loss = 740.65452\n",
      "[9, 3500] Loss = 740.84255\n",
      "[9, 3750] Loss = 741.31507\n",
      "[9, 4000] Loss = 739.94981\n",
      "Loss iteration 9 = 739.75676\n",
      "[10, 250] Loss = 654.84630\n",
      "[10, 500] Loss = 645.47820\n",
      "[10, 750] Loss = 648.30278\n",
      "[10, 1000] Loss = 654.38194\n",
      "[10, 1250] Loss = 664.56779\n",
      "[10, 1500] Loss = 668.68428\n",
      "[10, 1750] Loss = 670.45627\n",
      "[10, 2000] Loss = 671.54837\n",
      "[10, 2250] Loss = 672.46670\n",
      "[10, 2500] Loss = 672.02962\n",
      "[10, 2750] Loss = 677.54306\n",
      "[10, 3000] Loss = 679.38466\n",
      "[10, 3250] Loss = 681.34614\n",
      "[10, 3500] Loss = 682.80131\n",
      "[10, 3750] Loss = 684.57741\n",
      "[10, 4000] Loss = 683.45144\n",
      "Loss iteration 10 = 683.32985\n",
      "[11, 250] Loss = 622.27846\n",
      "[11, 500] Loss = 625.14863\n",
      "[11, 750] Loss = 625.64003\n",
      "[11, 1000] Loss = 631.96466\n",
      "[11, 1250] Loss = 632.54645\n",
      "[11, 1500] Loss = 634.26825\n",
      "[11, 1750] Loss = 636.29119\n",
      "[11, 2000] Loss = 639.75812\n",
      "[11, 2250] Loss = 640.76105\n",
      "[11, 2500] Loss = 640.35168\n",
      "[11, 2750] Loss = 639.81244\n",
      "[11, 3000] Loss = 641.66049\n",
      "[11, 3250] Loss = 644.25251\n",
      "[11, 3500] Loss = 644.16011\n",
      "[11, 3750] Loss = 645.38193\n",
      "[11, 4000] Loss = 645.65358\n",
      "Loss iteration 11 = 645.94052\n",
      "[12, 250] Loss = 577.82328\n",
      "[12, 500] Loss = 579.18469\n",
      "[12, 750] Loss = 589.39210\n",
      "[12, 1000] Loss = 587.03841\n",
      "[12, 1250] Loss = 589.95522\n",
      "[12, 1500] Loss = 593.64608\n",
      "[12, 1750] Loss = 596.65429\n",
      "[12, 2000] Loss = 598.31006\n",
      "[12, 2250] Loss = 600.37868\n",
      "[12, 2500] Loss = 601.97481\n",
      "[12, 2750] Loss = 601.75206\n",
      "[12, 3000] Loss = 602.15750\n",
      "[12, 3250] Loss = 601.43695\n",
      "[12, 3500] Loss = 602.05475\n",
      "[12, 3750] Loss = 601.21179\n",
      "[12, 4000] Loss = 601.28755\n",
      "Loss iteration 12 = 601.06832\n",
      "[13, 250] Loss = 537.99304\n",
      "[13, 500] Loss = 543.29430\n",
      "[13, 750] Loss = 548.06443\n",
      "[13, 1000] Loss = 556.90192\n",
      "[13, 1250] Loss = 558.10711\n",
      "[13, 1500] Loss = 559.31864\n",
      "[13, 1750] Loss = 559.21234\n",
      "[13, 2000] Loss = 561.24657\n",
      "[13, 2250] Loss = 562.12845\n",
      "[13, 2500] Loss = 564.96770\n",
      "[13, 2750] Loss = 567.84761\n",
      "[13, 3000] Loss = 568.87789\n",
      "[13, 3250] Loss = 568.18308\n",
      "[13, 3500] Loss = 569.84258\n",
      "[13, 3750] Loss = 569.69395\n",
      "[13, 4000] Loss = 569.12262\n",
      "Loss iteration 13 = 569.02322\n",
      "[14, 250] Loss = 514.76045\n",
      "[14, 500] Loss = 512.98723\n",
      "[14, 750] Loss = 507.57489\n",
      "[14, 1000] Loss = 517.94932\n",
      "[14, 1250] Loss = 521.16676\n",
      "[14, 1500] Loss = 522.28947\n",
      "[14, 1750] Loss = 526.02029\n",
      "[14, 2000] Loss = 526.50640\n",
      "[14, 2250] Loss = 526.98663\n",
      "[14, 2500] Loss = 529.87265\n",
      "[14, 2750] Loss = 530.46554\n",
      "[14, 3000] Loss = 530.51216\n",
      "[14, 3250] Loss = 533.80569\n",
      "[14, 3500] Loss = 534.95710\n",
      "[14, 3750] Loss = 535.68322\n",
      "[14, 4000] Loss = 535.94799\n",
      "Loss iteration 14 = 535.88544\n",
      "[15, 250] Loss = 503.61553\n",
      "[15, 500] Loss = 495.18816\n",
      "[15, 750] Loss = 490.44055\n",
      "[15, 1000] Loss = 493.39611\n",
      "[15, 1250] Loss = 500.02186\n",
      "[15, 1500] Loss = 503.93375\n",
      "[15, 1750] Loss = 506.73272\n",
      "[15, 2000] Loss = 509.67064\n",
      "[15, 2250] Loss = 510.04432\n",
      "[15, 2500] Loss = 511.51653\n",
      "[15, 2750] Loss = 511.90165\n",
      "[15, 3000] Loss = 512.05911\n",
      "[15, 3250] Loss = 511.74153\n",
      "[15, 3500] Loss = 511.81671\n",
      "[15, 3750] Loss = 511.66248\n",
      "[15, 4000] Loss = 511.61208\n",
      "Loss iteration 15 = 511.77390\n",
      "[16, 250] Loss = 476.09473\n",
      "[16, 500] Loss = 464.56789\n",
      "[16, 750] Loss = 468.70565\n",
      "[16, 1000] Loss = 472.63962\n",
      "[16, 1250] Loss = 475.25009\n",
      "[16, 1500] Loss = 479.25493\n",
      "[16, 1750] Loss = 482.04538\n",
      "[16, 2000] Loss = 486.80039\n",
      "[16, 2250] Loss = 488.68818\n",
      "[16, 2500] Loss = 490.14164\n",
      "[16, 2750] Loss = 490.18180\n",
      "[16, 3000] Loss = 490.55136\n",
      "[16, 3250] Loss = 490.82176\n",
      "[16, 3500] Loss = 491.77850\n",
      "[16, 3750] Loss = 492.15522\n",
      "[16, 4000] Loss = 492.34514\n",
      "Loss iteration 16 = 492.30795\n",
      "[17, 250] Loss = 454.18094\n",
      "[17, 500] Loss = 461.61015\n",
      "[17, 750] Loss = 460.07935\n",
      "[17, 1000] Loss = 455.62622\n",
      "[17, 1250] Loss = 454.05933\n",
      "[17, 1500] Loss = 456.27850\n",
      "[17, 1750] Loss = 458.03293\n",
      "[17, 2000] Loss = 461.41193\n",
      "[17, 2250] Loss = 460.61031\n",
      "[17, 2500] Loss = 462.57218\n",
      "[17, 2750] Loss = 464.22920\n",
      "[17, 3000] Loss = 465.46363\n",
      "[17, 3250] Loss = 467.13058\n",
      "[17, 3500] Loss = 467.28234\n",
      "[17, 3750] Loss = 468.12384\n",
      "[17, 4000] Loss = 468.74611\n",
      "Loss iteration 17 = 468.80071\n",
      "[18, 250] Loss = 423.83251\n",
      "[18, 500] Loss = 433.22013\n",
      "[18, 750] Loss = 437.36374\n",
      "[18, 1000] Loss = 437.61763\n",
      "[18, 1250] Loss = 441.86286\n",
      "[18, 1500] Loss = 442.46004\n",
      "[18, 1750] Loss = 442.06495\n",
      "[18, 2000] Loss = 444.31814\n",
      "[18, 2250] Loss = 445.95292\n",
      "[18, 2500] Loss = 446.40521\n",
      "[18, 2750] Loss = 447.21129\n",
      "[18, 3000] Loss = 448.72873\n",
      "[18, 3250] Loss = 448.00884\n",
      "[18, 3500] Loss = 448.25646\n",
      "[18, 3750] Loss = 448.83371\n",
      "[18, 4000] Loss = 449.05196\n",
      "Loss iteration 18 = 449.39509\n",
      "[19, 250] Loss = 403.95348\n",
      "[19, 500] Loss = 404.59403\n",
      "[19, 750] Loss = 409.69726\n",
      "[19, 1000] Loss = 413.88352\n",
      "[19, 1250] Loss = 415.96142\n",
      "[19, 1500] Loss = 420.82976\n",
      "[19, 1750] Loss = 422.38595\n",
      "[19, 2000] Loss = 423.73004\n",
      "[19, 2250] Loss = 425.91431\n",
      "[19, 2500] Loss = 426.91606\n",
      "[19, 2750] Loss = 428.16253\n",
      "[19, 3000] Loss = 430.34865\n",
      "[19, 3250] Loss = 431.15074\n",
      "[19, 3500] Loss = 432.04170\n",
      "[19, 3750] Loss = 433.87141\n",
      "[19, 4000] Loss = 434.97507\n",
      "Loss iteration 19 = 435.06808\n",
      "[20, 250] Loss = 391.19732\n",
      "[20, 500] Loss = 401.98063\n",
      "[20, 750] Loss = 406.21689\n",
      "[20, 1000] Loss = 404.93014\n",
      "[20, 1250] Loss = 408.17992\n",
      "[20, 1500] Loss = 408.92652\n",
      "[20, 1750] Loss = 412.33512\n",
      "[20, 2000] Loss = 413.07510\n",
      "[20, 2250] Loss = 412.72803\n",
      "[20, 2500] Loss = 414.74267\n",
      "[20, 2750] Loss = 415.99051\n",
      "[20, 3000] Loss = 416.92558\n",
      "[20, 3250] Loss = 419.24674\n",
      "[20, 3500] Loss = 418.69055\n",
      "[20, 3750] Loss = 419.35902\n",
      "[20, 4000] Loss = 420.14205\n",
      "Loss iteration 20 = 420.50320\n",
      "[21, 250] Loss = 388.98900\n",
      "[21, 500] Loss = 388.82116\n",
      "[21, 750] Loss = 387.02922\n",
      "[21, 1000] Loss = 389.77994\n",
      "[21, 1250] Loss = 392.39165\n",
      "[21, 1500] Loss = 392.77421\n",
      "[21, 1750] Loss = 395.16480\n",
      "[21, 2000] Loss = 396.51879\n",
      "[21, 2250] Loss = 398.91034\n",
      "[21, 2500] Loss = 399.50248\n",
      "[21, 2750] Loss = 400.88455\n",
      "[21, 3000] Loss = 402.95895\n",
      "[21, 3250] Loss = 403.66925\n",
      "[21, 3500] Loss = 404.45823\n",
      "[21, 3750] Loss = 404.38758\n",
      "[21, 4000] Loss = 405.30735\n",
      "Loss iteration 21 = 405.53303\n",
      "[22, 250] Loss = 371.63322\n",
      "[22, 500] Loss = 370.58639\n",
      "[22, 750] Loss = 372.15929\n",
      "[22, 1000] Loss = 372.99883\n",
      "[22, 1250] Loss = 375.83046\n",
      "[22, 1500] Loss = 378.64215\n",
      "[22, 1750] Loss = 381.21257\n",
      "[22, 2000] Loss = 382.35795\n",
      "[22, 2250] Loss = 385.71611\n",
      "[22, 2500] Loss = 387.72849\n",
      "[22, 2750] Loss = 388.71883\n",
      "[22, 3000] Loss = 388.67678\n",
      "[22, 3250] Loss = 390.15035\n",
      "[22, 3500] Loss = 391.00549\n",
      "[22, 3750] Loss = 391.60170\n",
      "[22, 4000] Loss = 393.23280\n",
      "Loss iteration 22 = 393.31386\n",
      "[23, 250] Loss = 370.79725\n",
      "[23, 500] Loss = 365.03178\n",
      "[23, 750] Loss = 365.75283\n",
      "[23, 1000] Loss = 365.89974\n",
      "[23, 1250] Loss = 365.83087\n",
      "[23, 1500] Loss = 367.43387\n",
      "[23, 1750] Loss = 370.97350\n",
      "[23, 2000] Loss = 372.72806\n",
      "[23, 2250] Loss = 374.23346\n",
      "[23, 2500] Loss = 374.01426\n",
      "[23, 2750] Loss = 375.52600\n",
      "[23, 3000] Loss = 375.84310\n",
      "[23, 3250] Loss = 377.57430\n",
      "[23, 3500] Loss = 378.08247\n",
      "[23, 3750] Loss = 378.93650\n",
      "[23, 4000] Loss = 379.09755\n",
      "Loss iteration 23 = 379.16326\n",
      "[24, 250] Loss = 350.21337\n",
      "[24, 500] Loss = 352.41610\n",
      "[24, 750] Loss = 353.08495\n",
      "[24, 1000] Loss = 355.04183\n",
      "[24, 1250] Loss = 357.72896\n",
      "[24, 1500] Loss = 359.44168\n",
      "[24, 1750] Loss = 360.20282\n",
      "[24, 2000] Loss = 360.39339\n",
      "[24, 2250] Loss = 360.97044\n",
      "[24, 2500] Loss = 361.77070\n",
      "[24, 2750] Loss = 362.62396\n",
      "[24, 3000] Loss = 363.38667\n",
      "[24, 3250] Loss = 365.05903\n",
      "[24, 3500] Loss = 366.35874\n",
      "[24, 3750] Loss = 367.27562\n",
      "[24, 4000] Loss = 368.78706\n",
      "Loss iteration 24 = 368.72826\n",
      "[25, 250] Loss = 346.63773\n",
      "[25, 500] Loss = 338.09201\n",
      "[25, 750] Loss = 340.38899\n",
      "[25, 1000] Loss = 343.00733\n",
      "[25, 1250] Loss = 345.86405\n",
      "[25, 1500] Loss = 347.50693\n",
      "[25, 1750] Loss = 349.25293\n",
      "[25, 2000] Loss = 351.80369\n",
      "[25, 2250] Loss = 353.53275\n",
      "[25, 2500] Loss = 356.01693\n",
      "[25, 2750] Loss = 357.12873\n",
      "[25, 3000] Loss = 358.56830\n",
      "[25, 3250] Loss = 358.74342\n",
      "[25, 3500] Loss = 359.91243\n",
      "[25, 3750] Loss = 359.56058\n",
      "[25, 4000] Loss = 360.29820\n",
      "Loss iteration 25 = 360.25473\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "(trained_net, adam_losses) = train(net, training_dataset, trainloader, losses, optimizer, criterion, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xu4XVV97vHvm2TnQkLIbe9tyKVBTbFgFegW8GB5EDBcjjVoBeGopEqf2B68tj4t9g+xIueBakulR+2JggaLXMQiEa2Ycmm9VMjmYhAiJoCElBg2SQiBQK6/88cYK3vtnbV21r7Mtfbe6/08z3zmXGPNudaYLJI3Y8w5xlREYGZmVqsxja6AmZmNLA4OMzPrFweHmZn1i4PDzMz6xcFhZmb94uAwM7N+cXCYmVm/ODjMzKxfHBxmZtYv4xpdgSLMmjUrFixY0OhqmJmNKPfff/9zEdF6sP1GZXAsWLCAzs7ORlfDzGxEkfRULfu5q8rMzPrFwWFmZv3i4DAzs35xcJiZWb84OMzMrF8cHGZm1i+FBoekT0h6RNIvJd0gaaKkIyTdK2mtpJskjc/7Tsiv1+X3F5R9zqdy+WOSziiyzmZm1rfCgkPSHOCjQEdEvB4YC5wPXAlcFRELga3ARfmQi4CtEfFa4Kq8H5KOyscdDZwJfFnS2EIqvX49fPrTsG5dIR9vZjYaFN1VNQ6YJGkccAiwETgVuCW/vxw4J28vzq/J758mSbn8xojYGRFPAuuA4wup7ebNcNllsHp1IR9vZjYaFBYcEfHfwBeA9aTA2AbcDzwfEXvybhuAOXl7DvB0PnZP3n9meXmFY/aTtFRSp6TOrq6ugVW6vT2tn312YMebmTWBIruqppNaC0cAhwOTgbMq7BqlQ6q8V628Z0HEsojoiIiO1taDTrVSWem4TZsGdryZWRMosqvqdODJiOiKiN3AvwL/A5iWu64A5gLP5O0NwDyA/P5hwJby8grHDK2WFpgxwy0OM7M+FBkc64ETJR2Sr1WcBjwK3A28O++zBLgtb6/Ir8nv3xURkcvPz3ddHQEsBO4rrNZtbQ4OM7M+FDY7bkTcK+kW4AFgD/AgsAz4PnCjpM/lsmvyIdcA35S0jtTSOD9/ziOSbiaFzh7g4ojYW1S9aWtzV5WZWR+U/lE/unR0dMSAp1U/77x0V9WvfjW0lTIzG+Yk3R8RHQfbzyPHe3OLw8ysTw6O3trb4fnnYdeuRtfEzGxYcnD01taW1gMdC2JmNso5OHorDQJ0d5WZWUUOjt5KLQ7fkmtmVpGDo7dScLjFYWZWkYOjN89XZWbWJwdHb1OmwMSJbnGYmVXh4OhNSq0OtzjMzCpycFTi+arMzKpycFTS3u6uKjOzKhwclbjFYWZWlYOjklJw7NvX6JqYmQ07Do5K2tthz540Z5WZmfXg4KjEgwDNzKpycFTiQYBmZlUVFhySjpT0UNnygqSPS5ohaaWktXk9Pe8vSVdLWidptaTjyj5rSd5/raQl1b91iHi+KjOzqgoLjoh4LCKOiYhjgD8AdgC3ApcAd0bEQuDO/BrgLNLzxBcCS4GvAEiaAVwKnAAcD1xaCpvCuKvKzKyqenVVnQY8HhFPAYuB5bl8OXBO3l4MXBfJz4FpkmYDZwArI2JLRGwFVgJnFlrbWbPSCHK3OMzMDlCv4DgfuCFvt0fERoC8zv+8Zw7wdNkxG3JZtfLijB2bwsMtDjOzAxQeHJLGA+8Avn2wXSuURR/lvb9nqaROSZ1dQ/H0Ps9XZWZWUT1aHGcBD0RE6Z/vm3IXFHld+tt5AzCv7Li5wDN9lPcQEcsioiMiOlpbWwdfa48eNzOrqB7BcQHd3VQAK4DSnVFLgNvKyi/Md1edCGzLXVl3AIskTc8XxRflsmJ5viozs4rGFfnhkg4B3gZ8qKz4CuBmSRcB64Fzc/kPgLOBdaQ7sD4AEBFbJF0GrMr7fTYithRZb8AtDjOzKgoNjojYAczsVbaZdJdV730DuLjK51wLXFtEHatqa4Pt2+Hll2HSpLp+tZnZcOaR49V49LiZWUUOjmo8CNDMrCIHRzVucZiZVeTgqMbzVZmZVeTgqMZdVWZmFTk4qjnkEJgyxS0OM7NeHBx9aWtzi8PMrBcHR188X5WZ2QEcHH1xi8PM7AAOjr64xWFmdgAHR1/a2uC552Dv3kbXxMxs2HBw9KW9Hfbtg82bG10TM7Nhw8HRFw8CNDM7gIOjLx4EaGZ2AAdHXzxflZnZARwcfXFXlZnZARwcfZk+HcaNc1eVmVmZQoND0jRJt0j6laQ1kt4saYaklZLW5vX0vK8kXS1pnaTVko4r+5wlef+1kpZU/8YhNmYMtLa6xWFmVqboFscXgR9GxOuANwJrgEuAOyNiIXBnfg1wFrAwL0uBrwBImgFcCpwAHA9cWgqbumhvd4vDzKxMYcEhaSpwMnANQETsiojngcXA8rzbcuCcvL0YuC6SnwPTJM0GzgBWRsSWiNgKrATOLKreB2hrc4vDzKxMkS2OVwNdwNclPSjpa5ImA+0RsREgr/MVaOYAT5cdvyGXVSuvD89XZWbWQ5HBMQ44DvhKRBwLvER3t1QlqlAWfZT3PFhaKqlTUmdXV9dA6ltZab6qOOArzcyaUpHBsQHYEBH35te3kIJkU+6CIq+fLdt/Xtnxc4Fn+ijvISKWRURHRHS0trYO3Vm0tcHLL8NLLw3dZ5qZjWCFBUdE/BZ4WtKRueg04FFgBVC6M2oJcFveXgFcmO+uOhHYlruy7gAWSZqeL4ovymX1URoE6O4qMzMgdScV6SPA9ZLGA08AHyCF1c2SLgLWA+fmfX8AnA2sA3bkfYmILZIuA1bl/T4bEVsKrne38kGAr3lN3b7WzGy4KjQ4IuIhoKPCW6dV2DeAi6t8zrXAtUNbuxp5viozsx48cvxgPF+VmVkPDo6DKV1od4vDzAxwcBzchAkwbZpbHGZmmYOjFh49bma2n4OjFp6vysxsPwdHLdziMDPbz8FRC89XZWa2n4OjFu3tsGUL7N7d6JqYmTWcg6MWpUGAzz3X2HqYmQ0DDo5aeL4qM7P9HBy1KJ+vysysyTk4auEWh5nZfg6OWrjFYWa2n4OjFlOnwvjxbnGYmeHgqI3U/QhZM7Mm5+ColUePm5kBDo7aeb4qMzOg4OCQ9BtJD0t6SFJnLpshaaWktXk9PZdL0tWS1klaLem4ss9ZkvdfK2lJte8rlFscZmZAfVocb42IYyKi9AjZS4A7I2IhcGd+DXAWsDAvS4GvQAoa4FLgBOB44NJS2NRV6RpHRN2/2sxsOGlEV9ViYHneXg6cU1Z+XSQ/B6ZJmg2cAayMiC0RsRVYCZxZ70rT1ga7dsG2bXX/ajOz4aTo4AjgR5Lul7Q0l7VHxEaAvM6DJJgDPF127IZcVq28B0lLJXVK6uzq6hri06B7LIevc5hZkys6OE6KiONI3VAXSzq5j31VoSz6KO9ZELEsIjoioqO19JzwoVQaPe7rHGbW5AoNjoh4Jq+fBW4lXaPYlLugyOvS38QbgHllh88FnumjvL48etzMDCgwOCRNlnRoaRtYBPwSWAGU7oxaAtyWt1cAF+a7q04EtuWurDuARZKm54vii3JZfXm+KjMzAMYV+NntwK2SSt/zrYj4oaRVwM2SLgLWA+fm/X8AnA2sA3YAHwCIiC2SLgNW5f0+GxFbCqx3ZbNmpRHkbnGYWZMrLDgi4gngjRXKNwOnVSgP4OIqn3UtcO1Q17Ffxo2DmTPd4jCzpueR4/3hQYBmZg6OfnFwmJk5OPrF81WZmTk4+sUtDjMzB0e/tLenKUdeeaXRNTEzaxgHR3+UBgEWMaWJmdkIUVNwSHqNpAl5+xRJH5U0rdiqDUOer8rMrOYWx3eAvZJeC1wDHAF8q7BaDVeer8rMrObg2BcRe4B3Av8YEZ8AZhdXrWHK81WZmdUcHLslXUCaW+r2XNZSTJWGMc9XZWZWc3B8AHgzcHlEPCnpCOBfiqvWMDV5MhxyiFscZtbUapqrKiIeBT4KkGeoPTQiriiyYsOWBwGaWZOr9a6qeyRNzc///gXwdUn/UGzVhikPAjSzJldrV9VhEfEC8C7g6xHxB8DpxVVrGGtrc4vDzJparcExLj+t7zy6L443p/Z2tzjMrKnVGhyfJT117/GIWCXp1cDa4qo1jLW1pZHj+/Y1uiZmZg1R68XxbwPfLnv9BPDHRVVqWGtvh717YcuW9FRAM7MmU+vF8bmSbpX0rKRNkr4jaW6Nx46V9KCk2/PrIyTdK2mtpJskjc/lE/Lrdfn9BWWf8alc/pikM/p/mkPIgwDNrMnV2lX1dWAFcDgwB/heLqvFx4A1Za+vBK6KiIXAVuCiXH4RsDUiXgtclfdD0lHA+cDRwJnAlyWNrfG7h54HAZpZk6s1OFoj4usRsScv3wBaD3ZQbpX8T+Br+bWAU4Fb8i7LgXPy9uL8mvz+aXn/xcCNEbEzIp4E1gHH11jvoecWh5k1uVqD4zlJ78vdTmMlvQ/YXMNx/wj8FVC6kjwTeD7PewWwgdSCIa+fBsjvb8v77y+vcMx+kpZK6pTU2VXktOcODjNrcrUGxwdJt+L+FtgIvJs0DUlVkt4OPBsR95cXV9g1DvJeX8d0F0Qsi4iOiOhobT1oY2jgZs6EMWPcVWVmTavWu6rWA+8oL5P0cVKLopqTgHdIOhuYCEzN+0+TNC63KuYCz+T9NwDzgA2SxgGHAVvKykvKj6m/MWOgtdUtDjNrWoN5AuBf9PVmRHwqIuZGxALSxe27IuK9wN2kFguk2XZvy9sr8mvy+3dFROTy8/NdV0cAC4H7BlHvwfN8VWbWxGpqcVRRqQupFn8N3Cjpc8CDpAdDkdfflLSO1NI4HyAiHpF0M/AosAe4OCL2DqLeg+f5qsysiQ0mOA64zlB1x4h7gHvy9hNUuCsqIl4Bzq1y/OXA5QOpZCHa2+HxxxtdCzOzhugzOCRtp3JACJhUSI1GArc4zKyJ9RkcEXFovSoyorS1wUsvpWXy5EbXxsysrgZzcbx5lUaPu9VhZk3IwTEQHgRoZk3MwTEQnq/KzJqYg2Mg3OIwsybm4BiIUnC4xWFmTcjBMRATJ8LUqW5xmFlTcnAMlMdymFmTcnAMlOerMrMm5eAYKLc4zKxJOTgGyi0OM2tSDo6BamuDzZthz56D72tmNoo4OAaqvR0iUniYmTURB8dAeSyHmTUpB8dAefS4mTWpwoJD0kRJ90n6haRHJP1tLj9C0r2S1kq6SdL4XD4hv16X319Q9lmfyuWPSTqjqDr3i+erMrMmVWSLYydwakS8ETgGOFPSicCVwFURsRDYClyU978I2BoRrwWuyvsh6SjSY2SPBs4EvixpbIH1ro1bHGbWpAoLjkhezC9b8hLAqcAtuXw5cE7eXpxfk98/TZJy+Y0RsTMingTWUeHRs3U3bRq0tLjFYWZNp9BrHJLGSnoIeBZYCTwOPB8RpXtYNwBz8vYc4GmA/P42YGZ5eYVjGkfyIEAza0qFBkdE7I2IY4C5pFbC71XaLa9V5b1q5T1IWiqpU1JnV1fXQKvcPw4OM2tCdbmrKiKeB+4BTgSmSSo963wu8Eze3gDMA8jvHwZsKS+vcEz5dyyLiI6I6GhtbS3iNA7k0eNm1oSKvKuqVdK0vD0JOB1YA9wNvDvvtgS4LW+vyK/J798VEZHLz893XR0BLATuK6re/eIWh5k1oXEH32XAZgPL8x1QY4CbI+J2SY8CN0r6HPAgcE3e/xrgm5LWkVoa5wNExCOSbgYeBfYAF0fE3gLrXbtSiyMiXfMwM2sChQVHRKwGjq1Q/gQV7oqKiFeAc6t81uXA5UNdx0Fra4OdO2H79vRgJzOzJuCR44NRGgTo7iozayIOjsHwfFVm1oQcHIPh0eNm1oQcHIPh+arMrAk5OAajNF7ELQ4zayIOjsFoaYEZM9ziMLOm4uAYLA8CNLMm4+AYrPZ2B4eZNRUHx2C1tbmrysyaioNjsNraYONG2LPn4PuamY0CDo7BOu00eOEFuOKKRtfEzKwuHByD9c53wgUXwGc+A6tWNbo2ZmaFc3AMhS99CQ4/HN73PnjppUbXxsysUA6OoTB9OixfDmvXwic/2ejamJkVysExVN76VvjLv4R//me4/fZG18bMrDAOjqH0uc/BG94AF13ksR1mNmo5OIbShAlw/fWwbRv86Z+mJwOamY0yRT5zfJ6kuyWtkfSIpI/l8hmSVkpam9fTc7kkXS1pnaTVko4r+6wlef+1kpZU+85h4fWvhyuvhO99D7761UbXxsxsyBXZ4tgD/GVE/B5wInCxpKOAS4A7I2IhcGd+DXAWsDAvS4GvQAoa4FLgBNIjZy8thc2w9ZGPwOmnwyc+Ab/+daNrY2Y2pAoLjojYGBEP5O3twBpgDrAYWJ53Ww6ck7cXA9dF8nNgmqTZwBnAyojYEhFbgZXAmUXVe0iMGQPf+Ebqunr/+2H37kbXyMxsyNTlGoekBcCxwL1Ae0RshBQuQH6MHnOAp8sO25DLqpUPb3PmwLJlcN996aK5mdkoUXhwSJoCfAf4eES80NeuFcqij/Le37NUUqekzq6uroFVdqi9+92wZEkKjv/6r0bXxsxsSBQaHJJaSKFxfUT8ay7elLugyOvSfasbgHllh88FnumjvIeIWBYRHRHR0Vp6Mt9wcPXVMH9+6rLavr3RtTEzG7Qi76oScA2wJiL+oeytFUDpzqglwG1l5Rfmu6tOBLblrqw7gEWSpueL4oty2cgwdSpcdx08+WS6WG5mNsIV2eI4CXg/cKqkh/JyNnAF8DZJa4G35dcAPwCeANYBXwX+N0BEbAEuA1bl5bO5bOT4wz+ESy6Ba66BW29tdG3MzAZFMQoHqXV0dERnZ2ejq9HTrl3w5jfDU0/Bww/D7NmNrpGZWQ+S7o+IjoPt55Hj9TJ+fBpVvmMHfPCDHlVuZiOWg6OeXvc6+MIX4Ic/THdaOTzMbARycNTbn/85vOc98OlPwx//MWzd2ugamZn1i4Oj3iS44Qb4+79P068fc4zHeJjZiOLgaAQJ/uIv4Cc/gbFj011XV14J+/Y1umZmZgfl4Gik44+HBx+Ed70r3a579tl+joeZDXsOjkY77DC46ab05MD/+A944xvhrrsaXSszs6ocHMOBBB/6UJoQcdq0NCX7pz8Ne/Y0umZmZgdwcAwnv//70NkJf/IncNllcOqpsGFDo2tlZtaDg2O4mTwZrr0WvvlNeOCBdNfV7bc3ulZmZvs5OIar970vBce8efBHf5TuwnrxxUbXyszMwTGs/e7vpjEeH/4wXHVVejjUxz/ux9GaWUM5OIa7iRPhn/4pBcjb3w5f/jIceSScdRZ8//se+2FmdefgGClOPDFNkrh+Pfzt38IvfpGCZOHCNArdU5eYWZ04OEaaV70q3ar71FNp/Mfhh8MnP5m6sZYuhdWrG11DMxvlHBwjVUsLnHce/PjHafT5e98L//IvaQDhySfDt78Nu3c3upZmNgo5OEaDY46Br341jfn4/OfT+rzzYO5cuPDCFCibNjW6lmY2ShT5zPFrJT0r6ZdlZTMkrZS0Nq+n53JJulrSOkmrJR1XdsySvP9aSUsqfZdlM2akbqu1a2HFijSA8N/+Dd7//tTFdeyxaU6su+6CnTsbXVszG6EKe3SspJOBF4HrIuL1uezvgC0RcYWkS4DpEfHX+VnkHwHOBk4AvhgRJ0iaAXQCHUAA9wN/EBF9Xgkelo+ObZR9+1JX1h13pOVnP0tTmRxyCLz1rbBoUVqOPDJNfWJmTavWR8cW+sxxSQuA28uC4zHglIjYKGk2cE9EHCnp/+XtG8r3Ky0R8aFc3mO/ahwcfdi+He6+G370oxQk69al8vnzU4Ccdhq85S2pm8vMmkqtwTGuHpUp0x4RGwFyeLTl8jnA02X7bchl1coPIGkpsBRg/vz5Q1ztUeTQQ+Ed70gLwBNPdIfITTfB176Wyn/nd1KAlJajjoIxviRmZvUPjmoq9ZFEH+UHFkYsA5ZBanEMXdVGuVe/Gv7sz9KyZw889BD89KfpIVP//u9p7AikWXtPOqk7SDo60uBEM2s69Q6OTZJml3VVlZ5atAGYV7bfXOCZXH5Kr/J76lDP5jRuXAqEjg742McgIrVIfvKT7uX730/7jh8Pb3pTCpPjjoM3vCENRhw3XP4tYmZFqfef8hXAEuCKvL6trPzDkm4kXRzflsPlDuD/lO6+AhYBn6pznZuXBK95TVqW5BvannsuXWAvBclVV3WPF5k4EY4+OoVI+TJrVuPOwcyGXJF3Vd1Aai3MAjYBlwLfBW4G5gPrgXMjYoskAf8XOBPYAXwgIjrz53wQ+Jv8sZdHxNcP9t2+OF5HO3fCmjVpxHr5Uj5uZPbsnkFy9NGpi+ywwxpXbzM7wLC4q6pRHBzDwKZN8PDDPcPkkUdg167ufaZNgwULupcjjuj5eurURtTcrGkN17uqrFm0t6fl9NO7y3bvToMTH30UfvOb7uXXv053du3Y0fMzpk/vDpT589Myb15a5s9Pn+87vczqzsFh9dPSkm7rPeqoA9+LSNdPygOltKxZk24XfumlAz9v7tyeYVLanjcvBcvMmWk/MxsyDg4bHiRobU3Lm9504PsRaer4p59Oy/r1Pbd/+tM0DmXPngOPnTo1BcjMmelCffm6d1l7e6rD2LHFn7PZCOXgsJFBSnNxzZiRZgCuZO/edG2lFChdXakVs3lz93rzZnjssbR+4YXKnzNmTHeIvOpV3d1ulbZnzXLIWNNxcNjoMXZsej7J4YfDCSccfP9du2DLlu5Q6epKwVNafvvbtF67Nq1ffrny50ydmi70T5/eve5ru3yZMGFo/xuY1YGDw5rX+PGp5fCqVx1834g0z1fvYNm8OXWhlZbnn4fHH+/efvHFvj930qQUIDNmHBgqpbJp09JUMaVlypTu9ZQpHnRpdef/48xqIaWWxdSpaYR8rXbvTgFSCpLykNm6NbV4yl8/9VSazXjr1oOHTsnEiZUD5ZBD0jJ5cvd2X0vpuNLnTJ7sULKK/H+FWZFaWrov+vdXKXSefz61drZvT2FSy3rbttQi2rEj3Y22Y0da+vtUyIkTe4ZJebhMmVJbKJXvM2lS6p6bODGtJ0zwLdUjkIPDbLgaTOhUs3t3ulbTO1BeeiktL77YM4TKl/Jg2rgxrV9+uftzBjqYuKXlwDApbVda1/petdeVylta/DyafnBwmDWTlpa0DPWo/Ig0/UwpiPpadu6EV15J6/Ltvso2b65c/soraRksKV3zKi0TJvRcV9ouXyqFXqXtlpZ0fKV1tbKWltRlOHbssAk3B4eZDZ7U/a/3GTPq+90RqSVVCpOXX+4ZQOVLX2W7dqXtXbt6bvcu27at+/N7B93Onf3vDuyPcePSUgqT0rp8++1vhy98obg64OAws5GuvLUwHOzbVzlQXnklhcquXWldvt17Xb69Z8+B62rbu3fX5emdDg4zs6E0Zky6CWDSpEbXpDC+ncHMzPrFwWFmZv3i4DAzs35xcJiZWb+MmOCQdKakxyStk3RJo+tjZtasRkRwSBoLfAk4CzgKuEBShacBmZlZ0UZEcADHA+si4omI2AXcCCxucJ3MzJrSSAmOOcDTZa835LL9JC2V1Cmps6urq66VMzNrJiNlAGClCVp6zKgWEcuAZQCSuiQ9ld+aBTxXbPWGrWY+d2ju8/e5N6/BnP/v1LLTSAmODcC8stdzgWeq7RwR+6cTldQZER0F1m3YauZzh+Y+f597c5471Of8R0pX1SpgoaQjJI0HzgdWNLhOZmZNaUS0OCJij6QPA3cAY4FrI+KRBlfLzKwpjYjgAIiIHwA/GMChy4a6LiNIM587NPf5+9ybV+HnrxjoU7vMzKwpjZRrHGZmNkyM2uBo9ilKJP1G0sOSHpLU2ej6FEnStZKelfTLsrIZklZKWpvX0xtZxyJVOf/PSPrv/Ps/JOnsRtaxKJLmSbpb0hpJj0j6WC4f9b9/H+de+G8/Kruq8hQlvwbeRrqVdxVwQUQ82tCK1ZGk3wAdETHq72eXdDLwInBdRLw+l/0dsCUirsj/cJgeEX/dyHoWpcr5fwZ4MSKKfYZog0maDcyOiAckHQrcD5wD/Amj/Pfv49zPo+DffrS2ODxFSROJiP8EtvQqXgwsz9vLSX+gRqUq598UImJjRDyQt7cDa0izSoz637+Pcy/caA2Og05R0gQC+JGk+yUtbXRlGqA9IjZC+gMGtDW4Po3wYUmrc1fWqOuq6U3SAuBY4F6a7Pfvde5Q8G8/WoPjoFOUNIGTIuI40ozCF+fuDGseXwFeAxwDbAT+vrHVKZakKcB3gI9HxAuNrk89VTj3wn/70Roc/ZqiZDSKiGfy+lngVlL3XTPZlPuAS33Bzza4PnUVEZsiYm9E7AO+yij+/SW1kP7ivD4i/jUXN8XvX+nc6/Hbj9bgaOopSiRNzhfLkDQZWAT8su+jRp0VwJK8vQS4rYF1qbvSX5rZOxmlv78kAdcAayLiH8reGvW/f7Vzr8dvPyrvqgLIt6D9I91TlFze4CrVjaRXk1oZkGYH+NZoPn9JNwCnkGYF3QRcCnwXuBmYD6wHzo2IUXkBucr5n0LqqgjgN8CHSn3+o4mktwA/Bh4G9uXivyH19Y/q37+Pc7+Agn/7URscZmZWjNHaVWVmZgVxcJiZWb84OMzMrF8cHGZm1i8ODjMz6xcHh9lBSPpZXi+Q9L+G+LP/ptJ3mQ1nvh3XrEaSTgE+GRFv78cxYyNibx/vvxgRU4aifmb14haH2UFIejFvXgH8YX7GwSckjZX0eUmr8oRyH8r7n5Kfk/At0uAsJH03Tzj5SGnSSUlXAJPy511f/l1KPi/pl/m5Ku8p++x7JN0i6VeSrs8jiM3qZsQ8c9xsGLiEshZHDoBtEfEmSROAn0r6Ud73eOD1EfFkfv3BiNgiaRKwStJ3IuISSR+OiGMqfNe7SKN/30gaEb5K0n/m944FjibNv/ZT4CTgJ0N/umaVucVhNnCLgAslPUSa4mImsDC/d19ZaAB8VNIvgJ+TJuBcSN/eAtyQJ6vbBPwH8Kayz96QJ7F7CFgwJGdjViO3OMwGTsAtnlonAAAA2UlEQVRHIuKOHoXpWshLvV6fDrw5InZIugeYWMNnV7OzbHsv/nNsdeYWh1nttgOHlr2+A/jzPLU1kn43z0bc22HA1hwarwNOLHtvd+n4Xv4TeE++jtIKnAzcNyRnYTZI/peKWe1WA3tyl9M3gC+SuokeyBeou6j8iNIfAn8maTXwGKm7qmQZsFrSAxHx3rLyW4E3A78gzXL6VxHx2xw8Zg3l23HNzKxf3FVlZmb94uAwM7N+cXCYmVm/ODjMzKxfHBxmZtYvDg4zM+sXB4eZmfWLg8PMzPrl/wMbm6Gt2nZUjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f94b3af50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_losses(adam_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store predictions in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(net, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x,y,z,v) = testing_data_inp[0].shape\n",
    "predicted_brain = reconstruct_brain(predictions,[x,y,z,v])\n",
    "predicted_brain = replace_background(predicted_brain, testing_data_inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 56, 46, 2)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_brain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate error on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test data: 8102.562012\n",
      "Mean absolute error on test data: 41.711079\n"
     ]
    }
   ],
   "source": [
    "mse = ((predicted_brain - testing_data_out[0]) ** 2).mean()\n",
    "print('MSE on test data: %f' % (mse))\n",
    "\n",
    "l1 = (np.absolute(predicted_brain - testing_data_out[0])).mean()\n",
    "print('Mean absolute error on test data: %f' % (l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'viz_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-876aa343d10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviz_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_data_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_data_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_data_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'viz_pred' is not defined"
     ]
    }
   ],
   "source": [
    "viz_pred(testing_data_inp[0], testing_data_inp[0], testing_data_out[0], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123.1389"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_brain.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098.3759"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data_out[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the target and the predicted scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to = \"/home/ubuntu/project/Dataset/EXP_AWS_1/TrueModel\"\n",
    "\n",
    "predicted_scan = nib.Nifti1Image(predicted_brain, affine_mat)\n",
    "nib.save(predicted_scan, save_to + \"/Predicted_Subj1Scan2_AWS.nii.gz\" )\n",
    "\n",
    "target_scan = nib.Nifti1Image(testing_data_out[0][:,:,:,0], affine_mat)\n",
    "nib.save(target_scan, save_to + \"/Target_Subj1Scan2_AWS.nii.gz\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(trained_net.state_dict(), '/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/True_Model.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_net = Net()\n",
    "trained_net.cuda()\n",
    "trained_net.load_state_dict(torch.load('/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/True_Model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mPredicted_Subj7Scan2_AWS.nii.gz\u001b[0m  \u001b[01;31mTarget_Subj7Scan2_AWS.nii.gz\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
