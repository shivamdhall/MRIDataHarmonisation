{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - CrossX - Patch - AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use both scans of subjects 1-8 from the PETMR and TRIO dataset for training.\n",
    "\n",
    "We used the scan of subjects 9-10 also from the PETMR and TRIO dataset for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function simply uploads the testing and training scans into lists of numpy arrays\n",
    "#the data is not yet sliced or patched at this stage\n",
    "\n",
    "#specify in a list what scans to use for training and what scans to use for testing\n",
    "\n",
    "\n",
    "def get_data(petmr_path, trio_path, scans_dict):\n",
    "    \n",
    "    train_data_inp = []\n",
    "    test_data_inp = []\n",
    "    train_data_out = []\n",
    "    test_data_out = []\n",
    "    paths = [petmr_path, trio_path]\n",
    "    \n",
    "    for data_path in paths:\n",
    "        if(data_path == petmr_path):\n",
    "            print \"Uploading Inputs:\"\n",
    "            training_data_store = train_data_inp\n",
    "            testing_data_store = test_data_inp\n",
    "        else:\n",
    "            print \"Uploading Outputs\"\n",
    "            training_data_store = train_data_out\n",
    "            testing_data_store = test_data_out\n",
    "        os.chdir(data_path)\n",
    "        for key, subjs in scans_dict.iteritems():\n",
    "            for subj_scan in subjs:\n",
    "                scan_image = nib.load(str(data_path) + \"/Subj\" + subj_scan + \"/Brain_Extracted.nii.gz\")\n",
    "                scan_data = scan_image.get_data()\n",
    "                #all scans have the same affine mat because registration has already been performed\n",
    "                #we only need it for saving the predictions as a NIfTI file\n",
    "                affine_mat = scan_image.affine\n",
    "                #get b=0 volumes only\n",
    "                bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/Subj\" + subj_scan + \"/NODDI.bval\",\\\n",
    "                                                          str(data_path) + \"/Subj\" + subj_scan + \"/NODDI.bvec\")\n",
    "                #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "                gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "                s0s_scan = scan_data[:, :, :, gtab_scan.b0s_mask]\n",
    "            \n",
    "                if(key == \"training\"):\n",
    "                    print (\"Training: Subj%s\" % subj_scan)\n",
    "                    #append this data to the list containing the training data\n",
    "                    training_data_store.append(s0s_scan)\n",
    "                else:\n",
    "                    print (\"Testing: Subj%s\" % subj_scan)\n",
    "                    testing_data_store.append(s0s_scan)\n",
    "    return (train_data_inp, train_data_out, test_data_inp, test_data_out, affine_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "\n",
    "def patchify(data_scans_inp, data_scans_out, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan = data_scans_out[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel = target_scan[pos_x,pos_y,pos_z,volume]\n",
    "\n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store.append(target_voxel)\n",
    "                    \n",
    "    return (input_patches_store, target_patches_store)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "#This version of the functions only considers voxels wholly contained within the brain\n",
    "\n",
    "def patchify_brain_only(data_scans_inp, data_scans_out, patch_size):\n",
    "    \n",
    "    input_patches_store = []\n",
    "    target_patches_store = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans_inp)):\n",
    "        input_scan = data_scans_inp[scan_no]\n",
    "        target_scan = data_scans_out[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        if((patch_size-1) % 2 != 0):\n",
    "            print \"The patch size is not compatible\"\n",
    "            return\n",
    "        padding = ((patch_size-1)/2)\n",
    "        #pad the input scan\n",
    "        full_padding = ((padding, padding), (padding, padding), (padding,padding), (0,0))\n",
    "        padded_scan = np.pad(input_scan, full_padding, mode='constant', constant_values=0)\n",
    "\n",
    "        #extract patches from the input scan\n",
    "        #use unpadded scan (original input scan) to identify non-backround voxels\n",
    "\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(v):\n",
    "            for pos_x in range(0, x):\n",
    "                for pos_y in range(0,y):\n",
    "                    for pos_z in range(0, z):\n",
    "                        if(input_scan[pos_x,pos_y,pos_z,volume] == 0):\n",
    "                            #this is a background voxel, ignore it\n",
    "                            continue\n",
    "                        input_patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        target_voxel = target_scan[pos_x,pos_y,pos_z,volume]\n",
    "\n",
    "                        #store the patch and the target\n",
    "                        input_patches_store.append(input_patch)\n",
    "                        target_patches_store.append(target_voxel)\n",
    "                    \n",
    "    return (input_patches_store, target_patches_store)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(dataset, mean=None, std=None):\n",
    "    data_array = np.array(dataset)\n",
    "    if mean==None and std==None:\n",
    "        #This is the training data\n",
    "        mean = np.mean(data_array)\n",
    "        std = np.std(data_array)\n",
    "    #normalise the data\n",
    "    data_array = (data_array - mean)/std\n",
    "    return (data_array, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_pred(inputs, predictions, labels, sliceNo, volume):\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1).set_axis_off()\n",
    "    plt.imshow(inputs[:,:,sliceNo,volume].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2).set_axis_off()\n",
    "    plt.imshow(predictions[:,:,sliceNo,volume].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.subplot(1, 3, 3).set_axis_off()\n",
    "    plt.imshow(labels[:,:,sliceNo,volume].T, cmap='gray', origin='lower')\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Inputs:\n",
      "Training: Subj1Scan1\n",
      "Training: Subj2Scan1\n",
      "Training: Subj3Scan2\n",
      "Training: Subj4Scan1\n",
      "Training: Subj5Scan1\n",
      "Training: Subj6Scan2\n",
      "Training: Subj7Scan1\n",
      "Training: Subj8Scan2\n",
      "Testing: Subj9Scan1\n",
      "Uploading Outputs\n",
      "Training: Subj1Scan1\n",
      "Training: Subj2Scan1\n",
      "Training: Subj3Scan2\n",
      "Training: Subj4Scan1\n",
      "Training: Subj5Scan1\n",
      "Training: Subj6Scan2\n",
      "Training: Subj7Scan1\n",
      "Training: Subj8Scan2\n",
      "Testing: Subj9Scan1\n",
      "Number of scans used for training input: 8\n",
      "Number of scans used for training output: 8\n",
      "Number of scans used for testing input: 1\n",
      "Number of scans used for testing output: 1\n"
     ]
    }
   ],
   "source": [
    "#upload the data\n",
    "petmr_data_path = '/home/ubuntu/project/Dataset/PETMR_data'\n",
    "trio_data_path = '/home/ubuntu/project/Dataset/TRIO_data'\n",
    "\n",
    "training_scans = [\"1Scan1\", \"2Scan1\",\"3Scan2\",\"4Scan1\", \"5Scan1\", \\\n",
    "                \"6Scan2\",\"7Scan1\",\"8Scan2\",]\n",
    "\n",
    "\n",
    "testing_scans = [\"9Scan1\"]\n",
    "\n",
    "(training_data_inp, training_data_out, testing_data_inp, testing_data_out, affine_mat) = \\\n",
    "        get_data(petmr_data_path, trio_data_path, {\"training\":training_scans, \"testing\":testing_scans})\n",
    "\n",
    "print (\"Number of scans used for training input: %d\" % len(training_data_inp))\n",
    "print (\"Number of scans used for training output: %d\" % len(training_data_out))\n",
    "print (\"Number of scans used for testing input: %d\" % len(testing_data_inp))\n",
    "print (\"Number of scans used for testing output: %d\" % len(testing_data_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patchify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchifying training set\n",
      "Patchifying testing set\n"
     ]
    }
   ],
   "source": [
    "print \"Patchifying training set\"\n",
    "(training_input, training_target) = patchify(training_data_inp, training_data_out, 7)\n",
    "\n",
    "print \"Patchifying testing set\"\n",
    "(testing_input, testing_target) = patchify(testing_data_inp, testing_data_out, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nember of training examples : 16967067\n",
      "Nember of testing examples : 2170350\n"
     ]
    }
   ],
   "source": [
    "print (\"Nember of training examples : %d\" % len(training_input))\n",
    "print (\"Nember of testing examples : %d\" % len(testing_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset class for our data\n",
    "\n",
    "class MRIdataset(Dataset):\n",
    "    \"\"\"MRI b=0 dataset for patches.\"\"\"\n",
    "\n",
    "    def __init__(self, input_patches, target_patches, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_patches: Input patches\n",
    "            target_patches: Corresponding target patches of the input patches\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        \"\"\"\n",
    "        self.input_patches = input_patches\n",
    "        self.target_patches = target_patches\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_patch = np.array(self.input_patches[idx])\n",
    "        target_patch = np.array(self.target_patches[idx])\n",
    "        sample = {'input': input_patch, 'target': target_patch}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class To_Tensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inp, out = sample['input'], sample['target']\n",
    "        \n",
    "        #first expand dimension because torch expects H x W x D x C\n",
    "        #currently we only have H x W x D\n",
    "        aug_inp = np.expand_dims(inp, 3)\n",
    "        \n",
    "        #The target is a single voxel,\n",
    "        #Conver it to an array\n",
    "        aug_out = np.array([out])\n",
    "\n",
    "        # swap channel axis because\n",
    "        # numpy: H x W x D x C\n",
    "        # torch: C x D x H x W\n",
    "        aug_inp = aug_inp.transpose((3, 2, 0, 1))\n",
    "        \n",
    "        return {'input': torch.Tensor(aug_inp),\n",
    "                'target': torch.Tensor(aug_out)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, training_dataset, trainloader, losses_list, optimizer, criterion, epochs):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): #done in batches\n",
    "            # get the inputs\n",
    "            inputs = data['input']\n",
    "            labels = data['target']\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize/update weights\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0] #loss is a variable tensor of size 1, we index to get the value out\n",
    "            if i % 10000 == 9999:    # print every 250 mini-batches\n",
    "                print('[%d, %d]' % (epoch + 1, i + 1))\n",
    "        total_loss = running_loss / i\n",
    "        losses_list.append(total_loss)\n",
    "        print('Loss iteration %d = %.5f' % (epoch+1, total_loss ))\n",
    "        '''   \n",
    "        test_error = 0\n",
    "        total = 0\n",
    "        for test_data in testloader: #batch processing\n",
    "            test_inputs = test_data['inp']\n",
    "            test_labels = test_data['out']\n",
    "            total += len(test_labels)\n",
    "\n",
    "            test_outputs = net(Variable(test_inputs))\n",
    "\n",
    "            test_error += (torch.nn.functional.mse_loss(test_outputs.data, test_labels, size_average=False)).data[0]\n",
    "\n",
    "        test_error /= total\n",
    "        print('MSE on test data: %f' % (test_error))\n",
    "        Adam_acc.append(test_error)\n",
    "        '''\n",
    "    print('Finished Training')\n",
    "    return (net, losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_losses(losses_list):\n",
    "    plt.figure\n",
    "    plt.plot(range(1,len(losses_list)+1), losses_list, 'r-')\n",
    "    plt.xlabel('iteration')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def testing_error(net, testloader):\n",
    "    net.eval()\n",
    "    test_error = 0\n",
    "    total = 0\n",
    "    for test_data in testloader: #batch processing\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        total += len(test_labels)\n",
    "        \n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "        \n",
    "        test_predictions = net(test_inputs)\n",
    "        \n",
    "        #Use MSE loss\n",
    "        test_error += (torch.nn.functional.mse_loss(Variable(test_predictions.data), test_labels, size_average=False)).data[0]\n",
    "\n",
    "    test_error /= total\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(net, testloader):\n",
    "    net.eval()\n",
    "    for index, test_data in enumerate(testloader):\n",
    "        test_inputs = test_data['input']\n",
    "        test_labels = test_data['target']\n",
    "        \n",
    "        test_inputs, test_labels = Variable(test_inputs.cuda()), Variable(test_labels.cuda())\n",
    "\n",
    "        #store the predictions in a numpy array which we can reshape later\n",
    "        test_predictions = net(test_inputs)\n",
    "        if(index == 0):\n",
    "            predictions = test_predictions.data.cpu().numpy() \n",
    "\n",
    "        else:\n",
    "            predictions = np.concatenate((predictions, test_predictions.data.cpu().numpy()), axis=0)\n",
    "            \n",
    "    #convert back to numpy dimensions of (HxWxDxCxNumbExpls)\n",
    "    predictions = predictions.transpose(3,4,2,1,0)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_brain(predictions, dimensions):\n",
    "    \n",
    "    size_x = dimensions[0]\n",
    "    size_y = dimensions[1]\n",
    "    size_z = dimensions[2]\n",
    "    size_v = dimensions[3]\n",
    "    #assume we have given it a single scan to reconstruct\n",
    "    reconstructed = np.reshape(predictions, [size_v, size_x, size_y, size_z], order='C')\n",
    "    reconstructed = reconstructed.transpose(1,2,3,0)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data using pytorch data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MRIdataset(training_input, training_target, transform=transforms.Compose([To_Tensor()]))\n",
    "testing_dataset = MRIdataset(testing_input, testing_target, transform=transforms.Compose([To_Tensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_dataset, batch_size=160,\n",
    "                        shuffle=True, num_workers=8)\n",
    "testloader = DataLoader(testing_dataset, batch_size=160,\n",
    "                        shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Relu\n",
    "\n",
    "--(WxHx2x1)--\n",
    "\n",
    "conv1 = receptive field -> (3x3x3), zero padding -> 2,  number of filters -> 10\n",
    "\n",
    "--(W+2xH+2x4x10)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv2 = receptive field -> (1x1x1), number of filters -> 15\n",
    "\n",
    "--(W+2xH+2x4x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv3 = receptive field -> (3x3x3), number of filters -> 15\n",
    "\n",
    "--(WxHx2x15)--\n",
    "\n",
    "--BATCH then RELU--\n",
    "\n",
    "conv4 = receptive field -> (1x1x2), number of filters -> 1\n",
    "\n",
    "--(WxHx1x1)--\n",
    "\n",
    "--RELU--\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv3d (1, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch1): BatchNorm3d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop1): Dropout(p=0.15)\n",
      "  (conv2): Conv3d (100, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch2): BatchNorm3d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop2): Dropout(p=0.15)\n",
      "  (conv3): Conv3d (100, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (batch3): BatchNorm3d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop3): Dropout(p=0.15)\n",
      "  (conv4): Conv3d (100, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (batch4): BatchNorm3d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (drop4): Dropout(p=0.15)\n",
      "  (conv5): Conv3d (100, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 100, 3)\n",
    "        self.batch1 = nn.BatchNorm3d(100)\n",
    "        self.drop1 = nn.Dropout(p=0.15)\n",
    "        self.conv2 = nn.Conv3d(100, 100, 1)\n",
    "        self.batch2 = nn.BatchNorm3d(100)\n",
    "        self.drop2 = nn.Dropout(p=0.15)\n",
    "        self.conv3 = nn.Conv3d(100, 100, 3)\n",
    "        self.batch3 = nn.BatchNorm3d(100)\n",
    "        self.drop3 = nn.Dropout(p=0.15)\n",
    "        self.conv4 = nn.Conv3d(100, 100, 1)\n",
    "        self.batch4 = nn.BatchNorm3d(100)\n",
    "        self.drop4 = nn.Dropout(p=0.15)\n",
    "        self.conv5 = nn.Conv3d(100, 1, 3)\n",
    "\n",
    "    #note this method isn't called explicitly during train, \n",
    "    #rather the instance object is called as pytorch is then \n",
    "    #able to take care of other stuff in the background\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(F.relu(self.batch1(self.conv1(x))))\n",
    "        x = self.drop2(F.relu(self.batch2(self.conv2(x))))\n",
    "        x = self.drop3(F.relu(self.batch3(self.conv3(x))))\n",
    "        x = self.drop4(F.relu(self.batch4(self.conv4(x))))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use MSE loss\n",
    "criterion = nn.MSELoss() #returns the average over a mini-batch as opposed to the average\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10000]\n",
      "[1, 20000]\n",
      "[1, 30000]\n",
      "[1, 40000]\n",
      "[1, 50000]\n",
      "[1, 60000]\n",
      "[1, 70000]\n"
     ]
    }
   ],
   "source": [
    "(trained_net, adam_losses) = train(net, training_dataset, trainloader, [], optimizer, criterion, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_losses(adam_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = testing_error(net, testloader)\n",
    "print('MSE on test data: %f\\n' % (test_error))\n",
    "\n",
    "print (\"Mean intensity per voxel : %f\" % mean)\n",
    "print (\"Mean error per voxel : %f\" % \\\n",
    "       (np.sqrt(test_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store predictions in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(net, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_inp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_brain = reconstruct_brain(predictions,[53,65,55,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_brain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_pred(testing_data_inp[0], predicted_brain, testing_data_out[0], 36, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_brain.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_out[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
