{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook defines functions that are used to further preprocess and clean the brain scans. Firstly, the functions get rid of any artefacts that may be present in a scan -- this is done by setting the intensity value of those voxels to the threshold value. Secondly, we apply histogram matching to all the scans using a unique reference scan for the PETMR and TRIO datasets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function simply uploads the selected scan, (It is used for the refernce scan only)\n",
    "\n",
    "def get_scan(petmr=False, trio=False, ref=False, subj=None, cor_subj=None, scan=None, matched=False):\n",
    "    \n",
    "    if ref == True:\n",
    "        # Paths to the ref scans\n",
    "        print \"Fetching reference scan\"\n",
    "        petmr_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data/ReferenceScan'\n",
    "        trio_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data/ReferenceScan'\n",
    "    else:\n",
    "        print \"Fetching subject scan\"\n",
    "        petmr_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data/Subj' + str(subj) + 'Scan' + str(scan)\n",
    "        trio_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data/Subj' + str(subj) + 'Scan' + str(scan)\n",
    "    \n",
    "    if(petmr == True):\n",
    "        print \"Uploading PETMR scan\"\n",
    "        data_path = petmr_data_path\n",
    "    else:\n",
    "        print \"Uploading Trio scan\"\n",
    "        data_path = trio_data_path\n",
    "    os.chdir(data_path)\n",
    "    if ref == True:\n",
    "        scan_image = nib.load(str(data_path) + '/Ref_Scan.nii.gz')\n",
    "    elif matched == True:\n",
    "        if cor_subj != None:\n",
    "            scan_image = nib.load(str(data_path) + '/Brain_Matched_Scan' + str(cor_subj) + '.nii.gz')\n",
    "        else:\n",
    "            scan_image = nib.load(str(data_path) + '/Brain_Matched.nii.gz')\n",
    "    else:\n",
    "        if cor_subj != None:\n",
    "            scan_image = nib.load(str(data_path) + '/Brain_Extracted_Scan' + str(cor_subj) + '.nii.gz')\n",
    "        else:\n",
    "            scan_image = nib.load(str(data_path) + '/Brain_Extracted.nii.gz')\n",
    "        \n",
    "    scan_data = scan_image.get_data()\n",
    "    bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/NODDI.bval\",\\\n",
    "                                              str(data_path) + \"/NODDI.bvec\")\n",
    "    #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "    gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "        \n",
    "    # Extract the b=0 volumes only\n",
    "    scan_data_b0s = scan_data[:,:,:,gtab_scan.b0s_mask]\n",
    "\n",
    "    return (scan_data_b0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis(scan, gtable, title, threshold):\n",
    "    \n",
    "    # Extract the b=0 volumes from the scan\n",
    "    b_0s = scan[:,:,:,gtable.b0s_mask]\n",
    "    \n",
    "    mask = b_0s>0\n",
    "    brain = b_0s[mask]\n",
    "    \n",
    "    \n",
    "    print(\"maximum: %d\" % brain.max())\n",
    "    print(\"minimum: %d\" % brain.min())\n",
    "    print(\"average: %d\" % brain.mean())\n",
    "    print(\"median: %d\" % np.median(brain))\n",
    "\n",
    "    print(\"Total number of voxels: %d\" % brain.shape[0])\n",
    "    print(\"Voxels greater than threshold value (%d): %f\" % (threshold, (brain>threshold).sum()))\n",
    "\n",
    "    plt.hist(brain.flatten(), bins = 1024);\n",
    "    plt.title(title)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We threshold using b=700 values as this is more robust in identifying artefacts\n",
    "# Use all b=700 values then take the union of them\n",
    "def threshold(full_scan, gtab, threshold):\n",
    "    \n",
    "    # Make the assumption that the first b=700 volume lies at postion 2\n",
    "    b_700 = full_scan[:,:,:, (gtab.bvals == 700)]\n",
    "\n",
    "    # Identify the voxels that lie above the threshold level\n",
    "    bool_matrix = b_700 > threshold\n",
    "    \n",
    "    # Combine the identified voxels using a union opertaion in a single scan\n",
    "    bool_matrix = np.logical_or.reduce(bool_matrix, axis=3)\n",
    "    \n",
    "    return bool_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm for performing histogram matching\n",
    "# Matching is only performed on b=0 volumes\n",
    "# We also only consider non-zero voxels when performing the matching\n",
    "\n",
    "\n",
    "def hist_match(general_scan, reference_scan):\n",
    "    \n",
    "    \n",
    "\n",
    "    oldshape = general_scan.shape\n",
    "    source = general_scan.ravel()\n",
    "    reference = reference_scan.ravel()\n",
    "\n",
    "    # get the set of unique pixel values and their corresponding indices and\n",
    "    # counts\n",
    "    \n",
    "    #bin_idx returns the index of the unique element in terms of the unique array\n",
    "    #returns the index of a value in s_values\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True, return_counts=True)\n",
    "    r_values, r_counts = np.unique(reference, return_counts=True)\n",
    "    \n",
    "    # remove the first element from s_counts, t_counts and t_values as these values correspond to 0 intensity\n",
    "    # we do not want to consider background voxels\n",
    "\n",
    "    # take the cumsum of the counts and normalize by the number of pixels to\n",
    "    # get the empirical cumulative distribution functions for the source and\n",
    "    # template images (maps pixel value --> quantile)\n",
    "    s_quantiles = np.cumsum(s_counts[1:]).astype(np.float64)\n",
    "    s_quantiles /= s_quantiles[-1]\n",
    "    r_quantiles = np.cumsum(r_counts[1:]).astype(np.float64)\n",
    "    r_quantiles /= r_quantiles[-1]\n",
    "    # interpolate linearly to find the pixel values in the template image\n",
    "    # that correspond most closely to the quantiles in the source image\n",
    "\n",
    "    interp_r_values = np.interp(s_quantiles, r_quantiles, r_values[1:])\n",
    "    \n",
    "    # the interpoltaed values do not contain the intensity value 0\n",
    "    # add this to the start of the list\n",
    "    interp_r_values = np.insert(interp_r_values, 0, 0)\n",
    "\n",
    "    return interp_r_values[bin_idx].reshape(oldshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_pred(before, reference, after, sliceNo, scale):\n",
    "    if scale == False:\n",
    "        plt.figure\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.subplot(1, 3, 1).set_axis_off()\n",
    "        plt.imshow(before[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "        plt.title(\"Initial\")\n",
    "        plt.subplot(1, 3, 2).set_axis_off()\n",
    "        plt.imshow(reference[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "        plt.title(\"Reference\")\n",
    "        plt.subplot(1, 3, 3).set_axis_off()\n",
    "        plt.imshow(after[:,:,sliceNo,0].T, cmap='gray', origin='lower')\n",
    "        plt.title(\"Matched\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        max1 = np.max(before)\n",
    "        max2 = np.max(reference)\n",
    "        if max1 > max2:\n",
    "            maximum = max1\n",
    "        else:\n",
    "            maximum = max2\n",
    "        plt.figure\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.subplot(1, 3, 1).set_axis_off()\n",
    "        plt.imshow(before[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmax = maximum, vmin=0)\n",
    "        plt.title(\"Initial\")\n",
    "        plt.subplot(1, 3, 2).set_axis_off()\n",
    "        plt.imshow(reference[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmax = maximum, vmin=0)\n",
    "        plt.title(\"Reference\")\n",
    "        plt.subplot(1, 3, 3).set_axis_off()\n",
    "        plt.imshow(after[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmax = maximum, vmin=0)\n",
    "        plt.title(\"Matched\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to the data scans\n",
    "petmr_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data'\n",
    "trio_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PETMR referece scan\n",
    " \n",
    "We identify a reference scan based on how *clean* the scan is -- it should contain minimal artefacts and should have a reasonable range with minimal high intensity voxels.\n",
    " \n",
    "##### Use Subject 2 Scan 2 as the refernce scan - Threshold = 2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching reference scan\n",
      "Uploading PETMR scan\n"
     ]
    }
   ],
   "source": [
    "# Get the PETMR reference scan\n",
    "petmr_reference = get_scan(petmr=True, ref=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TRIO referece scan\n",
    " \n",
    "We identify a reference scan based on how *clean* the scan is -- it should contain minimal artefacts and should have a reasonable range with minimal high intensity voxels.\n",
    " \n",
    "##### Use Subject 2 Scan 2 as the refernce scan (modeified with thresholding - replace with 0)  - Threshold = 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching reference scan\n",
      "Uploading Trio scan\n"
     ]
    }
   ],
   "source": [
    "# Get the Trio reference scan\n",
    "trio_reference = get_scan(trio=True, ref=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply thresholding and Histogram matching to all PETMR and TRIO scans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through all PETMR scans, apply threshoding and histogram matching to each scan\n",
    "# Note that each subject scan will contain 3 extracted brains,\n",
    "# Scan 1 (Brain_Extracted_Scan1) -- Registered to scan 1 of the other scanner (Used as output scans in CNN)\n",
    "# Scan 2 (Brain_Extracted_Scan2)-- Registered to scan 2 of the other scanner (Used as output scans in CNN)\n",
    "# Scan 3 (Brain_Extracted)-- Unregistered (Used as input scans in CNN)\n",
    "\n",
    "\n",
    "def threshold_and_match(ref_scan, threshold_val, petmr=False, trio=False):\n",
    "\n",
    "    subjects = [1,2,3,4,5,6,7,8,9,10]\n",
    "    scans = [1,2]\n",
    "    pairs = [('Extracted', 'Matched'), ('Extracted_Scan1', 'Matched_Scan1'), ('Extracted_Scan2', 'Matched_Scan2')]\n",
    "    if(petmr == True):\n",
    "        print \"Uploading PETMR scans:\"\n",
    "        data_path = petmr_data_path\n",
    "    else:\n",
    "        print \"Uploading Trio scans:\"\n",
    "        data_path = trio_data_path\n",
    "    for subject in subjects:\n",
    "        for scan in scans:\n",
    "            print \"Subj%dScan%d\" % (subject, scan)\n",
    "            for pair in pairs:\n",
    "                os.chdir(data_path)\n",
    "                scan_image = nib.load(str(data_path) + \"/Subj\" + str(subject) + \"Scan\" + str(scan) + \"/Brain_\" + pair[0] + \".nii.gz\")\n",
    "                scan_data = scan_image.get_data()\n",
    "                affine_mat = scan_image.affine\n",
    "                bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/Subj\" + str(subject) + \"Scan\" + str(scan)  + \"/NODDI.bval\",\\\n",
    "                                                      str(data_path) + \"/Subj\" + str(subject) + \"Scan\" + str(scan)  + \"/NODDI.bvec\")\n",
    "                gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "            \n",
    "                # identify threshold voxels - replace with 0\n",
    "                #threshold_matrix = threshold(scan_data, gtab_scan, threshold_val)\n",
    "                #scan_data[threshold_matrix, :] = 0\n",
    "            \n",
    "                # Perform histogram matching on the thresholded scan (use b=0 values only)\n",
    "                scan_b_0s = scan_data[:,:,:,gtab_scan.b0s_mask]\n",
    "                matched_scan = hist_match(scan_b_0s, ref_scan)\n",
    "            \n",
    "                # Replace the new matched b=0 volumes into the full thresholded scan\n",
    "                scan_data[:,:,:,gtab_scan.b0s_mask] = matched_scan\n",
    "            \n",
    "                # Replace the threshodled voxels with a value of -5\n",
    "                #scan_data[threshold_matrix, :] = -5\n",
    "\n",
    "                # Save this new scan\n",
    "                new_scan_img = nib.Nifti1Image(scan_data.astype(np.float32), affine_mat)\n",
    "                nib.save(new_scan_img, str(data_path)+  \"/Subj\" + str(subject) + \"Scan\" + str(scan)  + \"/Brain_\" + pair[1] + \".nii.gz\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading PETMR scans:\n",
      "Subj1Scan1\n",
      "Subj1Scan2\n",
      "Subj2Scan1\n",
      "Subj2Scan2\n",
      "Subj3Scan1\n",
      "Subj3Scan2\n",
      "Subj4Scan1\n",
      "Subj4Scan2\n",
      "Subj5Scan1\n",
      "Subj5Scan2\n",
      "Subj6Scan1\n",
      "Subj6Scan2\n",
      "Subj7Scan1\n",
      "Subj7Scan2\n",
      "Subj8Scan1\n",
      "Subj8Scan2\n",
      "Subj9Scan1\n",
      "Subj9Scan2\n",
      "Subj10Scan1\n",
      "Subj10Scan2\n"
     ]
    }
   ],
   "source": [
    "gtab = threshold_and_match(petmr_reference, 550, petmr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Trio scans:\n",
      "Subj1Scan1\n",
      "Subj1Scan2\n",
      "Subj2Scan1\n",
      "Subj2Scan2\n",
      "Subj3Scan1\n",
      "Subj3Scan2\n",
      "Subj4Scan1\n",
      "Subj4Scan2\n",
      "Subj5Scan1\n",
      "Subj5Scan2\n",
      "Subj6Scan1\n",
      "Subj6Scan2\n",
      "Subj7Scan1\n",
      "Subj7Scan2\n",
      "Subj8Scan1\n",
      "Subj8Scan2\n",
      "Subj9Scan1\n",
      "Subj9Scan2\n",
      "Subj10Scan1\n",
      "Subj10Scan2\n"
     ]
    }
   ],
   "source": [
    "gtab = threshold_and_match(trio_reference, 450, trio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get PETMR scans for Subj1Scan1\n",
    "scan_normal = get_scan(petmr=True, subj=1, cor_subj=1, scan=1, matched=False)\n",
    "scan_matched = get_scan(petmr=True, subj=1, cor_subj=1, scan=1, matched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_pred(scan_normal, petmr_reference, scan_matched, 25, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scan_normal.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scan_matched.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
