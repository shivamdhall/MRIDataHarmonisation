{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook defines functions that are used to further preprocess and clean the brain scans. Firstly, the functions get rid of any artefacts that may be present in a scan -- this is done by setting the intensity value of those voxels to the threshold value. Secondly, we apply histogram matching to all the scans using a unique reference scan for the PETMR and TRIO datasets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this function simply uploads the selected scan, (It is used for the refernce scan only)\n",
    "\n",
    "def get_ref_scan(petmr=False, trio=False):\n",
    "    \n",
    "    # Paths to the data scans\n",
    "    petmr_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data/ReferenceScan'\n",
    "    trio_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data/ReferenceScan'\n",
    "    \n",
    "    if(petmr == True):\n",
    "        print \"Uploading PETMR reference scan\"\n",
    "        data_path = petmr_data_path\n",
    "    else:\n",
    "        print \"Uploading Trio reference scan\"\n",
    "        data_path = trio_data_path\n",
    "    os.chdir(data_path)\n",
    "    scan_image = nib.load(str(data_path) + \"/Ref_Scan.nii.gz\")\n",
    "    scan_data = scan_image.get_data()\n",
    "    bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/NODDI.bval\",\\\n",
    "                                              str(data_path) + \"/NODDI.bvec\")\n",
    "    #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "    gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "        \n",
    "    # Extract the b=0 volumes only\n",
    "    scan_data_b0s = scan_data[:,:,:,gtab_scan.b0s_mask]\n",
    "\n",
    "    return (scan_data_b0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analysis(scan, gtable, title, threshold):\n",
    "    \n",
    "    # Extract the b=0 volumes from the scan\n",
    "    b_0s = scan[:,:,:,gtable.b0s_mask]\n",
    "    \n",
    "    mask = b_0s>0\n",
    "    brain = b_0s[mask]\n",
    "    \n",
    "    \n",
    "    print(\"maximum: %d\" % brain.max())\n",
    "    print(\"minimum: %d\" % brain.min())\n",
    "    print(\"average: %d\" % brain.mean())\n",
    "    print(\"median: %d\" % np.median(brain))\n",
    "\n",
    "    print(\"Total number of voxels: %d\" % brain.shape[0])\n",
    "    print(\"Voxels greater than threshold value (%d): %f\" % (threshold, (brain>threshold).sum()))\n",
    "\n",
    "    plt.hist(brain.flatten(), bins = 1024);\n",
    "    plt.title(title)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We threshold using b=700 values as this is more robust in identifying artefacts\n",
    "# Use all b=700 values then take the union of them\n",
    "def threshold(full_scan, gtab, threshold):\n",
    "    \n",
    "    # Make the assumption that the first b=700 volume lies at postion 2\n",
    "    b_700 = full_scan[:,:,:, (gtab.bvals == 700)]\n",
    "\n",
    "    # Identify the voxels that lie above the threshold level\n",
    "    bool_matrix = b_700 > threshold\n",
    "    \n",
    "    # Combine the identified voxels using a union opertaion in a single scan\n",
    "    bool_matrix = np.logical_or.reduce(bool_matrix, axis=3)\n",
    "    # Replace the identified voxels with a value of 0\n",
    "    full_scan[bool_matrix, :] = 0\n",
    "    \n",
    "    return full_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm for performing histogram matching\n",
    "# Matching is only performed on b=0 volumes\n",
    "# We also only consider non-zero voxels when performing the matching\n",
    "\n",
    "\n",
    "def hist_match(general_scan, reference_scan):\n",
    "    \n",
    "    \n",
    "\n",
    "    oldshape = general_scan.shape\n",
    "    source = general_scan.ravel()\n",
    "    reference = reference_scan.ravel()\n",
    "\n",
    "    # get the set of unique pixel values and their corresponding indices and\n",
    "    # counts\n",
    "    \n",
    "    #bin_idx returns the index of the unique element in terms of the unique array\n",
    "    #returns the index of a value in s_values\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True, return_counts=True)\n",
    "    r_values, r_counts = np.unique(reference, return_counts=True)\n",
    "    \n",
    "    # remove the first element from s_counts, t_counts and t_values as these values correspond to 0 intensity\n",
    "    # we do not want to consider background voxels\n",
    "\n",
    "    # take the cumsum of the counts and normalize by the number of pixels to\n",
    "    # get the empirical cumulative distribution functions for the source and\n",
    "    # template images (maps pixel value --> quantile)\n",
    "    s_quantiles = np.cumsum(s_counts[1:]).astype(np.float64)\n",
    "    s_quantiles /= s_quantiles[-1]\n",
    "    r_quantiles = np.cumsum(r_counts[1:]).astype(np.float64)\n",
    "    r_quantiles /= r_quantiles[-1]\n",
    "    # interpolate linearly to find the pixel values in the template image\n",
    "    # that correspond most closely to the quantiles in the source image\n",
    "\n",
    "    interp_r_values = np.interp(s_quantiles, r_quantiles, r_values[1:])\n",
    "    \n",
    "    # the interpoltaed values do not contain the intensity value 0\n",
    "    # add this to the start of the list\n",
    "    interp_r_values = np.insert(interp_r_values, 0, 0)\n",
    "\n",
    "    return interp_r_values[bin_idx].reshape(oldshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to the data scans\n",
    "petmr_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data'\n",
    "trio_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PETMR referece scan\n",
    " \n",
    "We identify a reference scan based on how *clean* the scan is -- it should contain minimal artefacts and should have a reasonable range with minimal high intensity voxels.\n",
    " \n",
    "##### Use Subject 1 Scan 2 as the refernce scan - Threshold = 2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading PETMR reference scan\n"
     ]
    }
   ],
   "source": [
    "# Get the PETMR reference scan\n",
    "petmr_reference = get_ref_scan(petmr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TRIO referece scan\n",
    " \n",
    "We identify a reference scan based on how *clean* the scan is -- it should contain minimal artefacts and should have a reasonable range with minimal high intensity voxels.\n",
    " \n",
    "##### Use Subject 2 Scan 2 as the refernce scan (modeified with thresholding - replace with 0)  - Threshold = 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Trio reference scan\n"
     ]
    }
   ],
   "source": [
    "# Get the Trio reference scan\n",
    "trio_reference = get_ref_scan(trio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply thresholding and Histogram matching to all PETMR scans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate through all PETMR scans, apply threshoding and histogram matching to each scan\n",
    "def threshold_and_match(ref_scan, threshold_val, petmr=False, trio=False):\n",
    "\n",
    "    subjects = [1]\n",
    "    scans = [1,2]\n",
    "    if(petmr == True):\n",
    "        print \"Uploading PETMR scans:\"\n",
    "        data_path = petmr_data_path\n",
    "    else:\n",
    "        print \"Uploading Trio scans:\"\n",
    "        data_path = trio_data_path\n",
    "    for subject in subjects:\n",
    "        for scan in scans:\n",
    "            os.chdir(data_path)\n",
    "            print \"Subj%dScan%d\" % (subject, scan)\n",
    "            scan_image = nib.load(str(data_path) + \"/Subj\" + str(subject) + \"Scan\" + str(scan) + \"/Brain_Extracted.nii.gz\")\n",
    "            scan_data = scan_image.get_data()\n",
    "            affine_mat = scan_image.affine\n",
    "            bvals_scan, bvecs_scan = read_bvals_bvecs(str(data_path) + \"/Subj\" + str(subject) + \"Scan\" + str(scan)  + \"/NODDI.bval\",\\\n",
    "                                                      str(data_path) + \"/Subj\" + str(subject) + \"Scan\" + str(scan)  + \"/NODDI.bvec\")\n",
    "            gtab_scan = gradient_table(bvals_scan, bvecs_scan, b0_threshold=5)\n",
    "            \n",
    "            # Perform thresholding on the scan\n",
    "            thresholded_scan = threshold(scan_data, gtab, threshold_val)\n",
    "            \n",
    "            # Perform histogram matching on the thresholded scan (use b=0 values only)\n",
    "            thresholded_scan_b_0s = thresholded_scan[:,:,:,gtab_scan.b0s_mask]\n",
    "            matched_scan = hist_match(thresholded_scan_b_0s, ref_scan)\n",
    "            \n",
    "            # Replace the new matched b=0 volumes into the full thresholded scan\n",
    "            thresholded_scan[:,:,:,gtab_scan.b0s_mask] = matched_scan\n",
    "            \n",
    "            # Save this new scan\n",
    "            new_scan_img = nib.Nifti1Image(thresholded_scan.astype(np.float32), affine_mat)\n",
    "            nib.save(new_scan_img, str(data_path)+  \"/Subj\" + str(subject) + \"Scan\" + str(scan)  + \"/Brain_Thresholded.nii.gz\")\n",
    "            \n",
    "    return gtab_scan \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading PETMR scans:\n",
      "Subj1Scan1\n",
      "Subj1Scan2\n",
      "Subj2Scan1\n",
      "Subj2Scan2\n",
      "Subj3Scan1\n",
      "Subj3Scan2\n",
      "Subj4Scan1\n",
      "Subj4Scan2\n",
      "Subj5Scan1\n",
      "Subj5Scan2\n",
      "Subj6Scan1\n",
      "Subj6Scan2\n",
      "Subj7Scan1\n",
      "Subj7Scan2\n",
      "Subj8Scan1\n",
      "Subj8Scan2\n",
      "Subj9Scan1\n",
      "Subj9Scan2\n",
      "Subj10Scan1\n",
      "Subj10Scan2\n"
     ]
    }
   ],
   "source": [
    "gtab = threshold_and_match(petmr_reference, 500, petmr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Trio scans:\n",
      "Subj1Scan1\n",
      "Subj1Scan2\n",
      "Subj2Scan1\n",
      "Subj2Scan2\n",
      "Subj3Scan1\n",
      "Subj3Scan2\n",
      "Subj4Scan1\n",
      "Subj4Scan2\n",
      "Subj5Scan1\n",
      "Subj5Scan2\n",
      "Subj6Scan1\n",
      "Subj6Scan2\n",
      "Subj7Scan1\n",
      "Subj7Scan2\n",
      "Subj8Scan1\n",
      "Subj8Scan2\n",
      "Subj9Scan1\n",
      "Subj9Scan2\n",
      "Subj10Scan1\n",
      "Subj10Scan2\n"
     ]
    }
   ],
   "source": [
    "gtab = threshold_and_match(trio_reference, 450, trio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
