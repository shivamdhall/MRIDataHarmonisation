{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fianl - AWS - Cycle-General Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use both scans of subjects 1-8 from the PETMR and TRIO dataset for training.\n",
    "\n",
    "We used the scan of subjects 9-10 also from the PETMR and TRIO dataset for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function simply uploads the testing and training scans into lists of numpy arrays\n",
    "#the data is not yet sliced or patched at this stage\n",
    "\n",
    "#specify in a list what scans to use for training and what scans to use for testing\n",
    "\n",
    "\n",
    "def get_data(petmr_path, trio_path, scans_dict, input_scanner):\n",
    "    \n",
    "    train_val_test_inp = []\n",
    "    train_val_test_out = []\n",
    "    test_data_inp = []\n",
    "    test_data_out = []\n",
    "    # only required for testing scans\n",
    "    test_data_affine_mat = []\n",
    "    \n",
    "    if input_scanner == \"PETMR\":\n",
    "        input_path = petmr_path\n",
    "        output_path = trio_path\n",
    "    else:\n",
    "        input_path = trio_path\n",
    "        output_path = petmr_path       \n",
    "    \n",
    "    for key, subjs in scans_dict.iteritems():\n",
    "        for subj_scan in subjs:\n",
    "                \n",
    "            input_scan_image = nib.load(str(input_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan\" + str(subj_scan[1]) + \"/Brain_Matched.nii.gz\")\n",
    "            input_scan_data = input_scan_image.get_data()\n",
    "                \n",
    "            input_bvals_scan, input_bvecs_scan = read_bvals_bvecs(str(input_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan\" + str(subj_scan[1]) + \"/NODDI.bval\",\\\n",
    "                                                          str(input_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan\" + str(subj_scan[1]) + \"/NODDI.bvec\")\n",
    "            \n",
    "            # Important : Upload the output scan that is registered to the appropriate input scan\n",
    "            \n",
    "            output_scan_image = nib.load(str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan1\" + \"/Brain_Matched.nii.gz\")\n",
    "            output_scan_data = output_scan_image.get_data()\n",
    "            \n",
    "            output_bvals_scan, output_bvecs_scan = read_bvals_bvecs(str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan1/NODDI.bval\",\\\n",
    "                                                          str(output_path) + \"/Subj\" + str(subj_scan[0]) + \"Scan1/NODDI.bvec\")\n",
    "                    \n",
    "            #set a threshold value for b=0 values (due to TRIO dataset)\n",
    "            input_gtab_scan = gradient_table(input_bvals_scan, input_bvecs_scan, b0_threshold=5)\n",
    "            input_s0s_scan = input_scan_data[:, :, :, input_gtab_scan.b0s_mask]\n",
    "                \n",
    "            output_gtab_scan = gradient_table(output_bvals_scan, output_bvecs_scan, b0_threshold=5)\n",
    "            output_s0s_scan = output_scan_data[:, :, :, output_gtab_scan.b0s_mask]\n",
    "            \n",
    "            # Use only the first volume, ignore other volumes\n",
    "            if(key == \"train_val_test\"):\n",
    "                print (\"Uploading Subject %s Scan %s\" % (str(subj_scan[0]), str(subj_scan[1])))\n",
    "                #append the data to the lists containing the training inputs and outputs\n",
    "                train_val_test_inp.append(input_s0s_scan[:,:,:,[0]])\n",
    "                train_val_test_out.append(output_s0s_scan[:,:,:,[0]])\n",
    "            else:\n",
    "                print (\"Testing: Subject %s Scan %s\" % (str(subj_scan[0]), str(subj_scan[1])))\n",
    "                test_data_inp.append(input_s0s_scan[:,:,:,[0]])\n",
    "                test_data_out.append(output_s0s_scan[:,:,:,[0]])\n",
    "                test_data_affine_mat.append(input_scan_image.affine)\n",
    "    return (train_val_test_inp, train_val_test_out, test_data_inp, test_data_out, test_data_affine_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function extracts patches from a scan and appends them to a list.\n",
    "#This is done for all volumes of a scan (for both the inputs and targets)\n",
    "\n",
    "def patchify(data_scans, patch_size=9, skip=0):\n",
    "    \n",
    "    patches_store = []\n",
    "    padded_scans = []\n",
    "    \n",
    "    for scan_no in range(0, len(data_scans)):\n",
    "        scan = data_scans[scan_no]\n",
    "        \n",
    "        # Pad the scan to ensure that the\n",
    "        (x,y,z,v) = scan.shape\n",
    "        x_padding = (patch_size - (x % patch_size)) % patch_size\n",
    "        y_padding = (patch_size - (y % patch_size)) % patch_size\n",
    "        z_padding = (patch_size - (z % patch_size)) % patch_size\n",
    "        x_padding_before = x_padding/2\n",
    "        x_padding_after = x_padding - x_padding_before\n",
    "        y_padding_before = y_padding/2\n",
    "        y_padding_after = y_padding - y_padding_before\n",
    "        z_padding_before = z_padding/2\n",
    "        z_padding_after = z_padding - z_padding_before\n",
    "        #pad the input scan\n",
    "        full_padding = ((x_padding_before, x_padding_after), (y_padding_before, y_padding_after), (z_padding_before, z_padding_after), (0,0))\n",
    "        padded_scan = np.pad(scan, full_padding, mode='constant', constant_values=0)\n",
    "        padded_scans.append(padded_scan)\n",
    "        \n",
    "        # Get new scan shape\n",
    "        (x,y,z,v) = padded_scan.shape\n",
    "        #iterate through each volume to extract the patches\n",
    "        for volume in range(0, v):\n",
    "            for pos_x in range(0, x-patch_size+1,skip):\n",
    "                for pos_y in range(0,y-patch_size+1,skip):\n",
    "                    for pos_z in range(0, z-patch_size+1,skip):\n",
    "                        patch = padded_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume]\n",
    "                        \n",
    "                        #store the patch and the target\n",
    "                        patches_store.append(patch)\n",
    "                        \n",
    "    return (padded_scans, patches_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_pred(inputs, predictions, labels, sliceNo):\n",
    "    maximum = np.max([inputs.max(), predictions.max(), labels.max()])\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1).set_axis_off()\n",
    "    plt.imshow(inputs[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmin=0, vmax=maximum)\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2).set_axis_off()\n",
    "    plt.imshow(predictions[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmin=0, vmax=maximum)\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.subplot(1, 3, 3).set_axis_off()\n",
    "    plt.imshow(labels[:,:,sliceNo,0].T, cmap='gray', origin='lower', vmin=0, vmax=maximum)\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_pred2(inputs, predictions, labels, sliceNo):\n",
    "    maximum = np.max([inputs.max(), predictions.max(), labels.max()])\n",
    "    plt.figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1).set_axis_off()\n",
    "    plt.imshow(inputs[:,:,sliceNo].T, cmap='gray', origin='lower', vmin=0, vmax=maximum)\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2).set_axis_off()\n",
    "    plt.imshow(predictions[:,:,sliceNo].T, cmap='gray', origin='lower', vmin=0, vmax=maximum)\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.subplot(1, 3, 3).set_axis_off()\n",
    "    plt.imshow(labels[:,:,sliceNo].T, cmap='gray', origin='lower', vmin=0, vmax=maximum)\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Subject 1 Scan 1\n",
      "Uploading Subject 2 Scan 1\n",
      "Testing: Subject 9 Scan 1\n",
      "Testing: Subject 9 Scan 2\n",
      "Number of scans used for training, validation and testing: 2\n",
      "Number of scans used for final testing: 2\n"
     ]
    }
   ],
   "source": [
    "#upload the data\n",
    "petmr_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/TRIO_data'\n",
    "trio_data_path = '/Volumes/Seagate Backup Plus Drive/Project/Dataset/PETMR_data'\n",
    "\n",
    "# Enter a list of tuples (subject, scan_number)\n",
    "# Use this to get all scans then split into training, validation and testing\n",
    "training_scans = [(1,1), (2,1)]\n",
    "\n",
    "# This is a final test scan only - used to generate a complete scan from the trained CNN\n",
    "testing_scans = [(9,1), (9,2)]\n",
    "\n",
    "data_dict = {\"train_val_test\": training_scans, \"testing\":testing_scans}\n",
    "\n",
    "(training_inp, training_out, final_test_inp, final_test_out, final_test_affine_mat) = \\\n",
    "        get_data(petmr_data_path, trio_data_path, data_dict, input_scanner=\"PETMR\")\n",
    "print(\"Number of scans used for training, validation and testing: %d\" % len(training_inp))\n",
    "print (\"Number of scans used for final testing: %d\" % len(final_test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_data(dataset, numb_slices):\n",
    "\n",
    "    # This function is used for paddiny a dataset with 0 values, we only pad the x and y\n",
    "    # dimension, it is not necessary to pad the z dimension as we will be extracting axial slices\n",
    "\n",
    "    max_width = 0\n",
    "    max_hight = 0\n",
    "    \n",
    "    #iterate through the scans and update the above stats\n",
    "    for scan in dataset:\n",
    "        (width, hight, depth, volume) = scan.shape\n",
    "        if width > max_width:\n",
    "            max_width = width\n",
    "        if hight > max_hight:\n",
    "            max_hight = hight\n",
    "            \n",
    "    #iterate throug the scans again and pad them based on the max stats\n",
    "    for index, scan in enumerate(dataset):\n",
    "        #get padding dimensions\n",
    "        (width, hight, depth, volume) = scan.shape\n",
    "        pad_width = max_width-width\n",
    "        pad_hight = max_hight-hight\n",
    "        # depth dimension should be compatible with numb_slices\n",
    "        pad_depth = (numb_slices - (depth % numb_slices)) % numb_slices\n",
    "        \n",
    "        pad_w_b = pad_width/2\n",
    "        pad_w_a = pad_width-pad_w_b\n",
    "        \n",
    "        pad_h_b = pad_hight/2\n",
    "        pad_h_a = pad_hight-pad_h_b\n",
    "        \n",
    "        pad_d_b = pad_depth/2\n",
    "        pad_d_a = pad_depth-pad_d_b\n",
    "        \n",
    "        \n",
    "        padding = ((pad_w_b, pad_w_a), (pad_h_b, pad_h_a), (pad_d_b, pad_d_a), (0,0))\n",
    "        aug_scan = np.pad(scan, padding, mode='constant', constant_values=0)\n",
    "        dataset[index] = aug_scan\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "def sliceify(scans_inp, numb_slices):\n",
    "\n",
    "    # This function extracts non-overlapping axial slices of thickness (numb_slices) from a scan and appends them to a list.\n",
    "    # This is done for all volumes of a scan\n",
    "\n",
    "    slices_store = []\n",
    "\n",
    "    # Since each scan can have different dimensions, it is first neccessary to pad each \n",
    "    # each scan to ensure that they have the same x and y dimension \n",
    "    # It is also necessary to ensure that the z component is divisible by numb_slices\n",
    "    # This helps with training and testing because we can use batches (must be same dimensions)\n",
    "    padded_scans = pad_data(scans_inp, 3)\n",
    "\n",
    "\n",
    "    for scan_no in range(0, len(padded_scans)):\n",
    "        input_scan = padded_scans[scan_no]\n",
    "        \n",
    "        (x,y,z,v) = input_scan.shape\n",
    "        print input_scan.shape\n",
    "\n",
    "        for volume in range(0, v):\n",
    "            for i in range(0, z, numb_slices):\n",
    "                #check that there exists x slices below and above\n",
    "                slices_store.append(scan_no[:,:,i:i+numb_slices,v])\n",
    "                \n",
    "\n",
    "    return (padded_scans, slices_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(3 - (6 % 3)) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_brain(predictions, scans, slice_size):\n",
    "    # Scans is a list containing the input scans where each scan is stored as a 4d numpy array\n",
    "    # Iterate through all the scans and reconstruct them\n",
    "    i = 0\n",
    "    reconstructed_scans = []\n",
    "    for scan in scans:\n",
    "        dimensions = scan.shape\n",
    "        size_x = dimensions[0]\n",
    "        size_y = dimensions[1]\n",
    "        size_z = dimensions[2]\n",
    "        size_v = dimensions[3]\n",
    "        predicted_scan = np.zeros((size_x, size_y, size_z, size_v))\n",
    "        \n",
    "        for volume in range(0, size_v):\n",
    "            for pos_z in range(0, size_z-slice_size+1, slice_size):\n",
    "                    predicted_scan[:, :, pos_z:pos_z+slice_size, volume] = predictions[:,:,:,0,i]\n",
    "                    i += slice_size\n",
    "\n",
    "        reconstructed_scans.append(predicted_scan)\n",
    "        \n",
    "    return reconstructed_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 69, 52, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_inp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 69, 54, 1)\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n",
      "33\n",
      "36\n",
      "39\n",
      "42\n",
      "45\n",
      "48\n",
      "51\n",
      "(56, 69, 54, 1)\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n",
      "33\n",
      "36\n",
      "39\n",
      "42\n",
      "45\n",
      "48\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "final_scans_inp_padded, final_test_inp_slices = sliceify(final_test_inp, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 69, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_inp_slices[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 69, 52, 1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scans_inp_padded[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_arr = np.array(final_test_inp_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 56, 69, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_arr = np.transpose(x_arr, (1,2,3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 69, 3, 106)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_arr = np.expand_dims(x_arr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 69, 3, 1, 106)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = rec_brain(x_arr, final_scans_inp_padded, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 69, 54, 1)\n",
      "(56, 69, 54, 1)\n"
     ]
    }
   ],
   "source": [
    "print res[0].shape\n",
    "print final_scans_inp_padded[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzAAAAFVCAYAAAAwrgrbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQT4iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f5dce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_pred2(final_test_inp_slices[0], final_test_inp_slices[0], final_test_inp_slices[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzAAAAFVCAYAAAAwrgrbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYoSZ1NKojnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fa79290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_pred(final_scans_inp_padded[0], final_scans_inp_padded[0], final_scans_inp_padded[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661.740966796875"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_inp_slices[0][:,:,2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661.74097"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scans_inp_padded[0][:,:,1,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patchify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchifying training set\n",
      "Patchifying final testing scans\n"
     ]
    }
   ],
   "source": [
    "print \"Patchifying training set\"\n",
    "_, training_patches_input = patchify(training_inp, 9, 3)\n",
    "_, training_patches_target = patchify(training_out, 9, 3)\n",
    "\n",
    "print \"Patchifying final testing scans\"\n",
    "padded_testing_scans_input, testing_patches_input = patchify(final_test_inp, 9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : PETMR: 95584, TRIO: 104032\n",
      "Number of final testing examples : 336\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples : PETMR: %d, TRIO: %d\" % (len(training_patches_input), len(training_patches_target)))\n",
    "print (\"Number of final testing examples : %d\" % len(testing_patches_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dataset class for our data\n",
    "\n",
    "class MRIdataset(Dataset):\n",
    "    \"\"\"MRI b=0 dataset for patches.\"\"\"\n",
    "\n",
    "    def __init__(self, patches, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patches: patches\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        \"\"\"\n",
    "        self.patches = patches\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = np.array(self.patches[idx])\n",
    "        sample = {'patch': patch}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class To_Tensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        patch = sample['patch']\n",
    "        \n",
    "        #first expand dimension because torch expects H x W x D x C\n",
    "        #currently we only have H x W x D\n",
    "        aug_patch = np.expand_dims(patch, 3)\n",
    "\n",
    "        # swap channel axis because\n",
    "        # numpy: H x W x D x C\n",
    "        # torch: C x D x H x W\n",
    "        aug_patch = aug_patch.transpose((3, 2, 0, 1))\n",
    "        \n",
    "        return {'patch': torch.Tensor(aug_patch)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(G_A, G_B, D_A, D_B, MSE_loss, L1_loss, optimizers, schedulers, trainloader_inp, trainloader_tar, epochs):\n",
    "    G_optimizer = optimizers[0]\n",
    "    D_A_optimizer = optimizers[1]\n",
    "    D_B_optimizer = optimizers[2]\n",
    "    G_scheduler = schedulers[0]\n",
    "    D_A_scheduler = schedulers[1]\n",
    "    D_B_scheduler = schedulers[2]\n",
    "    \n",
    "    # Generated image pool\n",
    "    num_pool = 50\n",
    "    fake_A_pool = ImagePool(num_pool)\n",
    "    fake_B_pool = ImagePool(num_pool)\n",
    "\n",
    "    G_A.train()\n",
    "    G_B.train()\n",
    "    D_A.train()\n",
    "    D_B.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        D_A_losses = []\n",
    "        D_B_losses = []\n",
    "        G_A_losses = []\n",
    "        G_B_losses = []\n",
    "        cycle_A_losses = []\n",
    "        cycle_B_losses = []\n",
    "        \n",
    "        running_D_A_loss = 0\n",
    "        running_D_B_loss = 0\n",
    "        running_G_A_loss = 0\n",
    "        running_G_B_loss = 0\n",
    "        running_G_loss = 0\n",
    "        running_cycle_A_loss = 0\n",
    "        running_cycle_B_loss =0\n",
    "\n",
    "        # training\n",
    "        for i, (data_inp, data_tar) in enumerate(zip(trainloader_inp, trainloader_tar)):\n",
    "\n",
    "            # input image data\n",
    "            real_A = data_inp['patch']\n",
    "            real_B = data_tar['patch']\n",
    "\n",
    "            real_A = Variable(real_A.cuda())\n",
    "            real_B = Variable(real_B.cuda())\n",
    "\n",
    "            # Train generator G\n",
    "            # A -> B\n",
    "            fake_B = G_A(real_A)\n",
    "            D_B_fake_decision = D_B(fake_B)\n",
    "            \n",
    "            G_A_loss = MSE_loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
    "            running_G_A_loss += G_A_loss.data[0]\n",
    "\n",
    "            # forward cycle loss\n",
    "            recon_A = G_B(fake_B)\n",
    "            cycle_A_loss = L1_loss(recon_A, real_A) * 5\n",
    "            running_cycle_A_loss += cycle_A_loss.data[0]\n",
    "\n",
    "            # B -> A\n",
    "            fake_A = G_B(real_B)\n",
    "            D_A_fake_decision = D_A(fake_A)\n",
    "            G_B_loss = MSE_loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()).cuda()))\n",
    "            running_G_B_loss += G_B_loss.data[0]\n",
    "\n",
    "            # backward cycle loss\n",
    "            recon_B = G_A(fake_A)\n",
    "            cycle_B_loss = L1_loss(recon_B, real_B) * 5\n",
    "            running_cycle_B_loss += cycle_B_loss.data[0]\n",
    "\n",
    "            # Back propagation\n",
    "            G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
    "            running_G_loss += G_loss.data[0]\n",
    "            G_optimizer.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "            # Train discriminator D_A\n",
    "            D_A_real_decision = D_A(real_A)\n",
    "            D_A_real_loss = MSE_loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()).cuda()))\n",
    "            fake_A = fake_A_pool.query(fake_A)\n",
    "            D_A_fake_decision = D_A(fake_A)\n",
    "            D_A_fake_loss = MSE_loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()).cuda()))\n",
    "\n",
    "            # Back propagation\n",
    "            D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "            running_D_A_loss += D_A_loss.data[0]\n",
    "            D_A_optimizer.zero_grad()\n",
    "            D_A_loss.backward()\n",
    "            D_A_optimizer.step()\n",
    "\n",
    "            # Train discriminator D_B\n",
    "            D_B_real_decision = D_B(real_B)\n",
    "            D_B_real_loss = MSE_loss(D_B_real_decision, Variable(torch.ones(D_B_real_decision.size()).cuda()))\n",
    "            fake_B = fake_B_pool.query(fake_A)\n",
    "            D_B_fake_decision = D_B(fake_B)\n",
    "            D_B_fake_loss = MSE_loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()).cuda()))\n",
    "\n",
    "            # Back propagation\n",
    "            D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "            running_D_B_loss += D_B_loss.data[0]\n",
    "            D_B_optimizer.zero_grad()\n",
    "            D_B_loss.backward()\n",
    "            D_B_optimizer.step()\n",
    "            \n",
    "            # loss values\n",
    "            D_A_losses.append(running_D_A_loss/(i+1))\n",
    "            D_B_losses.append(running_D_B_loss/(i+1))\n",
    "            G_A_losses.append(running_G_A_loss/(i+1))\n",
    "            G_B_losses.append(running_G_B_loss/(i+1))\n",
    "            cycle_A_losses.append(running_cycle_A_loss/(i+1))\n",
    "            cycle_B_losses.append(running_cycle_B_loss/(i+1))\n",
    "            \n",
    "            if i%50 == 49:\n",
    "                print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n",
    "                  % (epoch+1, epochs, i+1, len(trainloader_inp), running_D_A_loss/(i+1), running_D_B_loss/(i+1), running_G_A_loss/(i+1), running_G_B_loss/(i+1)))\n",
    "        \n",
    "        # Change learning rate using the scheduler\n",
    "        G_scheduler.step(running_G_loss/(i+1))\n",
    "        D_A_scheduler.step(running_D_A_loss/(i+1))\n",
    "        D_B_scheduler.step(running_D_B_loss/(i+1))\n",
    "        \n",
    "    return  (D_A_losses, D_B_losses, G_A_losses, G_B_losses, cycle_A_losses, cycle_B_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_losses(training_losses, validation_losses):\n",
    "    plt.figure\n",
    "    plt.plot(range(1,len(training_losses)+1), training_losses, 'r-', label=\"Training error\")\n",
    "    plt.plot(range(1,len(validation_losses)+1), validation_losses, 'b-', label=\"Validation error\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('iteration')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    plt.ylabel('Loss - (MSE)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(G_A, testloader):\n",
    "    G_A.eval()\n",
    "    for i, test_data in enumerate(testloader, 0):\n",
    "        real_A = test_data['patch']\n",
    "        real_A = Variable(real_A.cuda())\n",
    "\n",
    "        # A -> B\n",
    "        test_predictions = G_A(real_A)\n",
    "\n",
    "        #store the predictions in a numpy array which we can reshape later\n",
    "        if(i == 0):\n",
    "            predictions = test_predictions.data.cpu().numpy() \n",
    "        else:\n",
    "            predictions = np.concatenate((predictions, test_predictions.data.cpu().numpy()), axis=0)\n",
    "\n",
    "    # Transpose predictions from (NxCxDxHxW)\n",
    "    # to (NxCxHxWxD)\n",
    "    predictions = np.transpose(predictions, (0,1,3,4,2))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_brain(predictions, scans, patch_size):\n",
    "    # Scans is a list containing the input scans where each scan is stored as a 4d numpy array\n",
    "    # Iterate through all the scans and reconstruct them\n",
    "    i = 0\n",
    "    reconstructed_scans = []\n",
    "    for scan in scans:\n",
    "        dimensions = scan.shape\n",
    "        size_x = dimensions[0]\n",
    "        size_y = dimensions[1]\n",
    "        size_z = dimensions[2]\n",
    "        size_v = dimensions[3]\n",
    "        predicted_scan = np.zeros((size_x, size_y, size_z, size_v))\n",
    "        \n",
    "        for volume in range(0, size_v):\n",
    "            for pos_x in range(0, size_x-patch_size+1, patch_size):\n",
    "                for pos_y in range(0,size_y-patch_size+1, patch_size):\n",
    "                    for pos_z in range(0, size_z-patch_size+1, patch_size):\n",
    "                        predicted_scan[pos_x:pos_x+patch_size, pos_y:pos_y+patch_size, pos_z:pos_z+patch_size, volume] = predictions[i,0,:,:,:]\n",
    "                        i += 1\n",
    "\n",
    "        reconstructed_scans.append(predicted_scan)\n",
    "        \n",
    "    return reconstructed_scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data using pytorch data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset_inputs = MRIdataset(training_patches_input, transform=transforms.Compose([To_Tensor()]))\n",
    "training_dataset_targets = MRIdataset(training_patches_target, transform=transforms.Compose([To_Tensor()]))\n",
    "\n",
    "final_testing_dataset = MRIdataset(testing_patches_input, transform=transforms.Compose([To_Tensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainloader_inp = DataLoader(training_dataset_inputs, batch_size=256,\n",
    "                        shuffle=True, num_workers=16)\n",
    "\n",
    "trainloader_tar = DataLoader(training_dataset_targets, batch_size=256,\n",
    "                        shuffle=True, num_workers=16)\n",
    "\n",
    "final_test_loader = DataLoader(final_testing_dataset, batch_size=256,\n",
    "                        shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=0, activation='relu', batch_norm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv3d(input_size, output_size, kernel_size, stride, padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.BatchNorm3d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2, True)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out\n",
    "\n",
    "\n",
    "class DeconvBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=0, output_padding=0, activation='relu', batch_norm=True):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        self.deconv = torch.nn.ConvTranspose3d(input_size, output_size, kernel_size, stride, padding, output_padding)\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn = torch.nn.BatchNorm3d(output_size)\n",
    "        self.activation = activation\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.batch_norm:\n",
    "            out = self.bn(self.deconv(x))\n",
    "        else:\n",
    "            out = self.deconv(x)\n",
    "\n",
    "        if self.activation == 'relu':\n",
    "            return self.relu(out)\n",
    "        elif self.activation == 'lrelu':\n",
    "            return self.lrelu(out)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(out)\n",
    "        elif self.activation == 'no_act':\n",
    "            return out\n",
    "\n",
    "\n",
    "class ResnetBlock(torch.nn.Module):\n",
    "    def __init__(self, num_filter, kernel_size=3, stride=1, padding=1):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv3d(num_filter, num_filter, kernel_size, stride, padding)\n",
    "        self.conv2 = torch.nn.Conv3d(num_filter, num_filter, kernel_size, stride, padding)\n",
    "        self.bn = torch.nn.BatchNorm3d(num_filter)\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "\n",
    "        self.resnet_block = torch.nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn,\n",
    "            self.relu,\n",
    "            self.conv2,\n",
    "            self.bn\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.resnet_block(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_filter, output_dim, num_resnet):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = ConvBlock(input_dim, num_filter)\n",
    "        self.conv2 = ConvBlock(num_filter, num_filter * 2)\n",
    "        self.conv3 = ConvBlock(num_filter * 2, num_filter * 4)\n",
    "        # Resnet blocks\n",
    "        self.resnet_blocks = []\n",
    "        for i in range(num_resnet):\n",
    "            self.resnet_blocks.append(ResnetBlock(num_filter * 4))\n",
    "        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n",
    "        # Decoder\n",
    "        self.deconv1 = DeconvBlock(num_filter * 4, num_filter * 2)\n",
    "        self.deconv2 = DeconvBlock(num_filter * 2, num_filter)\n",
    "        self.deconv3 = DeconvBlock(num_filter, output_dim, batch_norm=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        # Resnet blocks\n",
    "        res = self.resnet_blocks(enc3)\n",
    "        # Decoder\n",
    "        dec1 = self.deconv1(res)\n",
    "        dec2 = self.deconv2(dec1)\n",
    "        out = self.deconv3(dec2)\n",
    "        return out\n",
    "\n",
    "    def normal_weight_init(self, mean=0.0, std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m, ConvBlock):\n",
    "                torch.nn.init.normal(m.conv.weight, mean, std)\n",
    "            if isinstance(m, DeconvBlock):\n",
    "                torch.nn.init.normal(m.deconv.weight, mean, std)\n",
    "            if isinstance(m, ResnetBlock):\n",
    "                torch.nn.init.normal(m.conv.weight, mean, std)\n",
    "                torch.nn.init.constant(m.conv.bias, 0)\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_filter, output_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        conv1 = ConvBlock(input_dim, num_filter, activation='lrelu', batch_norm=False)\n",
    "        conv2 = ConvBlock(num_filter, num_filter * 4, activation='lrelu')\n",
    "        conv3 = ConvBlock(num_filter * 4, output_dim, activation='no_act', batch_norm=False)\n",
    "\n",
    "        self.conv_blocks = torch.nn.Sequential(\n",
    "            conv1,\n",
    "            conv2,\n",
    "            conv3,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_blocks(x)\n",
    "        return out\n",
    "\n",
    "    def normal_weight_init(self, mean=0.0, std=0.02):\n",
    "        for m in self.children():\n",
    "            if isinstance(m, ConvBlock):\n",
    "                torch.nn.init.normal(m.conv.weight, mean, std)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Conv3d (1, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (bn): BatchNorm3d(10, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (lrelu): LeakyReLU(0.2, inplace)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Conv3d (10, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (bn): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (lrelu): LeakyReLU(0.2, inplace)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv): Conv3d (40, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (bn): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (lrelu): LeakyReLU(0.2, inplace)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define nets and initialise their weigths\n",
    "G_A = Generator(1, 10, 1, 3)\n",
    "G_B = Generator(1, 10, 1, 3)\n",
    "D_A = Discriminator(1, 10, 1)\n",
    "D_B = Discriminator(1, 10, 1)\n",
    "G_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "G_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "G_A.cuda()\n",
    "G_B.cuda()\n",
    "D_A.cuda()\n",
    "D_B.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "MSE_loss = nn.MSELoss().cuda()\n",
    "L1_loss = nn.L1Loss().cuda()\n",
    "\n",
    "# optimizers\n",
    "G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=0.01)\n",
    "D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=0.01)\n",
    "D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=0.01)\n",
    "\n",
    "G_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(G_optimizer, 'min', patience=0, verbose=True, threshold=0.08)\n",
    "D_A_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(D_A_optimizer, 'min', patience=0, verbose=True, threshold=0.08)\n",
    "D_B_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(D_B_optimizer, 'min', patience=0, verbose=True, threshold=0.08)\n",
    "\n",
    "optimizers = [G_optimizer, D_A_optimizer, D_B_optimizer]\n",
    "schedulers = [G_scheduler, D_A_scheduler, D_B_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_A_avg_losses = []\n",
    "D_B_avg_losses = []\n",
    "G_A_avg_losses = []\n",
    "G_B_avg_losses = []\n",
    "cycle_A_avg_losses = []\n",
    "cycle_B_avg_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [50/374], D_A_loss: 0.0815, D_B_loss: 0.0613, G_A_loss: 0.0836, G_B_loss: 0.6508\n",
      "Epoch [1/10], Step [100/374], D_A_loss: 0.0867, D_B_loss: 0.0613, G_A_loss: 0.0866, G_B_loss: 0.6432\n",
      "Epoch [1/10], Step [150/374], D_A_loss: 0.0849, D_B_loss: 0.0624, G_A_loss: 0.0867, G_B_loss: 0.6571\n",
      "Epoch [1/10], Step [200/374], D_A_loss: 0.0859, D_B_loss: 0.0620, G_A_loss: 0.0865, G_B_loss: 0.6515\n",
      "Epoch [1/10], Step [250/374], D_A_loss: 0.0858, D_B_loss: 0.0613, G_A_loss: 0.0876, G_B_loss: 0.6535\n",
      "Epoch [1/10], Step [300/374], D_A_loss: 0.0847, D_B_loss: 0.0613, G_A_loss: 0.0875, G_B_loss: 0.6547\n",
      "Epoch [1/10], Step [350/374], D_A_loss: 0.0851, D_B_loss: 0.0608, G_A_loss: 0.0873, G_B_loss: 0.6562\n",
      "Epoch [2/10], Step [50/374], D_A_loss: 0.0823, D_B_loss: 0.0572, G_A_loss: 0.0857, G_B_loss: 0.6784\n",
      "Epoch [2/10], Step [100/374], D_A_loss: 0.0835, D_B_loss: 0.0567, G_A_loss: 0.0844, G_B_loss: 0.6688\n",
      "Epoch [2/10], Step [150/374], D_A_loss: 0.0844, D_B_loss: 0.0588, G_A_loss: 0.0871, G_B_loss: 0.6598\n",
      "Epoch [2/10], Step [200/374], D_A_loss: 0.0831, D_B_loss: 0.0589, G_A_loss: 0.0863, G_B_loss: 0.6610\n",
      "Epoch [2/10], Step [250/374], D_A_loss: 0.0836, D_B_loss: 0.0590, G_A_loss: 0.0849, G_B_loss: 0.6639\n",
      "Epoch [2/10], Step [300/374], D_A_loss: 0.0839, D_B_loss: 0.0600, G_A_loss: 0.0855, G_B_loss: 0.6613\n",
      "Epoch [2/10], Step [350/374], D_A_loss: 0.0846, D_B_loss: 0.0605, G_A_loss: 0.0862, G_B_loss: 0.6590\n",
      "Epoch [3/10], Step [50/374], D_A_loss: 0.0819, D_B_loss: 0.0595, G_A_loss: 0.0904, G_B_loss: 0.6730\n",
      "Epoch [3/10], Step [100/374], D_A_loss: 0.0830, D_B_loss: 0.0602, G_A_loss: 0.0885, G_B_loss: 0.6620\n",
      "Epoch [3/10], Step [150/374], D_A_loss: 0.0834, D_B_loss: 0.0603, G_A_loss: 0.0869, G_B_loss: 0.6595\n",
      "Epoch [3/10], Step [200/374], D_A_loss: 0.0839, D_B_loss: 0.0605, G_A_loss: 0.0861, G_B_loss: 0.6596\n",
      "Epoch [3/10], Step [250/374], D_A_loss: 0.0837, D_B_loss: 0.0608, G_A_loss: 0.0863, G_B_loss: 0.6592\n",
      "Epoch [3/10], Step [300/374], D_A_loss: 0.0841, D_B_loss: 0.0603, G_A_loss: 0.0862, G_B_loss: 0.6589\n",
      "Epoch [3/10], Step [350/374], D_A_loss: 0.0841, D_B_loss: 0.0608, G_A_loss: 0.0864, G_B_loss: 0.6596\n",
      "Epoch [4/10], Step [50/374], D_A_loss: 0.0822, D_B_loss: 0.0651, G_A_loss: 0.0862, G_B_loss: 0.6625\n",
      "Epoch [4/10], Step [100/374], D_A_loss: 0.0831, D_B_loss: 0.0628, G_A_loss: 0.0830, G_B_loss: 0.6583\n",
      "Epoch [4/10], Step [150/374], D_A_loss: 0.0850, D_B_loss: 0.0617, G_A_loss: 0.0847, G_B_loss: 0.6569\n",
      "Epoch [4/10], Step [200/374], D_A_loss: 0.0843, D_B_loss: 0.0613, G_A_loss: 0.0843, G_B_loss: 0.6575\n",
      "Epoch [4/10], Step [250/374], D_A_loss: 0.0838, D_B_loss: 0.0615, G_A_loss: 0.0863, G_B_loss: 0.6596\n",
      "Epoch [4/10], Step [300/374], D_A_loss: 0.0839, D_B_loss: 0.0611, G_A_loss: 0.0865, G_B_loss: 0.6618\n",
      "Epoch [4/10], Step [350/374], D_A_loss: 0.0839, D_B_loss: 0.0612, G_A_loss: 0.0867, G_B_loss: 0.6587\n",
      "Epoch [5/10], Step [50/374], D_A_loss: 0.0852, D_B_loss: 0.0639, G_A_loss: 0.0887, G_B_loss: 0.6590\n",
      "Epoch [5/10], Step [100/374], D_A_loss: 0.0821, D_B_loss: 0.0617, G_A_loss: 0.0886, G_B_loss: 0.6626\n",
      "Epoch [5/10], Step [150/374], D_A_loss: 0.0836, D_B_loss: 0.0630, G_A_loss: 0.0855, G_B_loss: 0.6558\n",
      "Epoch [5/10], Step [200/374], D_A_loss: 0.0847, D_B_loss: 0.0623, G_A_loss: 0.0855, G_B_loss: 0.6506\n",
      "Epoch [5/10], Step [250/374], D_A_loss: 0.0849, D_B_loss: 0.0622, G_A_loss: 0.0849, G_B_loss: 0.6523\n",
      "Epoch [5/10], Step [300/374], D_A_loss: 0.0847, D_B_loss: 0.0619, G_A_loss: 0.0868, G_B_loss: 0.6548\n",
      "Epoch [5/10], Step [350/374], D_A_loss: 0.0843, D_B_loss: 0.0621, G_A_loss: 0.0870, G_B_loss: 0.6576\n",
      "Epoch [6/10], Step [50/374], D_A_loss: 0.0857, D_B_loss: 0.0600, G_A_loss: 0.0837, G_B_loss: 0.6618\n",
      "Epoch [6/10], Step [100/374], D_A_loss: 0.0851, D_B_loss: 0.0601, G_A_loss: 0.0842, G_B_loss: 0.6618\n",
      "Epoch [6/10], Step [150/374], D_A_loss: 0.0842, D_B_loss: 0.0601, G_A_loss: 0.0835, G_B_loss: 0.6569\n",
      "Epoch [6/10], Step [200/374], D_A_loss: 0.0845, D_B_loss: 0.0608, G_A_loss: 0.0845, G_B_loss: 0.6620\n",
      "Epoch [6/10], Step [250/374], D_A_loss: 0.0838, D_B_loss: 0.0602, G_A_loss: 0.0847, G_B_loss: 0.6646\n",
      "Epoch [6/10], Step [300/374], D_A_loss: 0.0834, D_B_loss: 0.0603, G_A_loss: 0.0852, G_B_loss: 0.6631\n",
      "Epoch [6/10], Step [350/374], D_A_loss: 0.0838, D_B_loss: 0.0604, G_A_loss: 0.0859, G_B_loss: 0.6623\n",
      "Epoch [7/10], Step [50/374], D_A_loss: 0.0853, D_B_loss: 0.0607, G_A_loss: 0.0925, G_B_loss: 0.6552\n",
      "Epoch [7/10], Step [100/374], D_A_loss: 0.0835, D_B_loss: 0.0590, G_A_loss: 0.0886, G_B_loss: 0.6600\n",
      "Epoch [7/10], Step [150/374], D_A_loss: 0.0834, D_B_loss: 0.0594, G_A_loss: 0.0880, G_B_loss: 0.6539\n",
      "Epoch [7/10], Step [200/374], D_A_loss: 0.0829, D_B_loss: 0.0589, G_A_loss: 0.0885, G_B_loss: 0.6607\n",
      "Epoch [7/10], Step [250/374], D_A_loss: 0.0838, D_B_loss: 0.0594, G_A_loss: 0.0893, G_B_loss: 0.6589\n",
      "Epoch [7/10], Step [300/374], D_A_loss: 0.0842, D_B_loss: 0.0598, G_A_loss: 0.0885, G_B_loss: 0.6593\n",
      "Epoch [7/10], Step [350/374], D_A_loss: 0.0840, D_B_loss: 0.0602, G_A_loss: 0.0884, G_B_loss: 0.6586\n",
      "Epoch [8/10], Step [50/374], D_A_loss: 0.0862, D_B_loss: 0.0639, G_A_loss: 0.0842, G_B_loss: 0.6340\n",
      "Epoch [8/10], Step [100/374], D_A_loss: 0.0853, D_B_loss: 0.0609, G_A_loss: 0.0857, G_B_loss: 0.6533\n",
      "Epoch [8/10], Step [150/374], D_A_loss: 0.0844, D_B_loss: 0.0603, G_A_loss: 0.0873, G_B_loss: 0.6561\n",
      "Epoch [8/10], Step [200/374], D_A_loss: 0.0848, D_B_loss: 0.0606, G_A_loss: 0.0859, G_B_loss: 0.6529\n",
      "Epoch [8/10], Step [250/374], D_A_loss: 0.0849, D_B_loss: 0.0613, G_A_loss: 0.0866, G_B_loss: 0.6542\n",
      "Epoch [8/10], Step [300/374], D_A_loss: 0.0851, D_B_loss: 0.0615, G_A_loss: 0.0879, G_B_loss: 0.6553\n",
      "Epoch [8/10], Step [350/374], D_A_loss: 0.0849, D_B_loss: 0.0616, G_A_loss: 0.0879, G_B_loss: 0.6548\n",
      "Epoch [9/10], Step [50/374], D_A_loss: 0.0893, D_B_loss: 0.0591, G_A_loss: 0.0862, G_B_loss: 0.6453\n",
      "Epoch [9/10], Step [100/374], D_A_loss: 0.0867, D_B_loss: 0.0596, G_A_loss: 0.0866, G_B_loss: 0.6572\n",
      "Epoch [9/10], Step [150/374], D_A_loss: 0.0855, D_B_loss: 0.0601, G_A_loss: 0.0863, G_B_loss: 0.6651\n",
      "Epoch [9/10], Step [200/374], D_A_loss: 0.0851, D_B_loss: 0.0597, G_A_loss: 0.0860, G_B_loss: 0.6616\n",
      "Epoch [9/10], Step [250/374], D_A_loss: 0.0854, D_B_loss: 0.0596, G_A_loss: 0.0867, G_B_loss: 0.6623\n",
      "Epoch [9/10], Step [300/374], D_A_loss: 0.0848, D_B_loss: 0.0605, G_A_loss: 0.0865, G_B_loss: 0.6633\n",
      "Epoch [9/10], Step [350/374], D_A_loss: 0.0845, D_B_loss: 0.0608, G_A_loss: 0.0870, G_B_loss: 0.6614\n",
      "Epoch [10/10], Step [50/374], D_A_loss: 0.0845, D_B_loss: 0.0617, G_A_loss: 0.0882, G_B_loss: 0.6721\n",
      "Epoch [10/10], Step [100/374], D_A_loss: 0.0844, D_B_loss: 0.0607, G_A_loss: 0.0853, G_B_loss: 0.6693\n",
      "Epoch [10/10], Step [150/374], D_A_loss: 0.0840, D_B_loss: 0.0596, G_A_loss: 0.0857, G_B_loss: 0.6710\n",
      "Epoch [10/10], Step [200/374], D_A_loss: 0.0856, D_B_loss: 0.0597, G_A_loss: 0.0870, G_B_loss: 0.6599\n",
      "Epoch [10/10], Step [250/374], D_A_loss: 0.0855, D_B_loss: 0.0598, G_A_loss: 0.0879, G_B_loss: 0.6590\n",
      "Epoch [10/10], Step [300/374], D_A_loss: 0.0847, D_B_loss: 0.0600, G_A_loss: 0.0869, G_B_loss: 0.6592\n",
      "Epoch [10/10], Step [350/374], D_A_loss: 0.0846, D_B_loss: 0.0604, G_A_loss: 0.0866, G_B_loss: 0.6601\n"
     ]
    }
   ],
   "source": [
    "losses = train(G_A, G_B, D_A, D_B, MSE_loss, L1_loss, optimizers, schedulers, trainloader_inp, trainloader_tar, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_test_predictions = get_predictions(G_A, final_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predicted_brains = reconstruct_brain(final_test_predictions, padded_testing_scans_input, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19cd4977d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_pred(padded_testing_scans_input[0], final_predicted_brains[0], padded_testing_scans_input[0], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_diff(final_predicted_brains[0], final_test_inp[0], final_test_out1[0], 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the target and the predicted scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to = \"/home/ubuntu/project/Dataset/Final_AWS_1\"\n",
    "\n",
    "predicted_scan = nib.Nifti1Image(final_predicted_brain, affine_mat)\n",
    "nib.save(predicted_scan, save_to + \"/Predicted_Subj9Scan2_AWS.nii.gz\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(trained_net.state_dict(), '/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/Final_Model_FC.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_net = Net()\n",
    "trained_net.cuda()\n",
    "trained_net.load_state_dict(torch.load('/home/ubuntu/project/MRIDataHarmonisation/Development/Model_Params_AWS/Final_Model_FC.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= [1,2,3,4]\n",
    "b =[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
